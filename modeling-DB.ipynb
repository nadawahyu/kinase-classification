{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Basically we are trying to find the best algorithm to classify the inhibitor types in our binary dataset from KinCoRe that we preprocessed. Here, we are trying out using Logistic Regression, Support Vector Machine, and Random Forest.\n",
    "\n",
    "The workflow is as follows:\n",
    "1. load packages, directory, and dataset\n",
    "2. find the best combination of sampling and standardization/normalization methods that yields the best baseline model\n",
    "3. run hyperparameter tuning for our model to get the highest metrics score\n",
    "4. repeat with different algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general data analysis packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# file management packages\n",
    "import csv, sys\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "# sampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "\n",
    "# modeling\n",
    "from sklearn import preprocessing, model_selection, feature_selection, metrics\n",
    "from sklearn.feature_selection import f_classif, SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler, Normalizer, PowerTransformer, QuantileTransformer, RobustScaler, StandardScaler\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# misc\n",
    "from textwrap import wrap\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lig_smiles</th>\n",
       "      <th>LigandType</th>\n",
       "      <th>lig_at</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>SPS</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNC(=O)c1c(C)oc2cc(Oc3ccnc4cc(OCCN5CCOCC5)ccc3...</td>\n",
       "      <td>Type1.5_Back</td>\n",
       "      <td>2169</td>\n",
       "      <td>12.178672</td>\n",
       "      <td>12.178672</td>\n",
       "      <td>0.173135</td>\n",
       "      <td>-0.173135</td>\n",
       "      <td>0.442423</td>\n",
       "      <td>14.411765</td>\n",
       "      <td>461.518</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O=C(O)c1cc2cc3ccc4oc(C(=O)O)cc4c3cc2o1</td>\n",
       "      <td>Type1</td>\n",
       "      <td>313</td>\n",
       "      <td>11.019783</td>\n",
       "      <td>11.019783</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>-1.142046</td>\n",
       "      <td>0.584168</td>\n",
       "      <td>11.454545</td>\n",
       "      <td>296.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O=C(O)c1cc2cc3ccc4oc(C(=O)O)cc4c3cc2o1</td>\n",
       "      <td>Type1</td>\n",
       "      <td>332</td>\n",
       "      <td>11.019783</td>\n",
       "      <td>11.019783</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>-1.142046</td>\n",
       "      <td>0.584168</td>\n",
       "      <td>11.454545</td>\n",
       "      <td>296.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COc1cc(Nc2nccc(Nc3cnc4ccccc4c3)n2)ccc1N1CCOCC1</td>\n",
       "      <td>Type1</td>\n",
       "      <td>60001</td>\n",
       "      <td>5.632207</td>\n",
       "      <td>5.632207</td>\n",
       "      <td>0.490670</td>\n",
       "      <td>0.490670</td>\n",
       "      <td>0.468745</td>\n",
       "      <td>13.718750</td>\n",
       "      <td>428.496</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cc1cc(Nc2nn(C(C)C)c(=O)c3cc(N4CCN(C)CC4)ccc23)...</td>\n",
       "      <td>Type1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.089887</td>\n",
       "      <td>13.089887</td>\n",
       "      <td>0.036424</td>\n",
       "      <td>-0.065059</td>\n",
       "      <td>0.722645</td>\n",
       "      <td>15.535714</td>\n",
       "      <td>381.484</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4764</th>\n",
       "      <td>O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...</td>\n",
       "      <td>Type1</td>\n",
       "      <td>1390</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>-1.022970</td>\n",
       "      <td>0.384505</td>\n",
       "      <td>12.264706</td>\n",
       "      <td>476.870</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4765</th>\n",
       "      <td>O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...</td>\n",
       "      <td>Type1</td>\n",
       "      <td>1392</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>-1.022970</td>\n",
       "      <td>0.384505</td>\n",
       "      <td>12.264706</td>\n",
       "      <td>476.870</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4766</th>\n",
       "      <td>O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...</td>\n",
       "      <td>Type1</td>\n",
       "      <td>1389</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>-1.022970</td>\n",
       "      <td>0.384505</td>\n",
       "      <td>12.264706</td>\n",
       "      <td>476.870</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...</td>\n",
       "      <td>Type1</td>\n",
       "      <td>1001</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>-1.022970</td>\n",
       "      <td>0.384505</td>\n",
       "      <td>12.264706</td>\n",
       "      <td>476.870</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4768</th>\n",
       "      <td>NC(=O)c1cnc2ccn(S(=O)(=O)c3ccccc3[N+](=O)[O-])...</td>\n",
       "      <td>Type1</td>\n",
       "      <td>2347</td>\n",
       "      <td>12.829889</td>\n",
       "      <td>12.829889</td>\n",
       "      <td>0.027974</td>\n",
       "      <td>-4.257491</td>\n",
       "      <td>0.557543</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>346.324</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4769 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             lig_smiles    LigandType  lig_at  \\\n",
       "0     CNC(=O)c1c(C)oc2cc(Oc3ccnc4cc(OCCN5CCOCC5)ccc3...  Type1.5_Back    2169   \n",
       "1                O=C(O)c1cc2cc3ccc4oc(C(=O)O)cc4c3cc2o1         Type1     313   \n",
       "2                O=C(O)c1cc2cc3ccc4oc(C(=O)O)cc4c3cc2o1         Type1     332   \n",
       "3        COc1cc(Nc2nccc(Nc3cnc4ccccc4c3)n2)ccc1N1CCOCC1         Type1   60001   \n",
       "4     Cc1cc(Nc2nn(C(C)C)c(=O)c3cc(N4CCN(C)CC4)ccc23)...         Type1       1   \n",
       "...                                                 ...           ...     ...   \n",
       "4764  O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...         Type1    1390   \n",
       "4765  O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...         Type1    1392   \n",
       "4766  O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...         Type1    1389   \n",
       "4767  O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...         Type1    1001   \n",
       "4768  NC(=O)c1cnc2ccn(S(=O)(=O)c3ccccc3[N+](=O)[O-])...         Type1    2347   \n",
       "\n",
       "      MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  MinEStateIndex  \\\n",
       "0             12.178672       12.178672           0.173135       -0.173135   \n",
       "1             11.019783       11.019783           0.138918       -1.142046   \n",
       "2             11.019783       11.019783           0.138918       -1.142046   \n",
       "3              5.632207        5.632207           0.490670        0.490670   \n",
       "4             13.089887       13.089887           0.036424       -0.065059   \n",
       "...                 ...             ...                ...             ...   \n",
       "4764          14.647223       14.647223           0.109453       -1.022970   \n",
       "4765          14.647223       14.647223           0.109453       -1.022970   \n",
       "4766          14.647223       14.647223           0.109453       -1.022970   \n",
       "4767          14.647223       14.647223           0.109453       -1.022970   \n",
       "4768          12.829889       12.829889           0.027974       -4.257491   \n",
       "\n",
       "           qed        SPS    MolWt  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  \\\n",
       "0     0.442423  14.411765  461.518  ...           0             0           0   \n",
       "1     0.584168  11.454545  296.234  ...           0             0           0   \n",
       "2     0.584168  11.454545  296.234  ...           0             0           0   \n",
       "3     0.468745  13.718750  428.496  ...           0             0           0   \n",
       "4     0.722645  15.535714  381.484  ...           0             0           0   \n",
       "...        ...        ...      ...  ...         ...           ...         ...   \n",
       "4764  0.384505  12.264706  476.870  ...           0             0           0   \n",
       "4765  0.384505  12.264706  476.870  ...           0             0           0   \n",
       "4766  0.384505  12.264706  476.870  ...           0             0           0   \n",
       "4767  0.384505  12.264706  476.870  ...           0             0           0   \n",
       "4768  0.557543  11.500000  346.324  ...           0             0           0   \n",
       "\n",
       "      fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  \\\n",
       "0                     0             0            0            0             0   \n",
       "1                     0             0            0            0             0   \n",
       "2                     0             0            0            0             0   \n",
       "3                     0             0            0            0             0   \n",
       "4                     0             0            0            0             0   \n",
       "...                 ...           ...          ...          ...           ...   \n",
       "4764                  0             0            0            0             0   \n",
       "4765                  0             0            0            0             0   \n",
       "4766                  0             0            0            0             0   \n",
       "4767                  0             0            0            0             0   \n",
       "4768                  0             0            0            0             0   \n",
       "\n",
       "      fr_unbrch_alkane  fr_urea  \n",
       "0                    0        0  \n",
       "1                    0        0  \n",
       "2                    0        0  \n",
       "3                    0        0  \n",
       "4                    0        0  \n",
       "...                ...      ...  \n",
       "4764                 0        0  \n",
       "4765                 0        0  \n",
       "4766                 0        0  \n",
       "4767                 0        0  \n",
       "4768                 0        0  \n",
       "\n",
       "[4769 rows x 190 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_db = pd.read_csv('data_binding_desc-03.csv').drop(columns=['Unnamed: 0'])\n",
    "data_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lig_smiles</th>\n",
       "      <th>LigandType</th>\n",
       "      <th>lig_at</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>SPS</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNC(=O)c1c(C)oc2cc(Oc3ccnc4cc(OCCN5CCOCC5)ccc3...</td>\n",
       "      <td>Type1.5</td>\n",
       "      <td>2169</td>\n",
       "      <td>12.178672</td>\n",
       "      <td>12.178672</td>\n",
       "      <td>0.173135</td>\n",
       "      <td>-0.173135</td>\n",
       "      <td>0.442423</td>\n",
       "      <td>14.411765</td>\n",
       "      <td>461.518</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O=C(O)c1cc2cc3ccc4oc(C(=O)O)cc4c3cc2o1</td>\n",
       "      <td>Type1</td>\n",
       "      <td>313</td>\n",
       "      <td>11.019783</td>\n",
       "      <td>11.019783</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>-1.142046</td>\n",
       "      <td>0.584168</td>\n",
       "      <td>11.454545</td>\n",
       "      <td>296.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O=C(O)c1cc2cc3ccc4oc(C(=O)O)cc4c3cc2o1</td>\n",
       "      <td>Type1</td>\n",
       "      <td>332</td>\n",
       "      <td>11.019783</td>\n",
       "      <td>11.019783</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>-1.142046</td>\n",
       "      <td>0.584168</td>\n",
       "      <td>11.454545</td>\n",
       "      <td>296.234</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COc1cc(Nc2nccc(Nc3cnc4ccccc4c3)n2)ccc1N1CCOCC1</td>\n",
       "      <td>Type1</td>\n",
       "      <td>60001</td>\n",
       "      <td>5.632207</td>\n",
       "      <td>5.632207</td>\n",
       "      <td>0.490670</td>\n",
       "      <td>0.490670</td>\n",
       "      <td>0.468745</td>\n",
       "      <td>13.718750</td>\n",
       "      <td>428.496</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cc1cc(Nc2nn(C(C)C)c(=O)c3cc(N4CCN(C)CC4)ccc23)...</td>\n",
       "      <td>Type1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.089887</td>\n",
       "      <td>13.089887</td>\n",
       "      <td>0.036424</td>\n",
       "      <td>-0.065059</td>\n",
       "      <td>0.722645</td>\n",
       "      <td>15.535714</td>\n",
       "      <td>381.484</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4764</th>\n",
       "      <td>O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...</td>\n",
       "      <td>Type1</td>\n",
       "      <td>1390</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>-1.022970</td>\n",
       "      <td>0.384505</td>\n",
       "      <td>12.264706</td>\n",
       "      <td>476.870</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4765</th>\n",
       "      <td>O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...</td>\n",
       "      <td>Type1</td>\n",
       "      <td>1392</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>-1.022970</td>\n",
       "      <td>0.384505</td>\n",
       "      <td>12.264706</td>\n",
       "      <td>476.870</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4766</th>\n",
       "      <td>O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...</td>\n",
       "      <td>Type1</td>\n",
       "      <td>1389</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>-1.022970</td>\n",
       "      <td>0.384505</td>\n",
       "      <td>12.264706</td>\n",
       "      <td>476.870</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...</td>\n",
       "      <td>Type1</td>\n",
       "      <td>1001</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>-1.022970</td>\n",
       "      <td>0.384505</td>\n",
       "      <td>12.264706</td>\n",
       "      <td>476.870</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4768</th>\n",
       "      <td>NC(=O)c1cnc2ccn(S(=O)(=O)c3ccccc3[N+](=O)[O-])...</td>\n",
       "      <td>Type1</td>\n",
       "      <td>2347</td>\n",
       "      <td>12.829889</td>\n",
       "      <td>12.829889</td>\n",
       "      <td>0.027974</td>\n",
       "      <td>-4.257491</td>\n",
       "      <td>0.557543</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>346.324</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4769 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             lig_smiles LigandType  lig_at  \\\n",
       "0     CNC(=O)c1c(C)oc2cc(Oc3ccnc4cc(OCCN5CCOCC5)ccc3...    Type1.5    2169   \n",
       "1                O=C(O)c1cc2cc3ccc4oc(C(=O)O)cc4c3cc2o1      Type1     313   \n",
       "2                O=C(O)c1cc2cc3ccc4oc(C(=O)O)cc4c3cc2o1      Type1     332   \n",
       "3        COc1cc(Nc2nccc(Nc3cnc4ccccc4c3)n2)ccc1N1CCOCC1      Type1   60001   \n",
       "4     Cc1cc(Nc2nn(C(C)C)c(=O)c3cc(N4CCN(C)CC4)ccc23)...      Type1       1   \n",
       "...                                                 ...        ...     ...   \n",
       "4764  O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...      Type1    1390   \n",
       "4765  O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...      Type1    1392   \n",
       "4766  O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...      Type1    1389   \n",
       "4767  O=C(O)c1ccc(Nc2ncc3c(n2)-c2ccc(Cl)cc2C(c2c(F)c...      Type1    1001   \n",
       "4768  NC(=O)c1cnc2ccn(S(=O)(=O)c3ccccc3[N+](=O)[O-])...      Type1    2347   \n",
       "\n",
       "      MaxAbsEStateIndex  MaxEStateIndex  MinAbsEStateIndex  MinEStateIndex  \\\n",
       "0             12.178672       12.178672           0.173135       -0.173135   \n",
       "1             11.019783       11.019783           0.138918       -1.142046   \n",
       "2             11.019783       11.019783           0.138918       -1.142046   \n",
       "3              5.632207        5.632207           0.490670        0.490670   \n",
       "4             13.089887       13.089887           0.036424       -0.065059   \n",
       "...                 ...             ...                ...             ...   \n",
       "4764          14.647223       14.647223           0.109453       -1.022970   \n",
       "4765          14.647223       14.647223           0.109453       -1.022970   \n",
       "4766          14.647223       14.647223           0.109453       -1.022970   \n",
       "4767          14.647223       14.647223           0.109453       -1.022970   \n",
       "4768          12.829889       12.829889           0.027974       -4.257491   \n",
       "\n",
       "           qed        SPS    MolWt  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  \\\n",
       "0     0.442423  14.411765  461.518  ...           0             0           0   \n",
       "1     0.584168  11.454545  296.234  ...           0             0           0   \n",
       "2     0.584168  11.454545  296.234  ...           0             0           0   \n",
       "3     0.468745  13.718750  428.496  ...           0             0           0   \n",
       "4     0.722645  15.535714  381.484  ...           0             0           0   \n",
       "...        ...        ...      ...  ...         ...           ...         ...   \n",
       "4764  0.384505  12.264706  476.870  ...           0             0           0   \n",
       "4765  0.384505  12.264706  476.870  ...           0             0           0   \n",
       "4766  0.384505  12.264706  476.870  ...           0             0           0   \n",
       "4767  0.384505  12.264706  476.870  ...           0             0           0   \n",
       "4768  0.557543  11.500000  346.324  ...           0             0           0   \n",
       "\n",
       "      fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  \\\n",
       "0                     0             0            0            0             0   \n",
       "1                     0             0            0            0             0   \n",
       "2                     0             0            0            0             0   \n",
       "3                     0             0            0            0             0   \n",
       "4                     0             0            0            0             0   \n",
       "...                 ...           ...          ...          ...           ...   \n",
       "4764                  0             0            0            0             0   \n",
       "4765                  0             0            0            0             0   \n",
       "4766                  0             0            0            0             0   \n",
       "4767                  0             0            0            0             0   \n",
       "4768                  0             0            0            0             0   \n",
       "\n",
       "      fr_unbrch_alkane  fr_urea  \n",
       "0                    0        0  \n",
       "1                    0        0  \n",
       "2                    0        0  \n",
       "3                    0        0  \n",
       "4                    0        0  \n",
       "...                ...      ...  \n",
       "4764                 0        0  \n",
       "4765                 0        0  \n",
       "4766                 0        0  \n",
       "4767                 0        0  \n",
       "4768                 0        0  \n",
       "\n",
       "[4769 rows x 190 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_db = data_db.replace({'Type1.5_Back':'Type1.5', 'Type1.5_Front':'Type1.5'})\n",
    "data_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='LigandType', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data_db, x='LigandType')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from here we can see that there are several columns that need to be dropped for the next step, such as `Unnamed: 0` and `lig_smiles`. The column `LigandType` needs to be separated as a target. The rest (209 columns) are features we'll use in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. preprocess data\n",
    "\n",
    "workflow in this step is the following:\n",
    "1. drop duplicate and null rows\n",
    "2. drop feature that begins with `Unnamed` (since it was generated automatically when we did not reset the index in the last step before saving the data from the previous step into csv)\n",
    "3. encode target using integer (0,1)\n",
    "4. separate features and target\n",
    "5. remove features which values don't have variation\n",
    "6. remove feature that has low correlation with other features\n",
    "7. split data into train-validation and test set\n",
    "8. split data into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data,\n",
    "                       target='LigandType', \n",
    "                       col_to_drop=['lig_smiles'],\n",
    "                       test_size=0.2, \n",
    "                       val_size=0.2, \n",
    "                       random_state=0,\n",
    "                       anova=True,\n",
    "                       ):\n",
    "    '''\n",
    "    preprocess data from the previous workflow\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "      data: pd.DataFrame\n",
    "        the input data to be preprocesed\n",
    "      target: str\n",
    "        target column for the model\n",
    "      col_to_drop: list\n",
    "        list of columns to drop\n",
    "      test_size: float\n",
    "        test size from the whole input data\n",
    "      val_size: float\n",
    "        validation set size from the whole input data\n",
    "      anova: bool\n",
    "        initial feature selection option using ANOVA\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "      X_train, X_val, X_test, y_train, y_val, y_test: np.array\n",
    "        the respective train, validation and test sets\n",
    "      descnm: np.array\n",
    "        feature names\n",
    "    '''\n",
    "\n",
    "    # drop duplicate rows\n",
    "    data_ = data.drop_duplicates().dropna()\n",
    "\n",
    "    # drop cols with 'unnamed'\n",
    "    colidx_to_drop = [i for i in data.columns if 'Unnamed' in i]\n",
    "\n",
    "    #encode target\n",
    "    to_mask = {}\n",
    "\n",
    "    for i,j in enumerate(data_[target].unique()):\n",
    "        to_mask.update({j:i})\n",
    "\n",
    "    data_ = data_.replace(to_mask)\n",
    "\n",
    "    # separate x and y\n",
    "    X = data_.loc[:, data_.columns.difference(col_to_drop+[target]+colidx_to_drop)]\n",
    "    y = data_[target]\n",
    "\n",
    "    # remove features that don't have variation\n",
    "    X_out = X.loc[:,X.apply(pd.Series.nunique) != 1]\n",
    "    mask = X_out.applymap(lambda x: isinstance(x, (int, float)))\n",
    "    X_out2 = X_out.where(mask)\n",
    "    X = X_out2.dropna(axis=1)\n",
    "\n",
    "    if anova == True:\n",
    "      # anova feature selection\n",
    "      f_stat, p_val, = f_classif(X, y)\n",
    "\n",
    "      # get index which probability is lower than p = 0.05\n",
    "      idx = [i for i,j in enumerate(p_val) if j < 0.05]\n",
    "      # select column with respective index\n",
    "      X = X.iloc[:,idx]\n",
    "    else:\n",
    "      pass\n",
    "\n",
    "    # split train-validation and test\n",
    "    X_trainval, X_test, y_trainval, y_test = model_selection.train_test_split(X, y, test_size = test_size, random_state=random_state, stratify=y)\n",
    "    # split train and validation\n",
    "    X_train, X_val, y_train, y_val = model_selection.train_test_split(X_trainval, y_trainval, test_size = val_size/(1-val_size), random_state=random_state, stratify=y_trainval)\n",
    "\n",
    "    descnm = np.array(X_train.columns)\n",
    "    X_train = np.array(X_train)\n",
    "    X_val = np.array(X_val)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_val = np.array(y_val)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    #return X_trainval, X_test, y_trainval, y_test\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, descnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, descnm = data_preprocessing(data_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2859\n",
      "953\n",
      "953\n",
      "4765\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_val))\n",
    "print(len(y_test))\n",
    "print(len(y_train)+len(y_val)+len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_db[data_db['LigandType']=='Type3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 = 292\n",
      "1 = 2266\n",
      "2 = 203\n",
      "3 = 98\n",
      "\n",
      "0 = 97\n",
      "1 = 755\n",
      "2 = 68\n",
      "3 = 33\n",
      "\n",
      "0 = 97\n",
      "1 = 755\n",
      "2 = 68\n",
      "3 = 33\n"
     ]
    }
   ],
   "source": [
    "print(f'0 = {len([i for i in y_train if i == 0])}')\n",
    "print(f'1 = {len([i for i in y_train if i == 1])}')\n",
    "print(f'2 = {len([i for i in y_train if i == 2])}')\n",
    "print(f'3 = {len([i for i in y_train if i == 3])}')\n",
    "print('')\n",
    "\n",
    "print(f'0 = {len([i for i in y_val if i == 0])}')\n",
    "print(f'1 = {len([i for i in y_val if i == 1])}')\n",
    "print(f'2 = {len([i for i in y_val if i == 2])}')\n",
    "print(f'3 = {len([i for i in y_val if i == 3])}')\n",
    "print('')\n",
    "\n",
    "print(f'0 = {len([i for i in y_test if i == 0])}')\n",
    "print(f'1 = {len([i for i in y_test if i == 1])}')\n",
    "print(f'2 = {len([i for i in y_test if i == 2])}')\n",
    "print(f'3 = {len([i for i in y_test if i == 3])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>NumValenceElectrons</th>\n",
       "      <th>NumRadicalElectrons</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.178672</td>\n",
       "      <td>-0.173135</td>\n",
       "      <td>12.178672</td>\n",
       "      <td>0.173135</td>\n",
       "      <td>0.442423</td>\n",
       "      <td>461.518</td>\n",
       "      <td>434.302</td>\n",
       "      <td>461.195071</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.019783</td>\n",
       "      <td>-1.142046</td>\n",
       "      <td>11.019783</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>0.584168</td>\n",
       "      <td>296.234</td>\n",
       "      <td>288.170</td>\n",
       "      <td>296.032088</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.019783</td>\n",
       "      <td>-1.142046</td>\n",
       "      <td>11.019783</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>0.584168</td>\n",
       "      <td>296.234</td>\n",
       "      <td>288.170</td>\n",
       "      <td>296.032088</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.632207</td>\n",
       "      <td>0.490670</td>\n",
       "      <td>5.632207</td>\n",
       "      <td>0.490670</td>\n",
       "      <td>0.468745</td>\n",
       "      <td>428.496</td>\n",
       "      <td>404.304</td>\n",
       "      <td>428.196074</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.089887</td>\n",
       "      <td>-0.065059</td>\n",
       "      <td>13.089887</td>\n",
       "      <td>0.036424</td>\n",
       "      <td>0.722645</td>\n",
       "      <td>381.484</td>\n",
       "      <td>354.268</td>\n",
       "      <td>381.227708</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>6.252538</td>\n",
       "      <td>0.518412</td>\n",
       "      <td>6.252538</td>\n",
       "      <td>0.518412</td>\n",
       "      <td>0.358838</td>\n",
       "      <td>458.518</td>\n",
       "      <td>432.310</td>\n",
       "      <td>458.195405</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215</th>\n",
       "      <td>11.222610</td>\n",
       "      <td>-0.469079</td>\n",
       "      <td>11.222610</td>\n",
       "      <td>0.204548</td>\n",
       "      <td>0.767397</td>\n",
       "      <td>333.347</td>\n",
       "      <td>318.227</td>\n",
       "      <td>333.111341</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216</th>\n",
       "      <td>14.647223</td>\n",
       "      <td>-1.022970</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>0.384505</td>\n",
       "      <td>476.870</td>\n",
       "      <td>461.750</td>\n",
       "      <td>476.085160</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4217</th>\n",
       "      <td>14.647223</td>\n",
       "      <td>-1.022970</td>\n",
       "      <td>14.647223</td>\n",
       "      <td>0.109453</td>\n",
       "      <td>0.384505</td>\n",
       "      <td>476.870</td>\n",
       "      <td>461.750</td>\n",
       "      <td>476.085160</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4218</th>\n",
       "      <td>12.829889</td>\n",
       "      <td>-4.257491</td>\n",
       "      <td>12.829889</td>\n",
       "      <td>0.027974</td>\n",
       "      <td>0.557543</td>\n",
       "      <td>346.324</td>\n",
       "      <td>336.244</td>\n",
       "      <td>346.037190</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4219 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MaxEStateIndex  MinEStateIndex  MaxAbsEStateIndex  MinAbsEStateIndex  \\\n",
       "0          12.178672       -0.173135          12.178672           0.173135   \n",
       "1          11.019783       -1.142046          11.019783           0.138918   \n",
       "2          11.019783       -1.142046          11.019783           0.138918   \n",
       "3           5.632207        0.490670           5.632207           0.490670   \n",
       "4          13.089887       -0.065059          13.089887           0.036424   \n",
       "...              ...             ...                ...                ...   \n",
       "4214        6.252538        0.518412           6.252538           0.518412   \n",
       "4215       11.222610       -0.469079          11.222610           0.204548   \n",
       "4216       14.647223       -1.022970          14.647223           0.109453   \n",
       "4217       14.647223       -1.022970          14.647223           0.109453   \n",
       "4218       12.829889       -4.257491          12.829889           0.027974   \n",
       "\n",
       "           qed    MolWt  HeavyAtomMolWt  ExactMolWt  NumValenceElectrons  \\\n",
       "0     0.442423  461.518         434.302  461.195071                  176   \n",
       "1     0.584168  296.234         288.170  296.032088                  108   \n",
       "2     0.584168  296.234         288.170  296.032088                  108   \n",
       "3     0.468745  428.496         404.304  428.196074                  162   \n",
       "4     0.722645  381.484         354.268  381.227708                  148   \n",
       "...        ...      ...             ...         ...                  ...   \n",
       "4214  0.358838  458.518         432.310  458.195405                  174   \n",
       "4215  0.767397  333.347         318.227  333.111341                  124   \n",
       "4216  0.384505  476.870         461.750  476.085160                  168   \n",
       "4217  0.384505  476.870         461.750  476.085160                  168   \n",
       "4218  0.557543  346.324         336.244  346.037190                  122   \n",
       "\n",
       "      NumRadicalElectrons  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  \\\n",
       "0                       0  ...           0             0           0   \n",
       "1                       0  ...           0             0           0   \n",
       "2                       0  ...           0             0           0   \n",
       "3                       0  ...           0             0           0   \n",
       "4                       0  ...           0             0           0   \n",
       "...                   ...  ...         ...           ...         ...   \n",
       "4214                    0  ...           0             0           0   \n",
       "4215                    0  ...           0             0           0   \n",
       "4216                    0  ...           0             0           0   \n",
       "4217                    0  ...           0             0           0   \n",
       "4218                    0  ...           0             0           0   \n",
       "\n",
       "      fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  \\\n",
       "0                     0             0            0            0             0   \n",
       "1                     0             0            0            0             0   \n",
       "2                     0             0            0            0             0   \n",
       "3                     0             0            0            0             0   \n",
       "4                     0             0            0            0             0   \n",
       "...                 ...           ...          ...          ...           ...   \n",
       "4214                  0             0            0            0             0   \n",
       "4215                  0             0            0            0             0   \n",
       "4216                  0             0            0            0             0   \n",
       "4217                  0             0            0            0             0   \n",
       "4218                  0             0            0            0             0   \n",
       "\n",
       "      fr_unbrch_alkane  fr_urea  \n",
       "0                    0        0  \n",
       "1                    0        0  \n",
       "2                    0        0  \n",
       "3                    0        0  \n",
       "4                    0        0  \n",
       "...                ...      ...  \n",
       "4214                 0        0  \n",
       "4215                 0        0  \n",
       "4216                 0        0  \n",
       "4217                 0        0  \n",
       "4218                 0        0  \n",
       "\n",
       "[4219 rows x 208 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_da_desc = data_db.drop(columns=['Unnamed: 0', 'lig_smiles', 'LigandType', 'lig_at'])#.describe().T\n",
    "data_da_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. find combination of sampling and standardization methods for a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_model(X_train, y_train, X_val, y_val,\n",
    "                algorithm = 'logreg',\n",
    "                multiclass = False,\n",
    "                kernel = 'rbf',\n",
    "                solver='liblinear',\n",
    "                max_iter=10000,\n",
    "                scaling = True,\n",
    "                random_state=0):\n",
    "    '''\n",
    "    Find the best combination of sampling and\n",
    "    standardization methods as a baseline model.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "        X_train, y_train, X_val, y_val: np.array or pd.DataFrame or pd.Series\n",
    "            Training and validation data and its targts\n",
    "        algorithm: str\n",
    "            The algorithm to use. Available are:\n",
    "            - Logistic regression: 'LogisticRegression'\n",
    "            - Support vector machine: 'SVC'\n",
    "            - Random forest: 'RandomForestClassification'\n",
    "        multiclass: bool\n",
    "            Determining whether the classification is binary or multiclass.\n",
    "            if `True` then the average metrics is computed as weighted\n",
    "            if `False` then the average metrics is computed as binary\n",
    "        kernel: str\n",
    "            only applies in support vector machine. \n",
    "            The kernel you wish to run.\n",
    "        solver: str\n",
    "            only applies in logistic regression. \n",
    "            The solver you wish to run. Default is 'liblinear'.\n",
    "        #sampling: str\n",
    "        #    sampling method you wish to use. Available are:\n",
    "        #    - smote\n",
    "        #    - random_over\n",
    "        #    - random_under\n",
    "        scaling: bool\n",
    "            scaling (standardization/normalization) of the data.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "        df_find_model\n",
    "            A DataFrame of the scores between different sampling and scaling methods \n",
    "            across metrics of the training and validation data\n",
    "    '''\n",
    "\n",
    "    def model_(X_train, y_train, X_val, y_val,\n",
    "                      algorithm = algorithm,\n",
    "                      multiclass = multiclass,\n",
    "                      kernel = kernel,\n",
    "                      solver = solver,\n",
    "                      sampling = 'SMOTE',\n",
    "                      max_iter=max_iter,\n",
    "                      scaling = scaling,\n",
    "                      random_state=random_state):\n",
    "        '''\n",
    "        Find the best combination of sampling and\n",
    "        standardization methods as a baseline model.\n",
    "\n",
    "        Args:\n",
    "        ----------\n",
    "            X_train, y_train, X_val, y_val: np.array or pd.DataFrame or pd.Series\n",
    "                Training and validation data and its targts\n",
    "            algorithm: str\n",
    "                The algorithm to use. Available are:\n",
    "                - Logistic regression: 'logreg'\n",
    "                - Support vector machine: 'svm'\n",
    "                - Random forest: 'rf'\n",
    "            multiclass: bool\n",
    "                Determining whether the classification is binary or multiclass.\n",
    "                if `True` then the average metrics is computed as weighted\n",
    "                if `False` then the average metrics is computed as binary\n",
    "            kernel: str\n",
    "                only applies in support vector machine. \n",
    "                The kernel you wish to run.\n",
    "            solver: str\n",
    "                only applies in logistic regression. \n",
    "                The solver you wish to run. Default is 'liblinear'.\n",
    "            sampling: str\n",
    "                sampling method you wish to use. Available are:\n",
    "                - smote\n",
    "                - random_over\n",
    "                - random_under\n",
    "            scaling: bool\n",
    "                scaling (standardization/normalization) of the data.\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "            dict\n",
    "                A dictionary of the scores between different sampling and scaling methods \n",
    "                across metrics of the training and validation data\n",
    "        '''\n",
    "\n",
    "        if type(sampling) == str:\n",
    "            sampling = [sampling]\n",
    "\n",
    "        for i in sampling:\n",
    "            if i == 'RandomUnderSampler':\n",
    "                X_train, y_train  = RandomUnderSampler(random_state=random_state).fit_resample(X_train, y_train)\n",
    "            elif i == 'RandomOverSampler':\n",
    "                X_train, y_train  = RandomOverSampler(random_state=random_state).fit_resample(X_train, y_train)\n",
    "            elif i == 'SMOTE':\n",
    "                X_train, y_train = SMOTE(random_state=random_state).fit_resample(X_train, y_train)\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        if algorithm == 'LogisticRegression':\n",
    "            model = LogisticRegression(solver=solver, random_state=random_state, max_iter=max_iter)\n",
    "        elif algorithm == 'SVC':\n",
    "            model = SVC(kernel=kernel, random_state=random_state)\n",
    "        else:\n",
    "            model = RandomForestClassifier(random_state=random_state)\n",
    "            scaling = False\n",
    "\n",
    "        # scaling\n",
    "        if scaling == False:\n",
    "            train_scaled = {'none':X_train}\n",
    "            val_scaled = {'none':X_val}\n",
    "        else:\n",
    "            X_train_MAS = preprocessing.MaxAbsScaler().fit_transform(X_train)\n",
    "            X_train_MMS = preprocessing.MinMaxScaler().fit_transform(X_train)\n",
    "            X_train_SS = preprocessing.StandardScaler().fit_transform(X_train)\n",
    "            X_train_NORM = preprocessing.Normalizer().fit_transform(X_train)\n",
    "            X_train_NMAS = preprocessing.MaxAbsScaler().fit_transform(X_train_NORM)\n",
    "            X_train_NMMS = preprocessing.MinMaxScaler().fit_transform(X_train_NORM)\n",
    "            X_train_NSS = preprocessing.StandardScaler().fit_transform(X_train_NORM)\n",
    "            X_train_MASNORM = preprocessing.Normalizer().fit_transform(X_train_MAS)\n",
    "            X_train_MMSNORM = preprocessing.Normalizer().fit_transform(X_train_MMS)\n",
    "            X_train_SSNORM = preprocessing.Normalizer().fit_transform(X_train_SS)\n",
    "\n",
    "            train_scaled = {\n",
    "                'none':X_train,\n",
    "                'MaxAbsScaler':X_train_MAS,\n",
    "                'MinMaxScaler':X_train_MMS,\n",
    "                'StandardScaler':X_train_SS,\n",
    "                'Normalizer':X_train_NORM,\n",
    "                'Normalizer + MaxAbsScaler':X_train_NMAS,\n",
    "                'Normalizer + MinMaxScaler':X_train_NMMS,\n",
    "                'Normalizer + StandardScaler':X_train_NSS,\n",
    "                'MaxAbsScaler + Normalizer':X_train_MASNORM,\n",
    "                'MinMaxScaler + Normalizer':X_train_MMSNORM,\n",
    "                'StandardScaler + Normalizer':X_train_SSNORM,\n",
    "                }\n",
    "\n",
    "        output_dict= {\n",
    "            'sampling': [],\n",
    "            'scaling': [],\n",
    "            'train_accuracy': [],\n",
    "            'train_f1': [],\n",
    "            'train_ba':[],\n",
    "            'train_mcc':[],\n",
    "            'train_cf': [],\n",
    "            'val_accuracy':[],\n",
    "            'val_f1':[],\n",
    "            'val_ba':[],\n",
    "            'val_mcc':[],\n",
    "            'val_cf': [],\n",
    "        }\n",
    "\n",
    "        for sampl in sampling:\n",
    "            for scaler, scaled in train_scaled.items():\n",
    "                fit = model.fit(scaled, y_train)\n",
    "                y_pred = fit.predict(scaled)\n",
    "                y_val_pred = fit.predict(X_val)\n",
    "\n",
    "\n",
    "                # calculate statistical metrics accuracy for training set\n",
    "                train_accuracy = metrics.accuracy_score(y_train, y_pred)\n",
    "                val_accuracy = metrics.accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "                if multiclass == True:\n",
    "                    # calculate statistical metrics for training set\n",
    "                    train_f1 = metrics.f1_score(y_train, y_pred, average = 'weighted')\n",
    "                    train_ba = metrics.balanced_accuracy_score(y_train, y_pred)\n",
    "                    train_mcc = metrics.matthews_corrcoef(y_train, y_pred)\n",
    "                    train_cf = metrics.confusion_matrix(y_train, y_pred)\n",
    "\n",
    "                    # calculate statistical metrics for val set\n",
    "                    val_f1 = metrics.f1_score(y_val, y_val_pred, average = 'weighted')\n",
    "                    val_ba = metrics.balanced_accuracy_score(y_val, y_val_pred)\n",
    "                    val_mcc = metrics.matthews_corrcoef(y_val, y_val_pred)\n",
    "                    val_cf = metrics.confusion_matrix(y_val, y_val_pred)\n",
    "                else:\n",
    "                    # calculate statistical metrics for training set\n",
    "                    train_f1 = metrics.f1_score(y_train, y_pred, average = 'binary')\n",
    "                    train_ba = metrics.balanced_accuracy_score(y_train, y_pred)\n",
    "                    train_mcc = metrics.matthews_corrcoef(y_train, y_pred)\n",
    "                    train_cf = metrics.confusion_matrix(y_train, y_pred)\n",
    "\n",
    "                    # calculate statistical metrics for val set\n",
    "                    val_f1 = metrics.f1_score(y_val, y_val_pred, average = 'binary')\n",
    "                    val_ba = metrics.balanced_accuracy_score(y_val, y_val_pred)\n",
    "                    val_mcc = metrics.matthews_corrcoef(y_val, y_val_pred)\n",
    "                    val_cf = metrics.confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "\n",
    "                output_dict['sampling'].append(sampl)\n",
    "                output_dict['scaling'].append(scaler)\n",
    "                # train metrics\n",
    "                output_dict['train_accuracy'].append(train_accuracy)\n",
    "                output_dict['train_f1'].append(train_f1)\n",
    "                output_dict['train_ba'].append(train_ba)\n",
    "                output_dict['train_mcc'].append(train_mcc)\n",
    "                output_dict['train_cf'].append(train_cf)\n",
    "                # val metrics\n",
    "                output_dict['val_accuracy'].append(val_accuracy)\n",
    "                output_dict['val_f1'].append(val_f1)\n",
    "                output_dict['val_ba'].append(val_ba)\n",
    "                output_dict['val_mcc'].append(val_mcc)\n",
    "                output_dict['val_cf'].append(val_cf)\n",
    "        return output_dict\n",
    "\n",
    "    \n",
    "    model_smote = model_(X_train, y_train, X_val, y_val, sampling = 'SMOTE', kernel=kernel, algorithm=algorithm, scaling=scaling, solver=solver, max_iter=max_iter)\n",
    "    model_under = model_(X_train, y_train, X_val, y_val, sampling = 'RandomUnderSampler', kernel=kernel, algorithm=algorithm, scaling=scaling, solver=solver, max_iter=max_iter)\n",
    "    model_over = model_(X_train, y_train, X_val, y_val, sampling = 'RandomOverSampler', kernel=kernel, algorithm=algorithm, scaling=scaling, solver=solver, max_iter=max_iter)\n",
    "    model_nosampling = model_(X_train, y_train, X_val, y_val, sampling = 'no_sampling', kernel=kernel, algorithm=algorithm, scaling=scaling, solver=solver, max_iter=max_iter)\n",
    "\n",
    "    df_model = []\n",
    "    for i in [model_smote, model_under, model_over, model_nosampling]:\n",
    "        df = pd.DataFrame.from_dict(i)\n",
    "        df_model.append(df)\n",
    "\n",
    "    df_find_model = pd.concat(df_model, ignore_index=True)\n",
    "    df_find_model = df_find_model.sort_values(by=['val_ba', 'val_mcc', 'train_ba', 'train_mcc'], ascending=False).round(3)\n",
    "    #df_find_model.to_csv('linreg_allo_rdkit_model_baseline.csv')\n",
    "\n",
    "    return df_find_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get new standardized and sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampled_scaled(X_train, y_train, \n",
    "            sampling = 'SMOTE',\n",
    "            scaling = True,\n",
    "            random_state=0):\n",
    "    '''\n",
    "    Find the best combination of sampling and\n",
    "    standardization methods as a baseline model.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "        X_train, y_train, X_val, y_val: np.array or pd.DataFrame or pd.Series\n",
    "            Training and validation data and its targts\n",
    "        sampling: str\n",
    "            sampling method you wish to use. Available are:\n",
    "            - smote\n",
    "            - random_over\n",
    "            - random_under\n",
    "        scaling: bool\n",
    "            scaling (standardization/normalization) of the data.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "        X_train, y_train, X_val, y_val: np.array or pd.DataFrame or pd.Series\n",
    "            Training data and its targets after sampled and scaled\n",
    "    '''\n",
    "\n",
    "    if type(sampling) == str:\n",
    "        sampling = [sampling]\n",
    "    if type(scaling) == str:\n",
    "        scaling = [scaling]\n",
    "\n",
    "    for i in sampling:\n",
    "        if i == 'random_under':\n",
    "            X_train, y_train  = RandomUnderSampler(random_state=random_state).fit_resample(X_train, y_train)\n",
    "        elif i == 'random_over':\n",
    "            X_train, y_train  = RandomOverSampler(random_state=random_state).fit_resample(X_train, y_train)\n",
    "        elif i == 'SMOTE':\n",
    "            X_train, y_train = SMOTE(random_state=random_state).fit_resample(X_train, y_train)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # scaling\n",
    "    for j in scaling:\n",
    "        if j == 'MaxAbsScaler':\n",
    "            X_train = preprocessing.MaxAbsScaler().fit_transform(X_train)\n",
    "        elif j == 'MinMaxScaler':\n",
    "            X_train = preprocessing.MinMaxScaler().fit_transform(X_train)\n",
    "        elif j == 'StandardScaler':\n",
    "            X_train = preprocessing.StandardScaler().fit_transform(X_train)\n",
    "        elif j == 'Normalizer':\n",
    "            X_train = preprocessing.Normalizer().fit_transform(X_train)\n",
    "        #elif j == 'MaxAbsScalerN':\n",
    "        #    X_train_NMAS = preprocessing.MaxAbsScaler().fit_transform(X_train_NORM)\n",
    "        #elif j == 'MinMaxScalerN':\n",
    "        #    X_train_NMMS = preprocessing.MinMaxScaler().fit_transform(X_train_NORM)\n",
    "        #elif j == 'StandardScalerN':\n",
    "        #    X_train_NSS = preprocessing.StandardScaler().fit_transform(X_train_NORM)\n",
    "        #elif j == 'NMaxAbsScaler':\n",
    "        #    X_train_MASNORM = preprocessing.Normalizer().fit_transform(X_train_MAS)\n",
    "        #elif j == 'NMinMaxScaler':\n",
    "        #    X_train_MMSNORM = preprocessing.Normalizer().fit_transform(X_train_MMS)\n",
    "        #elif j == 'NStandardScaler':\n",
    "        #    X_train_SSNORM = preprocessing.Normalizer().fit_transform(X_train_SS)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return X_train, y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation took 84.48786091804504 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_lbfgs = pd.DataFrame(find_model(X_train, y_train, X_val, y_val, \n",
    "                                      multiclass=True, \n",
    "                                      algorithm='LogisticRegression', \n",
    "                                      solver='lbfgs'))#.to_csv('da_lr_lbfgs.csv')\n",
    "end_time = time.time()\n",
    "duration_lbfgs = end_time-start_time\n",
    "print(f\"Operation took {duration_lbfgs} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lbfgs.to_csv('db_lr_lbfgs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>scaling</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_ba</th>\n",
       "      <th>train_mcc</th>\n",
       "      <th>train_cf</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_ba</th>\n",
       "      <th>val_mcc</th>\n",
       "      <th>val_cf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.176</td>\n",
       "      <td>[[3, 79, 0, 0, 0], [0, 2095, 0, 1, 0], [0, 171...</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.036</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [0, 38, 25, 635, 0], [0, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.046</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.030</td>\n",
       "      <td>[[0, 1, 0, 27, 0], [0, 136, 0, 562, 0], [0, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.029</td>\n",
       "      <td>[[28, 0, 0, 0, 0], [657, 41, 0, 0, 0], [56, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.688</td>\n",
       "      <td>[[42, 2, 5, 2, 1], [3, 38, 3, 3, 5], [0, 4, 40...</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.014</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [4, 0, 60, 634, 0], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.240</td>\n",
       "      <td>[[1898, 0, 96, 26, 76], [1222, 443, 170, 144, ...</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.023</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [0, 25, 0, 656, 17], [0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.046</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.024</td>\n",
       "      <td>[[0, 1, 0, 27, 0], [0, 150, 0, 548, 0], [0, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.010</td>\n",
       "      <td>[[0, 126, 1970, 0, 0], [132, 221, 1743, 0, 0],...</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.033</td>\n",
       "      <td>[[28, 0, 0, 0, 0], [677, 21, 0, 0, 0], [58, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.292</td>\n",
       "      <td>[[1986, 5, 89, 14, 2], [1268, 453, 152, 107, 1...</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.020</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [0, 19, 0, 0, 679], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.208</td>\n",
       "      <td>[[2063, 0, 5, 0, 28], [1622, 236, 50, 37, 151]...</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.017</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [2, 18, 0, 1, 677], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.044</td>\n",
       "      <td>[[0, 3, 49, 0, 0], [1, 7, 44, 0, 0], [0, 3, 49...</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.024</td>\n",
       "      <td>[[0, 0, 28, 0, 0], [5, 30, 663, 0, 0], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.207</td>\n",
       "      <td>[[2062, 0, 5, 0, 29], [1623, 236, 48, 35, 154]...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.015</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [2, 17, 0, 1, 678], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.210</td>\n",
       "      <td>[[43, 0, 8, 0, 1], [24, 12, 16, 0, 0], [27, 2,...</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.027</td>\n",
       "      <td>[[0, 0, 28, 0, 0], [5, 28, 665, 0, 0], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.208</td>\n",
       "      <td>[[42, 0, 9, 0, 1], [24, 12, 16, 0, 0], [26, 2,...</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.026</td>\n",
       "      <td>[[0, 0, 28, 0, 0], [5, 27, 666, 0, 0], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.087</td>\n",
       "      <td>[[1999, 55, 6, 2, 34], [1658, 173, 3, 3, 259],...</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.009</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [0, 7, 7, 1, 683], [0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.575</td>\n",
       "      <td>[[1609, 149, 140, 146, 52], [374, 758, 356, 33...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.522</td>\n",
       "      <td>[[1546, 155, 179, 129, 87], [348, 733, 388, 32...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.516</td>\n",
       "      <td>[[1534, 167, 159, 132, 104], [364, 702, 355, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.514</td>\n",
       "      <td>[[1534, 169, 159, 129, 105], [367, 707, 348, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.512</td>\n",
       "      <td>[[1566, 107, 166, 158, 99], [357, 686, 389, 35...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.454</td>\n",
       "      <td>[[1385, 179, 144, 158, 230], [344, 670, 393, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.450</td>\n",
       "      <td>[[1411, 179, 144, 158, 204], [345, 675, 389, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.115</td>\n",
       "      <td>[[2, 80, 0, 0, 0], [2, 2093, 0, 1, 0], [1, 169...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>none</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[2096, 0, 0, 0, 0], [2096, 0, 0, 0, 0], [2096...</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[28, 0, 0, 0, 0], [698, 0, 0, 0, 0], [58, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 0, 52, 0], [0, 0, 0, 52, 0], [0, 0, 0,...</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [0, 0, 0, 698, 0], [0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[2096, 0, 0, 0, 0], [2096, 0, 0, 0, 0], [2096...</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[28, 0, 0, 0, 0], [698, 0, 0, 0, 0], [58, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>none</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[82, 0, 0, 0, 0], [2096, 0, 0, 0, 0], [174, 0...</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[28, 0, 0, 0, 0], [698, 0, 0, 0, 0], [58, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.180</td>\n",
       "      <td>[[2018, 0, 58, 0, 20], [1389, 257, 355, 40, 55...</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.017</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [1, 34, 0, 663, 0], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.187</td>\n",
       "      <td>[[2044, 0, 32, 0, 20], [1380, 256, 358, 40, 62...</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.016</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [1, 33, 0, 664, 0], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.045</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 173...</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [2, 696, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.450</td>\n",
       "      <td>[[1450, 162, 164, 158, 162], [380, 686, 368, 3...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [3, 695, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.045</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 173...</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [4, 694, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [11, 687, 0, 0, 0], [0, 58,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.281</td>\n",
       "      <td>[[44, 0, 2, 5, 1], [27, 12, 4, 3, 6], [26, 1, ...</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [0, 0, 41, 0, 657], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [18, 680, 0, 0, 0], [0, 58,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.477</td>\n",
       "      <td>[[36, 4, 3, 5, 4], [4, 26, 6, 6, 10], [5, 8, 2...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [14, 0, 19, 665, 0], [0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.487</td>\n",
       "      <td>[[35, 4, 3, 6, 4], [4, 30, 6, 3, 9], [5, 8, 23...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [12, 0, 20, 666, 0], [0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.338</td>\n",
       "      <td>[[36, 5, 4, 4, 3], [6, 25, 3, 4, 14], [13, 10,...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [51, 0, 0, 647, 0], [2, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.358</td>\n",
       "      <td>[[38, 5, 4, 4, 1], [9, 25, 4, 2, 12], [14, 10,...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [46, 0, 0, 652, 0], [2, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.426</td>\n",
       "      <td>[[34, 6, 3, 5, 4], [7, 30, 3, 3, 9], [8, 10, 2...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [29, 0, 0, 669, 0], [1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.394</td>\n",
       "      <td>[[1338, 225, 140, 239, 154], [394, 602, 343, 3...</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [36, 662, 0, 0, 0], [1, 57,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [36, 662, 0, 0, 0], [1, 57,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.372</td>\n",
       "      <td>[[1254, 280, 176, 286, 100], [387, 614, 334, 3...</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [38, 660, 0, 0, 0], [1, 57,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.475</td>\n",
       "      <td>[[1484, 160, 169, 168, 115], [369, 741, 311, 3...</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>[[1, 27, 0, 0, 0], [95, 586, 0, 0, 17], [7, 48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.467</td>\n",
       "      <td>[[1436, 156, 212, 172, 120], [338, 733, 328, 3...</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>[[1, 27, 0, 0, 0], [109, 578, 0, 0, 11], [10, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sampling                      scaling  train_accuracy  train_f1  \\\n",
       "40         no_sampling  Normalizer + StandardScaler           0.836     0.767   \n",
       "39         no_sampling    Normalizer + MinMaxScaler           0.830     0.754   \n",
       "37         no_sampling                   Normalizer           0.830     0.753   \n",
       "14  RandomUnderSampler               StandardScaler           0.750     0.750   \n",
       "29   RandomOverSampler  Normalizer + StandardScaler           0.351     0.324   \n",
       "38         no_sampling    Normalizer + MaxAbsScaler           0.830     0.754   \n",
       "26   RandomOverSampler                   Normalizer           0.204     0.098   \n",
       "7                SMOTE  Normalizer + StandardScaler           0.377     0.356   \n",
       "5                SMOTE    Normalizer + MaxAbsScaler           0.294     0.232   \n",
       "15  RandomUnderSampler                   Normalizer           0.215     0.106   \n",
       "6                SMOTE    Normalizer + MinMaxScaler           0.293     0.231   \n",
       "16  RandomUnderSampler    Normalizer + MaxAbsScaler           0.342     0.307   \n",
       "17  RandomUnderSampler    Normalizer + MinMaxScaler           0.342     0.307   \n",
       "4                SMOTE                   Normalizer           0.238     0.142   \n",
       "3                SMOTE               StandardScaler           0.658     0.645   \n",
       "10               SMOTE  StandardScaler + Normalizer           0.616     0.605   \n",
       "2                SMOTE                 MinMaxScaler           0.611     0.597   \n",
       "1                SMOTE                 MaxAbsScaler           0.609     0.595   \n",
       "25   RandomOverSampler               StandardScaler           0.606     0.591   \n",
       "24   RandomOverSampler                 MinMaxScaler           0.560     0.547   \n",
       "23   RandomOverSampler                 MaxAbsScaler           0.558     0.544   \n",
       "36         no_sampling               StandardScaler           0.832     0.761   \n",
       "0                SMOTE                         none           0.200     0.067   \n",
       "11  RandomUnderSampler                         none           0.200     0.067   \n",
       "22   RandomOverSampler                         none           0.200     0.067   \n",
       "33         no_sampling                         none           0.032     0.002   \n",
       "27   RandomOverSampler    Normalizer + MaxAbsScaler           0.300     0.244   \n",
       "28   RandomOverSampler    Normalizer + MinMaxScaler           0.305     0.247   \n",
       "34         no_sampling                 MaxAbsScaler           0.830     0.754   \n",
       "32   RandomOverSampler  StandardScaler + Normalizer           0.558     0.546   \n",
       "35         no_sampling                 MinMaxScaler           0.830     0.754   \n",
       "43         no_sampling  StandardScaler + Normalizer           0.830     0.753   \n",
       "18  RandomUnderSampler  Normalizer + StandardScaler           0.392     0.382   \n",
       "41         no_sampling    MaxAbsScaler + Normalizer           0.830     0.753   \n",
       "12  RandomUnderSampler                 MaxAbsScaler           0.581     0.576   \n",
       "13  RandomUnderSampler                 MinMaxScaler           0.588     0.584   \n",
       "19  RandomUnderSampler    MaxAbsScaler + Normalizer           0.465     0.454   \n",
       "20  RandomUnderSampler    MinMaxScaler + Normalizer           0.481     0.466   \n",
       "21  RandomUnderSampler  StandardScaler + Normalizer           0.538     0.534   \n",
       "30   RandomOverSampler    MaxAbsScaler + Normalizer           0.512     0.498   \n",
       "42         no_sampling    MinMaxScaler + Normalizer           0.830     0.753   \n",
       "31   RandomOverSampler    MinMaxScaler + Normalizer           0.495     0.484   \n",
       "8                SMOTE    MaxAbsScaler + Normalizer           0.577     0.565   \n",
       "9                SMOTE    MinMaxScaler + Normalizer           0.572     0.561   \n",
       "\n",
       "    train_ba  train_mcc                                           train_cf  \\\n",
       "40     0.231      0.176  [[3, 79, 0, 0, 0], [0, 2095, 0, 1, 0], [0, 171...   \n",
       "39     0.202      0.046  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "37     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "14     0.750      0.688  [[42, 2, 5, 2, 1], [3, 38, 3, 3, 5], [0, 4, 40...   \n",
       "29     0.351      0.240  [[1898, 0, 96, 26, 76], [1222, 443, 170, 144, ...   \n",
       "38     0.202      0.046  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "26     0.204      0.010  [[0, 126, 1970, 0, 0], [132, 221, 1743, 0, 0],...   \n",
       "7      0.377      0.292  [[1986, 5, 89, 14, 2], [1268, 453, 152, 107, 1...   \n",
       "5      0.294      0.208  [[2063, 0, 5, 0, 28], [1622, 236, 50, 37, 151]...   \n",
       "15     0.215      0.044  [[0, 3, 49, 0, 0], [1, 7, 44, 0, 0], [0, 3, 49...   \n",
       "6      0.293      0.207  [[2062, 0, 5, 0, 29], [1623, 236, 48, 35, 154]...   \n",
       "16     0.342      0.210  [[43, 0, 8, 0, 1], [24, 12, 16, 0, 0], [27, 2,...   \n",
       "17     0.342      0.208  [[42, 0, 9, 0, 1], [24, 12, 16, 0, 0], [26, 2,...   \n",
       "4      0.238      0.087  [[1999, 55, 6, 2, 34], [1658, 173, 3, 3, 259],...   \n",
       "3      0.658      0.575  [[1609, 149, 140, 146, 52], [374, 758, 356, 33...   \n",
       "10     0.616      0.522  [[1546, 155, 179, 129, 87], [348, 733, 388, 32...   \n",
       "2      0.611      0.516  [[1534, 167, 159, 132, 104], [364, 702, 355, 3...   \n",
       "1      0.609      0.514  [[1534, 169, 159, 129, 105], [367, 707, 348, 3...   \n",
       "25     0.606      0.512  [[1566, 107, 166, 158, 99], [357, 686, 389, 35...   \n",
       "24     0.560      0.454  [[1385, 179, 144, 158, 230], [344, 670, 393, 3...   \n",
       "23     0.558      0.450  [[1411, 179, 144, 158, 204], [345, 675, 389, 3...   \n",
       "36     0.219      0.115  [[2, 80, 0, 0, 0], [2, 2093, 0, 1, 0], [1, 169...   \n",
       "0      0.200      0.000  [[2096, 0, 0, 0, 0], [2096, 0, 0, 0, 0], [2096...   \n",
       "11     0.200      0.000  [[0, 0, 0, 52, 0], [0, 0, 0, 52, 0], [0, 0, 0,...   \n",
       "22     0.200      0.000  [[2096, 0, 0, 0, 0], [2096, 0, 0, 0, 0], [2096...   \n",
       "33     0.200      0.000  [[82, 0, 0, 0, 0], [2096, 0, 0, 0, 0], [174, 0...   \n",
       "27     0.300      0.180  [[2018, 0, 58, 0, 20], [1389, 257, 355, 40, 55...   \n",
       "28     0.305      0.187  [[2044, 0, 32, 0, 20], [1380, 256, 358, 40, 62...   \n",
       "34     0.201      0.045  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 173...   \n",
       "32     0.558      0.450  [[1450, 162, 164, 158, 162], [380, 686, 368, 3...   \n",
       "35     0.201      0.045  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 173...   \n",
       "43     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "18     0.392      0.281  [[44, 0, 2, 5, 1], [27, 12, 4, 3, 6], [26, 1, ...   \n",
       "41     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "12     0.581      0.477  [[36, 4, 3, 5, 4], [4, 26, 6, 6, 10], [5, 8, 2...   \n",
       "13     0.588      0.487  [[35, 4, 3, 6, 4], [4, 30, 6, 3, 9], [5, 8, 23...   \n",
       "19     0.465      0.338  [[36, 5, 4, 4, 3], [6, 25, 3, 4, 14], [13, 10,...   \n",
       "20     0.481      0.358  [[38, 5, 4, 4, 1], [9, 25, 4, 2, 12], [14, 10,...   \n",
       "21     0.538      0.426  [[34, 6, 3, 5, 4], [7, 30, 3, 3, 9], [8, 10, 2...   \n",
       "30     0.512      0.394  [[1338, 225, 140, 239, 154], [394, 602, 343, 3...   \n",
       "42     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "31     0.495      0.372  [[1254, 280, 176, 286, 100], [387, 614, 334, 3...   \n",
       "8      0.577      0.475  [[1484, 160, 169, 168, 115], [369, 741, 311, 3...   \n",
       "9      0.572      0.467  [[1436, 156, 212, 172, 120], [338, 733, 328, 3...   \n",
       "\n",
       "    val_accuracy  val_f1  val_ba  val_mcc  \\\n",
       "40         0.096   0.096   0.215    0.036   \n",
       "39         0.204   0.268   0.215    0.030   \n",
       "37         0.082   0.094   0.212    0.029   \n",
       "14         0.053   0.011   0.211    0.014   \n",
       "29         0.077   0.063   0.209    0.023   \n",
       "38         0.219   0.290   0.209    0.024   \n",
       "26         0.058   0.051   0.206    0.033   \n",
       "7          0.043   0.045   0.205    0.020   \n",
       "5          0.042   0.042   0.205    0.017   \n",
       "15         0.103   0.077   0.205    0.024   \n",
       "6          0.040   0.040   0.205    0.015   \n",
       "16         0.101   0.073   0.205    0.027   \n",
       "17         0.100   0.071   0.204    0.026   \n",
       "4          0.029   0.017   0.202    0.009   \n",
       "3          0.829   0.751   0.200    0.000   \n",
       "10         0.829   0.751   0.200    0.000   \n",
       "2          0.829   0.751   0.200    0.000   \n",
       "1          0.829   0.751   0.200    0.000   \n",
       "25         0.829   0.751   0.200    0.000   \n",
       "24         0.829   0.751   0.200    0.000   \n",
       "23         0.829   0.751   0.200    0.000   \n",
       "36         0.829   0.751   0.200    0.000   \n",
       "0          0.033   0.002   0.200    0.000   \n",
       "11         0.049   0.005   0.200    0.000   \n",
       "22         0.033   0.002   0.200    0.000   \n",
       "33         0.033   0.002   0.200    0.000   \n",
       "27         0.087   0.081   0.200    0.017   \n",
       "28         0.086   0.079   0.200    0.016   \n",
       "34         0.827   0.750   0.199   -0.013   \n",
       "32         0.825   0.750   0.199   -0.016   \n",
       "35         0.824   0.750   0.199   -0.000   \n",
       "43         0.816   0.746   0.197   -0.008   \n",
       "18         0.021   0.003   0.195   -0.008   \n",
       "41         0.808   0.742   0.195   -0.013   \n",
       "12         0.048   0.006   0.194   -0.009   \n",
       "13         0.048   0.006   0.194   -0.009   \n",
       "19         0.046   0.005   0.190   -0.007   \n",
       "20         0.046   0.005   0.190   -0.008   \n",
       "21         0.046   0.004   0.190   -0.012   \n",
       "30         0.786   0.732   0.190   -0.030   \n",
       "42         0.786   0.732   0.190   -0.030   \n",
       "31         0.784   0.730   0.189   -0.032   \n",
       "8          0.697   0.689   0.175   -0.037   \n",
       "9          0.688   0.684   0.173   -0.037   \n",
       "\n",
       "                                               val_cf  \n",
       "40  [[0, 0, 0, 28, 0], [0, 38, 25, 635, 0], [0, 1,...  \n",
       "39  [[0, 1, 0, 27, 0], [0, 136, 0, 562, 0], [0, 13...  \n",
       "37  [[28, 0, 0, 0, 0], [657, 41, 0, 0, 0], [56, 2,...  \n",
       "14  [[0, 0, 0, 28, 0], [4, 0, 60, 634, 0], [0, 0, ...  \n",
       "29  [[0, 0, 0, 28, 0], [0, 25, 0, 656, 17], [0, 0,...  \n",
       "38  [[0, 1, 0, 27, 0], [0, 150, 0, 548, 0], [0, 14...  \n",
       "26  [[28, 0, 0, 0, 0], [677, 21, 0, 0, 0], [58, 0,...  \n",
       "7   [[0, 0, 0, 0, 28], [0, 19, 0, 0, 679], [0, 0, ...  \n",
       "5   [[0, 0, 0, 0, 28], [2, 18, 0, 1, 677], [0, 0, ...  \n",
       "15  [[0, 0, 28, 0, 0], [5, 30, 663, 0, 0], [0, 1, ...  \n",
       "6   [[0, 0, 0, 0, 28], [2, 17, 0, 1, 678], [0, 0, ...  \n",
       "16  [[0, 0, 28, 0, 0], [5, 28, 665, 0, 0], [0, 1, ...  \n",
       "17  [[0, 0, 28, 0, 0], [5, 27, 666, 0, 0], [0, 1, ...  \n",
       "4   [[0, 0, 0, 0, 28], [0, 7, 7, 1, 683], [0, 0, 0...  \n",
       "3   [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "10  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "2   [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "1   [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "25  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "24  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "23  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "36  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "0   [[28, 0, 0, 0, 0], [698, 0, 0, 0, 0], [58, 0, ...  \n",
       "11  [[0, 0, 0, 28, 0], [0, 0, 0, 698, 0], [0, 0, 0...  \n",
       "22  [[28, 0, 0, 0, 0], [698, 0, 0, 0, 0], [58, 0, ...  \n",
       "33  [[28, 0, 0, 0, 0], [698, 0, 0, 0, 0], [58, 0, ...  \n",
       "27  [[0, 0, 0, 28, 0], [1, 34, 0, 663, 0], [0, 1, ...  \n",
       "28  [[0, 0, 0, 28, 0], [1, 33, 0, 664, 0], [0, 1, ...  \n",
       "34  [[0, 28, 0, 0, 0], [2, 696, 0, 0, 0], [0, 58, ...  \n",
       "32  [[0, 28, 0, 0, 0], [3, 695, 0, 0, 0], [0, 58, ...  \n",
       "35  [[0, 28, 0, 0, 0], [4, 694, 0, 0, 0], [0, 58, ...  \n",
       "43  [[0, 28, 0, 0, 0], [11, 687, 0, 0, 0], [0, 58,...  \n",
       "18  [[0, 0, 0, 0, 28], [0, 0, 41, 0, 657], [0, 0, ...  \n",
       "41  [[0, 28, 0, 0, 0], [18, 680, 0, 0, 0], [0, 58,...  \n",
       "12  [[0, 0, 0, 28, 0], [14, 0, 19, 665, 0], [0, 0,...  \n",
       "13  [[0, 0, 0, 28, 0], [12, 0, 20, 666, 0], [0, 0,...  \n",
       "19  [[0, 0, 0, 28, 0], [51, 0, 0, 647, 0], [2, 0, ...  \n",
       "20  [[0, 0, 0, 28, 0], [46, 0, 0, 652, 0], [2, 0, ...  \n",
       "21  [[0, 0, 0, 28, 0], [29, 0, 0, 669, 0], [1, 0, ...  \n",
       "30  [[0, 28, 0, 0, 0], [36, 662, 0, 0, 0], [1, 57,...  \n",
       "42  [[0, 28, 0, 0, 0], [36, 662, 0, 0, 0], [1, 57,...  \n",
       "31  [[0, 28, 0, 0, 0], [38, 660, 0, 0, 0], [1, 57,...  \n",
       "8   [[1, 27, 0, 0, 0], [95, 586, 0, 0, 17], [7, 48...  \n",
       "9   [[1, 27, 0, 0, 0], [109, 578, 0, 0, 11], [10, ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lbfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>scaling</th>\n",
       "      <th>value</th>\n",
       "      <th>set</th>\n",
       "      <th>met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.767</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.754</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.753</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Random Undersampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.750</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Random Oversampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.324</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Random Oversampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>val</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>val</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Random Oversampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>val</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>val</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>val</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                sampling                      scaling  value    set  met\n",
       "44           No Sampling  Normalizer + StandardScaler  0.767  train   f1\n",
       "45           No Sampling    Normalizer + MinMaxScaler  0.754  train   f1\n",
       "46           No Sampling                   Normalizer  0.753  train   f1\n",
       "47   Random Undersampler               StandardScaler  0.750  train   f1\n",
       "48    Random Oversampler  Normalizer + StandardScaler  0.324  train   f1\n",
       "..                   ...                          ...    ...    ...  ...\n",
       "347   Random Oversampler    MaxAbsScaler + Normalizer -0.030    val  mcc\n",
       "348          No Sampling    MinMaxScaler + Normalizer -0.030    val  mcc\n",
       "349   Random Oversampler    MinMaxScaler + Normalizer -0.032    val  mcc\n",
       "350                SMOTE    MaxAbsScaler + Normalizer -0.037    val  mcc\n",
       "351                SMOTE    MinMaxScaler + Normalizer -0.037    val  mcc\n",
       "\n",
       "[264 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lbfgs_melted = pd.melt(model_lbfgs, id_vars=['sampling', 'scaling'], value_vars=['train_accuracy', 'train_f1', 'train_ba', 'train_mcc', 'val_accuracy', 'val_f1', 'val_ba', 'val_mcc',], var_name='metrics', value_name='value')\n",
    "model_lbfgs_melted = model_lbfgs_melted.drop(model_lbfgs_melted[model_lbfgs_melted['metrics'].isin(['train_accuracy', 'val_accuracy'])].index)\n",
    "model_lbfgs_melted['set'] = np.where(model_lbfgs_melted['metrics'].str.startswith('train'), 'train', 'val')\n",
    "model_lbfgs_melted['met'] = np.where(model_lbfgs_melted['metrics'].str.endswith('f1'), 'f1', \n",
    "                                     np.where(model_lbfgs_melted['metrics'].str.endswith('ba'), 'ba', 'mcc'))\n",
    "model_lbfgs_melted['sampling'] = np.where(model_lbfgs_melted['sampling'].str.startswith('RandomOver'), 'Random Oversampler', \n",
    "                                          np.where(model_lbfgs_melted['sampling'].str.startswith('RandomUnder'), 'Random Undersampler', \n",
    "                                                   np.where(model_lbfgs_melted['sampling'].str.startswith('SMOTE'), 'SMOTE', 'No Sampling'\n",
    "                                          )))\n",
    "model_lbfgs_melted = model_lbfgs_melted.drop(columns=['metrics'])\n",
    "model_lbfgs_melted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zh/6tz72s157dsdk3fzz1x9rvfc0000gn/T/ipykernel_93117/3265252411.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  model_lbfgs_melted[model_lbfgs_melted['met']=='ba'][model_lbfgs_melted['set']=='train'].value.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6120681818181818"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lbfgs_melted[model_lbfgs_melted['met']=='ba'][model_lbfgs_melted['set']=='train'].value.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zh/6tz72s157dsdk3fzz1x9rvfc0000gn/T/ipykernel_93117/787339492.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  model_lbfgs_melted[model_lbfgs_melted['met']=='ba'][model_lbfgs_melted['set']=='val'].value.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5360227272727273"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lbfgs_melted[model_lbfgs_melted['met']=='ba'][model_lbfgs_melted['set']=='val'].value.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.violinplot(data=model_lbfgs_melted[model_lbfgs_melted['met']=='mcc'], \n",
    "               x='sampling', y='value', hue='set',)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('MCC Values for Baseline Model, lbfgs solver')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHFCAYAAAAaD0bAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC6Y0lEQVR4nOydd3wUZf7HPzOzLb03UukdpDcRFAFBEFHAiqCop+h5Vu44fyfKeccpiih3WCminIIiHgJKF1AQRQEbvYWSQnrfNs/vj8lMdpNNsruZbdnv+/XaV7KzzzzzbJv57LdyjDEGgiAIgiCIIIL39QIIgiAIgiC8DQkggiAIgiCCDhJABEEQBEEEHSSACIIgCIIIOkgAEQRBEAQRdJAAIgiCIAgi6CABRBAEQRBE0EECiCAIgiCIoIMEEEEQBEEQQQcJIKLFrFy5EhzH2d0SEhIwcuRIbNy4sdH9CgoKoNfrwXEcDh486NSxJk+ejJCQEJSUlDQ65q677oJWq0VeXp7Tz4HjODz//PNOj/c2S5YsQYcOHaDT6cBxXJPPv6W4+356k5EjR2LkyJF223z1Hn799dfK67Ry5UqHY6677jpwHIesrCxVj52VlYWZM2e6tW9LXq+ZM2c2eC4cx+HRRx91av8dO3agf//+CAsLA8dx+Pzzz91ahy/x93MG0TwkgAjVWLFiBfbv3499+/bhnXfegSAImDhxIr744guH4z/44AOYTCYAwLJly5w6xqxZs1BTU4P//ve/Dh8vLS3F+vXrMWHCBCQlJbn3RPyMw4cP47HHHsO1116LnTt3Yv/+/YiIiPD4cV19P33N/v37cf/99/vs+BEREQ4/x2fPnsXXX3+NyMhIH6zK/2CMYdq0adBqtdiwYQP279+PESNG+HpZRBBCAohQjR49emDw4MEYMmQIJk+ejI0bN0Kv1+Ojjz5yOH758uVITEzEgAED8NFHH6G6urrZY4wbNw5t2rTB8uXLHT4uzzNr1qwWPRd/4rfffgMAPPDAA7j66qsxePBgCILQojmrqqqaHePq++lrBg8ejLS0NJ8d/7bbbsM333yDkydP2m1fvnw5UlNTMWzYMB+tzL+4fPkyioqKMHnyZIwaNQqDBw9GTEyMr5cVEJjNZlgsFl8vo9VAAojwGAaDATqdDlqttsFjBw4cwK+//orp06fjgQceQGlpKdatW9fsnIIgYMaMGfjxxx/xyy+/NHh8xYoVSElJwbhx43DlyhXMnj0b3bp1Q3h4OBITE3Hddddh7969zR7n+eefB8dxDbbL7qFz587ZbV+zZg2GDBmCsLAwhIeHY+zYsTh06JDdmDNnzuD2229HmzZtoNfrkZSUhFGjRuHw4cONrmPkyJG4++67AQCDBg0Cx3F2Lo/ly5ejd+/eMBgMiI2NxeTJk3H06FG7OWbOnInw8HD88ssvGDNmDCIiIjBq1KhmX4P6NPZ+vvDCCxg0aBBiY2MRGRmJvn37YtmyZajfZ3nnzp0YOXIk4uLiEBISgoyMDNx66612YsxkMuHFF19Ely5doNfrkZCQgHvvvRdXrlxpdn31XRLye7Vr1y48/PDDiI+PR1xcHG655RZcvny5wf7OvIdNMXr0aKSnp9uJc1EU8f7772PGjBng+Yan25qaGsydOxdt27aFTqdDamoqHnnkkQYuTrPZjDlz5iA5ORmhoaG4+uqr8f333ztcR25uLv7whz8gLS0NOp0Obdu2xQsvvOC1C+fbb7+NTp06Qa/Xo1u3bvj444+Vx55//nlFpP75z39u4Bb83//+h169ekGv16Ndu3Z4/fXXHX4XP/nkEwwaNAhRUVEIDQ1Fu3btcN999zW7Nmf2y87Oxt13343ExETo9Xp07doVr776KkRRbHTeI0eOgOM4hxbAL7/8EhzHYcOGDcq2kydP4s4777Q7xn/+8x+7/WTX6gcffICnnnoKqamp0Ov1OHXqVLPPk3ASRhAtZMWKFQwA++6775jZbGYmk4lduHCBPfbYY4znefbVV1812OeBBx5gANhvv/3GysrKWGhoKBs5cqRTxzt58iTjOI49/vjjdtt/++03BoD95S9/YYwxduzYMfbwww+zjz/+mH399dds48aNbNasWYznebZr1y67fQGwefPmKffnzZvHHH095Od69uxZZds//vEPxnEcu++++9jGjRvZZ599xoYMGcLCwsLYb7/9pozr3Lkz69ChA/vggw/Y7t272bp169hTTz3VYC31n9P//d//MQBsxYoVbP/+/ezUqVOMMcb++c9/MgDsjjvuYJs2bWKrVq1i7dq1Y1FRUezEiRPKHDNmzGBarZZlZWWxBQsWsB07drAtW7Y0ekxX38+ZM2eyZcuWsW3btrFt27axv//97ywkJIS98MILypizZ88yg8HARo8ezT7//HP29ddfs9WrV7Pp06ez4uJixhhjVquV3XDDDSwsLIy98MILbNu2bey9995jqamprFu3bqyqqkqZb8SIEWzEiBF266j/HsrPo127duyPf/wj27JlC3vvvfdYTEwMu/baa+32dfY9dMSuXbsYAPbJJ5+wv/3tb6xNmzbMYrEwxhj78ssvGcdx7NSpU+zGG29kmZmZyn6iKLKxY8cyjUbD/va3v7GtW7eyV155hYWFhbE+ffqwmpoau/eQ4zj2zDPPsK1bt7JFixax1NRUFhkZyWbMmKGMy8nJYenp6SwzM5O9/fbbbPv27ezvf/870+v1bObMmU2+Xq4wY8YMu+ciz5eens66devGPvroI7ZhwwZ2ww03KK8NY4xduHCBffbZZwwA++Mf/8j279/PfvrpJ+W14nmejRw5kq1fv5598sknbNCgQSwrK8vuu7hv3z7GcRy7/fbb2ebNm9nOnTvZihUr2PTp05tcszP75efns9TUVJaQkMDeeust9tVXX7FHH32UAWAPP/xwk69fnz592LBhwxocd9q0aSwxMZGZzWbGmPSdjoqKYj179mSrVq1iW7duZU899RTjeZ49//zzyn7y5yo1NZVNmTKFbdiwgW3cuJEVFhY2+TwJ5yEBRLQY+UJT/6bX69nSpUsbjK+srGSRkZFs8ODByjb5BC9f3JtjxIgRLD4+nplMJmXbU089xQDYXfxtsVgszGw2s1GjRrHJkyfbPeauAMrOzmYajYb98Y9/tBtXXl7OkpOT2bRp0xhjjBUUFDAAbPHixU49P0fH/OGHH5RtxcXFLCQkhI0fP95ubHZ2NtPr9ezOO+9Uts2YMYMBYMuXL3fpeM6+n7ZYrVZmNpvZ/PnzWVxcHBNFkTHG2KeffsoAsMOHDze670cffcQAsHXr1tlt/+GHHxgAu2O7IoBmz55tN+7ll19mAFhOTg5jzPn3sDFsBdCZM2cYx3Fs48aNjDHGpk6dqgj7+gLoq6++YgDYyy+/bDffmjVrGAD2zjvvMMYYO3r0KAPAnnjiCbtxq1evZgDsBNAf/vAHFh4ezs6fP2839pVXXlF+cDT2erlCYwIoJCSE5ebmKtssFgvr0qUL69Chg7Lt7NmzDABbuHCh3f4DBgxg6enpzGg0KtvKy8tZXFyc3XdRfi4lJSUurdmZ/f7yl78wAOzAgQN22x9++GHGcRw7fvy43fO1ff3eeOMNBsBuTFFREdPr9eypp55Sto0dO5alpaWx0tJSu2M8+uijzGAwsKKiIsZY3efqmmuucel5Es5DLjBCNVatWoUffvgBP/zwA7788kvMmDEDjzzyCP7973/bjVu7di3KysrsTM/33XcfGGNYsWKFU8eaNWsWCgoKFLOyxWLBhx9+iOHDh6Njx47KuLfeegt9+/aFwWCARqOBVqvFjh07GriJ3GXLli2wWCy45557YLFYlJvBYMCIESPw9ddfAwBiY2PRvn17LFy4EIsWLcKhQ4eaNKk3x/79+1FdXd0gAyg9PR3XXXcdduzY0WCfW2+91aVjOPt+7ty5E9dffz2ioqIgCAK0Wi2ee+45FBYWIj8/HwBw1VVXQafT4cEHH8T777+PM2fONDjexo0bER0djYkTJ9q9lldddRWSk5OV19JVbrrpJrv7vXr1AgCcP38egPPvoTO0bdsWI0eOxPLly1FYWIj//e9/jbpmdu7cCQAN3sOpU6ciLCxMeQ937doFQMputGXatGnQaDR22zZu3Ihrr70Wbdq0sXsu48aNAwDs3r3b6efiDqNGjbJLPhAEAbfddhtOnTqFixcvNrpfZWUlDh48iJtvvhk6nU7ZHh4ejokTJ9qNHTBgAADp+a9duxaXLl1yam3O7Ldz505069YNAwcOtNs+c+ZMMMaU98wRd911F/R6vV0m4EcffQSj0Yh7770XgOTy3LFjByZPnozQ0FC792j8+PGoqanBd999Zzevq99bwnlIABGq0bVrV/Tv3x/9+/fHDTfcgLfffhtjxozBnDlz7GIali1bBoPBgBtuuAElJSUoKSlBr169kJWVhZUrV8JqtTZ7rClTpiAqKkoRTJs3b0ZeXp5d8POiRYvw8MMPY9CgQVi3bh2+++47/PDDD7jhhhucCrh2BjnVfsCAAdBqtXa3NWvWoKCgAIAUn7Jjxw6MHTsWL7/8Mvr27YuEhAQ89thjKC8vd/m4hYWFAICUlJQGj7Vp00Z5XCY0NNTlLCRn3s/vv/8eY8aMAQC8++67+Pbbb/HDDz/g2WefBQDldW7fvj22b9+OxMREPPLII2jfvj3at2+P119/XTleXl4eSkpKlDgj21tubq7yWrpKXFyc3X29Xm+3NmffQ2eZNWsWvvjiCyxatAghISGYMmWKw3GFhYXQaDRISEiw285xHJKTk5X3UP6bnJxsN06j0TR4bnl5efjiiy8aPI/u3bsDgNuvobPUX6PttvqfSVuKi4vBGHOYuVl/2zXXXIPPP/9cEa1paWno0aNHs8H5zuxXWFjY6HequecQGxuLm266CatWrVLOYStXrsTAgQOV17+wsBAWiwVLlixp8B6NHz8eQMP3yNF6CHXQND+EINynV69e2LJlC06cOIGBAwfixIkT+OabbwAAGRkZDvfZsmWLcjJojJCQENxxxx149913kZOTg+XLlyMiIgJTp05Vxnz44YcYOXIk3nzzTbt9nREcBoMBAGA0GpULJtDw5BQfHw8A+PTTT5GZmdnknJmZmUqQ5IkTJ7B27Vo8//zzMJlMeOutt5pdky3yhS8nJ6fBY5cvX1bWJeMooNsd6r+fH3/8MbRaLTZu3Ki8ZgAc1nUZPnw4hg8fDqvVioMHD2LJkiV4/PHHkZSUhNtvv10JUv7qq68cHttTqf+uvIfOcMstt+CRRx7Bv/71LzzwwAMICQlxOC4uLg4WiwVXrlyxE0GMMeTm5ioWC/m9zs3NRWpqqjLOYrE0uCDHx8ejV69e+Mc//uHwmPKF3FPk5uY2uq2+WLMlJiYGHMc5rN3laM5JkyZh0qRJMBqN+O6777BgwQLceeedyMrKwpAhQxo9TnP7xcXFNfqdAtDge1Wfe++9F5988gm2bduGjIwM/PDDD3bnn5iYGAiCgOnTp+ORRx5xOEfbtm3t7qv13SUaQgKI8ChyhpN8gpcFwLvvvosOHTrYja2ursakSZOwfPnyZgUQIP3Sfuutt7Bw4UJs3rwZM2fORGhoqPI4x3F24gUAfv75Z+zfvx/p6elNzi1npvz888/KhQhAgxo4Y8eOhUajwenTp10yVXfq1An/93//h3Xr1uGnn35yej+ZIUOGICQkBB9++KGd6Lt48SJ27tzZqNWhpdR/PzmOg0ajsUvLr66uxgcffNDoHIIgYNCgQejSpQtWr16Nn376CbfffjsmTJiAjz/+GFarFYMGDfLI+h3h7nvYGCEhIXjuueewZ88ePPzww42OGzVqFF5++WV8+OGHeOKJJ5Tt69atQ2VlpZKpJxd8XL16Nfr166eMW7t2bYPMrgkTJmDz5s1o3769T1LLd+zYgby8PMVqY7VasWbNGrRv377JEgVhYWHo378/Pv/8c7zyyiuKG6yioqLJ4pt6vR4jRoxAdHQ0tmzZgkOHDjUpgJrbb9SoUViwYAF++ukn9O3bVxm/atUqcByHa6+9tsl5x4wZg9TUVKxYsQIZGRkwGAy44447lMdDQ0Nx7bXX4tChQ+jVq5edu4/wPiSACNX49ddflRNyYWEhPvvsM2zbtg2TJ09G27ZtYbFYsGrVKnTt2rXRgnUTJ07Ehg0bGvwqdkT//v3Rq1cvLF68GIyxBrV/JkyYgL///e+YN28eRowYgePHj2P+/PnKWppi/PjxiI2NxaxZszB//nxoNBqsXLkSFy5csBuXlZWF+fPn49lnn8WZM2dwww03ICYmBnl5efj+++8RFhaGF154AT///DMeffRRTJ06FR07doROp8POnTvx888/4y9/+UtzL20DoqOj8be//Q1//etfcc899+COO+5AYWEhXnjhBRgMBsybN8/lOevT3PsJADfeeCMWLVqEO++8Ew8++CAKCwvxyiuvNBCeb731Fnbu3Ikbb7wRGRkZqKmpUdLFr7/+egDA7bffjtWrV2P8+PH405/+hIEDB0Kr1eLixYvYtWsXJk2ahMmTJ7f4edXH2ffQFZ588kk8+eSTTY4ZPXo0xo4diz//+c8oKyvDsGHD8PPPP2PevHno06cPpk+fDkByRd59991YvHgxtFotrr/+evz666945ZVXGrg158+fj23btmHo0KF47LHH0LlzZ9TU1ODcuXPYvHkz3nrrrSaFiCz865d5cJb4+Hhcd911+Nvf/oawsDAsXboUx44ds0uFb4z58+fjxhtvxNixY/GnP/0JVqsVCxcuRHh4OIqKipRxzz33HC5evIhRo0YhLS0NJSUleP3116HVapssqOjMfk888QRWrVqFG2+8EfPnz0dmZiY2bdqEpUuX4uGHH0anTp2afA6CIOCee+7BokWLEBkZiVtuuQVRUVF2Y15//XVcffXVGD58OB5++GFkZWWhvLwcp06dwhdffNFknBGhMj4NwSZaBY6yhqKiothVV13FFi1apKTzfv75581mQsmZMa+++qpTx3799dcZANatW7cGjxmNRvb000+z1NRUZjAYWN++fdnnn3/eaAZL/YyY77//ng0dOpSFhYWx1NRUNm/ePPbee+81SIOXn9u1117LIiMjmV6vZ5mZmWzKlCls+/btjDHG8vLy2MyZM1mXLl1YWFgYCw8PZ7169WKvvfaakjLdGI6ywGTee+891qtXL6bT6VhUVBSbNGlSg7TtGTNmsLCwsCaP4eh4zb2fMsuXL2edO3dmer2etWvXji1YsIAtW7bM7nXav38/mzx5MsvMzGR6vZ7FxcWxESNGsA0bNtjNZTab2SuvvMJ69+7NDAYDCw8PZ126dGF/+MMf2MmTJ5VxrmSB1X/d5Oya+uUHmnsPG8M2C6wp6meBMcZYdXU1+/Of/8wyMzOZVqtlKSkp7OGHH1ZKA8gYjUb21FNPscTERGYwGNjgwYPZ/v37WWZmpl0WGGOMXblyhT322GOsbdu2TKvVstjYWNavXz/27LPPsoqKikZfL8YYi4+Pt8vObIzGvkOPPPIIW7p0KWvfvj3TarWsS5cubPXq1XbjGssCY4yx9evXs549ezKdTscyMjLYv/71L/bYY4+xmJgYZczGjRvZuHHjWGpqKtPpdCwxMZGNHz+e7d27t8k1O7vf+fPn2Z133sni4uKYVqtlnTt3ZgsXLmRWq7XB83WURXfixAnle7Nt2zaHazl79iy77777WGpqKtNqtSwhIYENHTqUvfjii8oYZz9XhPtwjNWrVkYQBEEEHb///ju6d++OjRs34sYbb/T1cgBIBSCvuuoqpKamYuvWrb5eDtHKIBcYQRAEgV27dmHIkCE+FT+zZs3C6NGjkZKSgtzcXLz11ls4evSoXbYgQagFWYAIgiAIv2DatGnYt28frly5Aq1Wi759++Kvf/0rbrjhBl8vjWiFkAAiCIIgCCLooEKIBEEQBEEEHSSACIIgCIIIOkgAEQRBEAQRdFAWmANEUcTly5cRERFBZcgJgiAIIkBgjKG8vBxt2rQBzzdj4/FhDSLGGGP/+c9/WFZWFtPr9axv375sz549jY6dMWNGgwJtqFcEz1ERNwCsurra6TVduHDB4Rx0oxvd6EY3utHN/28XLlxo9lrvUwvQmjVr8Pjjj2Pp0qUYNmwY3n77bYwbNw6///67w0aZr7/+Ov71r38p9y0WC3r37m3XCwkAIiMjcfz4cbttto0am0NuunjhwgWXO2gTBEEQBOEbysrKkJ6e7lTzZJ8KoEWLFmHWrFlKX6jFixdjy5YtePPNN7FgwYIG46Oiouz6qnz++ecoLi7GvffeazeO4zgkJye7vS7Z7RUZGUkCiCAIgiACDGfCV3wWBG0ymfDjjz9izJgxdtvHjBmDffv2OTXHsmXLcP311yMzM9Nue0VFBTIzM5GWloYJEybg0KFDTc5jNBpRVlZmdyMIgiAIovXiMwFUUFAAq9WKpKQku+1JSUnIzc1tdv+cnBx8+eWXDbqKd+nSBStXrsSGDRvw0UcfwWAwYNiwYTh58mSjcy1YsECxLkVFRSE9Pd29J0UQBEEQREDg8zT4+mYqxphTpquVK1ciOjoaN998s932wYMH4+6770bv3r0xfPhwrF27Fp06dcKSJUsanWvu3LkoLS1VbhcuXHDruRAEQRAEERj4LAYoPj4egiA0sPbk5+c3sArVhzGG5cuXY/r06dDpdE2O5XkeAwYMaNICpNfrodfrnV98LVarFWaz2eX9CECr1UIQBF8vgyAIgghSfCaAdDod+vXrh23btmHy5MnK9m3btmHSpElN7rt7926cOnUKs2bNavY4jDEcPnwYPXv2bPGabefMzc1FSUmJanMGI9HR0UhOTqZaSwRBEITX8WkW2JNPPonp06ejf//+GDJkCN555x1kZ2fjoYceAiC5pi5duoRVq1bZ7bds2TIMGjQIPXr0aDDnCy+8gMGDB6Njx44oKyvDG2+8gcOHD+M///mPauuWxU9iYiJCQ0PpAu4ijDFUVVUhPz8fAJCSkuLjFREEQRDBhk8F0G233YbCwkLMnz8fOTk56NGjBzZv3qxkdeXk5CA7O9tun9LSUqxbtw6vv/66wzlLSkrw4IMPIjc3F1FRUejTpw/27NmDgQMHqrJmq9WqiJ+4uDhV5gxGQkJCAEguz8TERHKHEQRBEF6FY4wxXy/C3ygrK0NUVBRKS0sb1AGqqanB2bNnkZWVpVzECfeorq7GuXPn0LZtW5cKVRIEQRCEI5q6ftfH51lggQq5vVoOvYYEQRCEryABRBAEQRBE0EECiCAIgiCIoIMEUJBx7tw5cByHw4cP+3opBEEQBOEzSAARBEEQBBF0kAAKUD799FP07NkTISEhiIuLw/XXX4/KykoAwIoVK9C1a1cYDAZ06dIFS5cuVfZr27YtAKBPnz7gOA4jR470xfKJZsjPz8frr7+OJUuWoLCw0NfLIQiCaHX4tA4Q4R45OTm444478PLLL2Py5MkoLy/H3r17wRjDu+++i3nz5uHf//43+vTpg0OHDuGBBx5AWFgYZsyYge+//x4DBw7E9u3b0b1792ZbiRC+Yf369Vi/fj0AqWL29OnTfbwigiCI1gUJoAAkJycHFosFt9xyi1I0Um718fe//x2vvvoqbrnlFgCSxef333/H22+/jRkzZiAhIQEAEBcXh+TkZN88AaJZSktLlf+p5QpBEIT6kAAKQHr37o1Ro0ahZ8+eGDt2LMaMGYMpU6bAYrHgwoULmDVrFh544AFlvMViQVRUlA9XTLhKRUWFw/8JgiAIdSABFIAIgoBt27Zh37592Lp1K5YsWYJnn30WX3zxBQDg3XffxaBBgxrsQwQOJIAIgiA8CwmgAIXjOAwbNgzDhg3Dc889h8zMTHz77bdITU3FmTNncNdddzncT475sVqt3lwu4SLl5eUO/ycIgiDUgQRQAHLgwAHs2LEDY8aMQWJiIg4cOIArV66ga9eueP755/HYY48hMjIS48aNg9FoxMGDB1FcXIwnn3wSiYmJCAkJwVdffYW0tDQYDAZyj/khZWVlDv8nCIIg1IEEUAASGRmJPXv2YPHixSgrK0NmZiZeffVVjBs3DgAQGhqKhQsXYs6cOQgLC0PPnj3x+OOPAwA0Gg3eeOMNzJ8/H8899xyGDx+Or7/+2ndPhnCIbRC07f8EQRCEOlA3eAc40w2eOpi3HHotHVNTU4MbbrhBuc/zPLZv3w6ep7JdBNFayM3NBc/zSExM9PVSWhXUDZ4gApji4mIAAAMHABBFkdxgBNGK2Lp1K26//XZMmzYNe/bs8fVyghYSQAThZxQVFQEAmC4MTNDbbSMIIvA5duyY8v+JEyd8uJLghgQQQfgZigDShkDUhdhtIwgi8LHN7CTrru8gAUQQfkZBQQEAQNSGgmnDAABXrlzx5ZIIglAR28QGEkC+g7LACMLPkMUO04UBohlAnSgiCCLwsW1vI8f8Ed6HBBBB+Bl1AigUTLQAkLrDEwTROrB1aZN723eQACIIP0MWO6IuHFytBYhcYATROrBYLHaip6CgAIwxcBznw1UFJxQDRBB+Rm5uLgDJBSbqwgEAeXl5vlwSQRAqUVRUBFEUlfvV1dXU789HkAAiCD/CYrEo1h5RH24ngKhmKUEEPvKPGVEXDlFjsNtGeBcSQCpitVphsVi8dvNlQ9OsrCwsXrzYZ8dvrRQUFEAURTCOB9OGgumlLLCqqirKFiGIVkBOTg4A6QcO00s/cC5fvuzLJQUtFAOkElarFbdMmYrSYu8FtEXFxOKzTz+BIAhOjR85ciSuuuoqVYTLDz/8gLCwsBbPQ9gjnxyZLhzgOIDTQNSGgDdXIycnhxrXEkSAc/HiRQCAaIgEZ7VAqCzApUuXfLyq4IQEkEowxlBaXITyvvcAnBcMa0wEflqlqluEMQar1QqNpvmPRUJCgmrHJeqQ439EfYSyjekiAHM1cnNz0aVLF18tjSAIFcjOzgYAiIYocFaL3TbCu5ALTG04HuC9cHNRZM2cORO7d+/G66+/Do7jwHEcVq5cCY7jsGXLFvTv3x96vR579+7F6dOnMWnSJCQlJSE8PBwDBgzA9u3b7ear7wLjOA7vvfceJk+ejNDQUHTs2BEbNmxQ4xUNKmRTuK0Akv+XrUMEQQQu586dAwCIhmiIIdF22wjvQgIoSHj99dcxZMgQPPDAA8jJyUFOTg7S09MBAHPmzMGCBQtw9OhR9OrVCxUVFRg/fjy2b9+OQ4cOYezYsZg4cWKzv1JeeOEFTJs2DT///DPGjx+Pu+66i2pcuIgsgOTYAAAQDRF2jxEEEZgYjcY6C1BIDMSQGADA2bNn7TLDCO9AAihIiIqKgk6nQ2hoKJKTk5GcnKzEDs2fPx+jR49G+/btERcXh969e+MPf/gDevbsiY4dO+LFF19Eu3btmrXozJw5E3fccQc6dOiAf/7zn6isrMT333/vjafXaqizAEUq22QLEMUJEERgc+7cOSnJQdBLZS4MkWC8gJqaGiU2iPAeJIAI9O/f3+5+ZWUl5syZg27duiE6Ohrh4eE4duxYsxagXr16Kf+HhYUhIiKCKhi7iCKADDYxQOQCI4hWwfHjxwEA1rD42iQHHmJInN1jhPcgAUQ0yOZ65plnsG7dOvzjH//A3r17cfjwYfTs2RMmk6nJebRard19juPIrOsClZWVSpNE+xggyRqUl5cHi8Xik7URBNFyjh49CgCwhsUp26xh8XaPEd6DssCCCJ1O51TtoL1792LmzJmYPHkyAKCiooKC9LyAYv3RGABBp2xn2hAwXoAoWpGXl4fU1FRfLZEgiBbw66+/AgCs4YnKNmt4IpD/u/IY4T3IAhREZGVl4cCBAzh37pxScM8RHTp0wGeffYbDhw/jyJEjuPPOO8mS4wWUGkA21h8AAMdB1FEgNEEEMkVFRbhw4QIYAGt4krLdGiH9f+rUKVRWVvpodcEJCSC1YSIgeuHGXBckTz/9NARBQLdu3ZCQkNBoTM9rr72GmJgYDB06FBMnTsTYsWPRt2/flr4yChaLhdo6OMC2Qmx9KA6IIAKbI0eOAJCyv6DRK9uZLgyiPgKiKOKXX37x1fKCEnKBqQTHcYiKiQV+WuW1Y0bFxLrUQbhTp07Yv3+/3baZM2c2GJeVlYWdO3fabXvkkUfs7td3iTkSNCUlJQ22FRYWoqCgAJGRkYiJiXFu4UFCnQCKaPAY1QIiiMDmp59+AgBYI9s0eMwSkQKdsRw//fQTBg8e7O2lBS0kgFRCEAR89uknXrVscBzndBsMf6G4uBgAUFZWRgKoHo26wFBnFZIrRRMEETgwxpSSIBYHAsga2QYoOIEffvjB20sLakgAqUigiRFfQK6vxlHaYOgcucBIABFEoJKdnY28vDwwToA1IrnB45aoNmDgcPbsWeTn5yMxMdHBLITaUAwQQfgBjDHk5eUBcBwDJIuiQBNAp0+fxhtvvKGY/wkiGPnuu+8AQBI/grbhAI0BYniC3VjC85AAIgg/oKysDDU1NQCkoMj6yKKouLgYRqPRq2trCa+88go+++wzzJkzx9dLIQifsW/fPgCAJTq90TGWKOmxb7/91itrIkgAEYRfIFfMFjUGgHfgmRb0YLzkYi0oKPDm0lrEhQsXAIAKOBJBS0lJiZLdZYnOaHScJUZ67KeffkJVVZVX1hbskAAiCD/gypUrABxbfwAAHKc8Ru1FCCJw+OabbyCKIqyhcXZNjusjGqIhGiJhNpsbZOsSnoEEEEH4AbIAEhsTQABErfRYIFmACCLY2bNnDwDAEpPV9ECOgzlaGrN7927PLooA4AcCaOnSpWjbti0MBgP69euHvXv3Njp25syZ4Diuwa179+5249atW4du3bpBr9ejW7duWL9+vaefBkG0iMLCQgBS24vGYLpQACSACCJQKC0txY8//ggAMMdmNTveUjvmwIED5AbzAj4VQGvWrMHjjz+OZ599FocOHcLw4cMxbty4RisUv/7668jJyVFuFy5cQGxsLKZOnaqM2b9/P2677TZMnz4dR44cwfTp0zFt2jQcOHDAW0+LIFxGEUBNWICYNtRuLEEQ/s3evXthtVphDYkFM0Q1O14MjYOoj4TRaCQ3mBfwqQBatGgRZs2ahfvvvx9du3bF4sWLkZ6ejjfffNPh+KioKCQnJyu3gwcPori4GPfee68yZvHixRg9ejTmzp2LLl26YO7cuRg1ahQWL17s8edjtVphsVi8dnOmsamaZGVlqfo6Uk2gOpyxAIm1jwWSALKtVO7tzytB+Bq5or4lrq1zO3AczLFt7fYlPIfPCiGaTCb8+OOP+Mtf/mK3fcyYMUrKYHMsW7YM119/PTIzM5Vt+/fvxxNPPGE3buzYsR4XQFarFbdNvQUFRaUePY4t8bFRWPPJZ1SAsRUgV8gWm3KB1T4mjw00LBYLfVaJoKGwsBCHDh0CAJhj2zm9nyW2HfQ5R3DgwAGUl5cjIqJhZXhCHXwmgAoKCmC1WpGUlGS3PSkpyalibzk5Ofjyyy/x3//+1257bm6uy3MajUa72iplZWXOPAU7GGMoKCrFuyMKITjfnsttrAx4YHdgW1ECee1qI/dNYxpDo2NagwDS6/XNDySIVsDOnTvBGIM1LNG+vQ1jgFhbFoLXAPX6OYqhMbCGxADVxdi9ezcmTJjgxVUHFz4Pgq7fzJMx5lSDz5UrVyI6Oho333xzi+dcsGABoqKilFt6euPFqppD4AAN7/mbqyLr7bffRmpqKkTRvov8TTfdhBkzZuD06dOYNGkSkpKSEB4ejgEDBmD79u1uvw7OQAJIgjGmiJomg6BrxVGgCiCz2ezrJRCE19ixYwcAwBxXz/ojWhDx0weI+OmDOiFUD0vtPvIchGfwmQCKj4+HIAgNLDP5+fkNLDj1YYxh+fLlmD59OnQ6nd1jycnJLs85d+5clJaWKje5eFtrYurUqSgoKMCuXbuUbcXFxdiyZQvuuusuVFRUYPz48di+fTsOHTqEsWPHYuLEiY0GpKsBCSCJ6upqmEwmAM1ZgKTHysvLAyaexlb0kAAigoWLFy/i2LFjYOBgiXUy/scGc2x7AMDhw4eVEhmE+vhMAOl0OvTr1w/btm2z275t2zYMHTq0yX13796NU6dOYdasWQ0eGzJkSIM5t27d2uScer0ekZGRdrfWRmxsLG644QY7l+Enn3yC2NhYjBo1Cr1798Yf/vAH9OzZEx07dsSLL76Idu3aYcOGDaqug0RPQ0pLpbgxxgmOq0DXwgRJADHGUF5e7pW1tRQSQEQwIl+DrFFtmrTqNgbTh8MSngjGGAVDexCfusCefPJJvPfee1i+fDmOHj2KJ554AtnZ2XjooYcASJaZe+65p8F+y5Ytw6BBg9CjR48Gj/3pT3/C1q1b8dJLL+HYsWN46aWXsH37djz++OOefjp+z1133YV169Yp8U6rV6/G7bffDkEQUFlZiTlz5qBbt26Ijo5GeHg4jh075lELUH13XLCiCCCNoUE8gB08Dybo7PbxZ0RRtLNUkQAiggHGWJ37q9aS4w6WOGlfT4ciBDM+C4IGgNtuuw2FhYWYP38+cnJy0KNHD2zevFnJ6srJyWlwAS4tLcW6devw+uuvO5xz6NCh+Pjjj/F///d/+Nvf/ob27dtjzZo1GDRokMefj78zceJEiKKITZs2YcCAAdi7dy8WLVoEAHjmmWewZcsWvPLKK+jQoQNCQkIwZcoUxTWjBowxsgA5oE4ANR8gzDR6cFZTQAig+oJHzc8SQfgrx48fx8WLF8F4AZaYzOZ3aARLTFuw7O9w8uRJnD9/3i7bmVAHnwogAJg9ezZmz57t8LGVK1c22BYVFdVshcwpU6ZgypQpaiyvVRESEoJbbrkFq1evxqlTp9CpUyf069cPgFSwa+bMmZg8eTIAoKKiAufOnfPhaoMHOeuQaZ0RQAbAWO5WpqK3qS94yAJEBAOy9ccSnQEIWrfnYVoDrJFp0JRewI4dO3DfffeptUSiFp9ngRHe5a677sKmTZuwfPly3H333cr2Dh064LPPPsPhw4dx5MgR3Hnnnaq7qOrPR9YgCcUCJDQeAC0jW4nIAkQQ/ocoikqiicWF2j+NYbbJBqPzpfqQAFIZKwMsoudvVje/C9dddx1iY2Nx/Phx3Hnnncr21157DTExMRg6dCgmTpyIsWPHom/fviq9Ko6hL7SEaxYgvd0+/gxZgIhg45dffkFBQQGYoIMlKq3F81miM8B4AZcuXcLJkydVWCFhi89dYK0FjuMQHxuFB7zYxDc+Nsqpmkm2CIKAy5cvN9ielZXVINvgkUcesbvfUpdYfcFDAkjCLgi6GeQxgWABsi0u6ug+QbQ2FOtPTCbAq1D1XNDCEpUObfE57Nq1C506dWr5nIQCCSCVEAQBaz75TPWLuiiKOHXqFADAaogGGINgLAXHcejYsWNAtRYgF5hjWqsAqm8BIgFEtGasVit275Z+AZvdqP3TGJbYtooAevDBB13+0Us0DgkgFfGEGKmqqoIgCGDgAK2UAs1bNODAYLFYoNEEzltIFiDHONMGQ0YuhhgI1aDrCx6KASJaM7/88guKi4vBBB2sEW1Um9cSlQ7Ga5Cbm4sTJ06gc+fOqs0d7FAMkJ+jZLzZZhMIkuiprKz0wYrchwSQYxQBpG1dFiASQEQwIVt/JPeXipdWQaPEE+3Zs0e9eQkSQP6OLHLkAni2/5MAah0UFRUBAJim+Yqxcrd4eR9/pr4Aqqmp8dFKCMKzMMbwzTffAADMLaj90xiWmCwAUrkSQj1IALmJNy7eZrMZNTU1YACYjQVIFkDV1dWwWBw30/NH6r9mVAlasorIGV2irnkBxLShACQB5O8CkoKgiWDhxIkTuHLlChivgTVSPfeXjCUqDYzjkZ2d7dHq/MEGCSAX0WolIdJcMUY1UPo98RqAs3mrOB6sNsOgoqLC4+tQi/oXbPmCKL+mwUhhYSGA2j5gghNp8LUWILPZ7PduMLIAEcHCvn37AACWqNQm+/m5jUYHa0Sy3bGIlhM4EbR+giAIiI6ORn5+PgAgNDTUY1H5xcXFEEURoiCAWexrqDAI4EUzioqKYDA0HzviD9TU1EAURTDGIIoiKisrkZKSElCZbGojd3pmutCm+4DJ8AJEjQG8pQZXrlxBdHS0ZxfYAsgCRAQL+/fvB1Bb/dlDWKIzoCm7jP379+P222/32HGCCRJAbpCcLClxWQR5ArPZLFkHOE5ye9S/ODIGzlQFgKGysjIgssFqamqUgF+z2QyLxYI+ffr4dlE+Jjc3FwAg6sKc3ofpwgFLDfLy8tCxY0dPLa3FVFdX290nCxDRGikqKsKJEycAANamih8yEZypErDWhS1wxgpA0IDpwuyt/A6QA6F/+eUXVFRUIDw8vOWLD3L8/6rph3Ach5SUFCQmJnqsuu2KFSuwa9cumCNTYcpw3MhVf+5baCrycMMNN9hVdfZXvvnmG7zzzjsQRRHl5eWYOnVq0Ne0kAUQ00c4vY+oD4dQVYCcnBxPLUsVyAVGBAMHDx4EAFhD4xQXtSM4UyXCf/7Eblv4b+sBABW9pjZ7DmCGSIj6SMBYhkOHDmH48OEtXDlBAqgFCILgEfdNaWkpPv/8cxiNRlTF9oe13HH6sCAkIzT/F6xbtw633347QkNDVV+LmlRVVdlZzcglAly6dAkAILokgCLs9vVXZMGjFxiMVo4EENEqkQWQJTLV48eyRKVCl1+GgwcPkgBSAQqC9kNk8WMNjYM1PKnRcdaoNIiGSFRWVmLjxo1eXKF7UExIQy5cuAAAEA1RTu8jj5X39VdkF1iUVsr2IwFEtDYYY/jpp58AANYo9bO/6iNnmMnHJFoGCSA/o6qqCp9++ikAwJTcs+nAWI6TxgBYs2aN3wsKao1gD2MM58+fBwCIhmin9xNDpLHyvv6KLIAidKLdfYJoLVy6dElqfsrxsIYnevx4lohkMEg/fuQMUsJ9SAD5GZ9++inKy8thNUTBEpvV7HhzXAeIujAUFhZiw4YNnl9gC6DKwPbk5eWhsrISjOMgGiKd3k8MiQEAFBQU+HUqvGzxidYxu/sE0Vr4+eefAQDWsATPpL/XR6OHGBILQAqGJloGCSA/orS0FGvWrAEAmNpc1WxWAACAF6SxAD788EO/rg4tC6BQDblEAODkyZMAagWNK52jBa0SByTP4Y/IFp9IsgAFDadPn8bDDz+MAwcO+HopXuHXX38FAK9Yf2SsEUl2xybchwSQH7Fq1SpUVlbCGhILS2w7p/czx3eEaIhEaWkpPvroIw+usGXIAihcy+zuByvHjx8HAFhD413e1xom7XPs2DFV16QmSgxQrQDyRvFQwre88cYbOHr0KObNm+frpXiFo0ePAgBEbwqg2mP9/vvvXjtma4UEkJ9w/vx5fP755wAAY/oA54riyXA8jGkDAEixQP6aHl0ngKQLYrC7wGQTthie4PK+1jDpJOjPvwJlARStJ4tfsHD69GkAwfFeV1dXK3F41jDXv8PuIv9gOnXqVEC1QvJHSAD5AYwxLFmyBFarFeboDFijXE+ntERnwBKRArPZjP/85z8eWGXLkU+KEbUWoGB2iZhMJsV601SmX2PIvwJ//fVXWK1WVdemFrLFR7YAGY1GOmETrYazZ89Klfo1IVIldy/BDJFgvBYmk8nvM0H9HRJAfsDXX3+NgwcPgnECjOkD3ZuE42DMHAwGDt98841Smt2fIAtQHb/99huMRiNEbYhLKfAyYlgcmKBDRUWF38YB1VmAWINtBBHonDlzBgAghsZ498AcpyRCyGsg3IMEkI8pLy/HkiVLAACmlF5gLmQD1UcMiYE5uTsAYPHixX53salvAQoGM3ljfP/99wAAa0Qb19ydMhwPS21zRHkuf0NJg9eKEDiy+hGtC7kru1yWwptYa49JneFbBgkgH/P222+jqKgIoiESppSejgcxBljN0q1eR/X6GNv0gagLQ15eHlasWOGBFbtP/SDoYBZASvfo6HS357DW7uuP1j6LxaK8vwaBwSBI7zkFQhOtBXeKmKqFfMyLFy96/ditCRJAPuTQoUNKBeeazGGN15EQLYj46QNE/PQBIDYTQyFoUZM5FIBUU0jOUvAH6ixAdTEhwcj58+dx/vx5MI6DxY14LxlLVDoYpEwUTzbmdQdbS49BYAjRkAAiWhdKI2MX2tioBdOH262BcA8SQD6iuroaCxcuBACYEjrDGpmi2tzW6HSY49pDFEW89NJLfhNrIwsguS6MyWTy2wBeT7Jr1y4AgDUyFdDo3Z6H6UKVAGp5Tn9BFkAajkEnACFkASJaGVeuXAEAqZO7lxF1kgDytx8+gQYJIB/x3nvv4fLlyxB1YVLau8rUZAyCqDHg3LlzWLVqlerzu0N9F5jttmCBMYZt27YBAMyxbVs8nyVOqhe1devWFs+lJnJBTtnyYyALENGKMJlMqKioAACIWu83oZa7zhcXF4M1ExZBNA4JIB9w5MgRrFu3DgBQkzUMEHTqH0RjgLHWFfbf//7XLwrm2QbFygRbHNAvv/yCS5cugfEaWGKyWjyfObYdGMfj9OnTOHHiRMsXqBKy0JFjf2Qh5M+VygnCWcrLywEADPDM+bsZWK3l2GKxUGJBCyAB5GWqq6vx0ksvAQBM8Z1gjUrz2LEssVkwx7aFKIr417/+5XNXmGztMQiAjg/OatD/+9//AEjCBYK25RNq9LDEZAKAX/WCkwWQLHxkFxidrFs3nDsZjQGIIuQFrVtZnBMmTMCqVaswYcIEcBwHzuSiZZTXgIGzXwvhMiSAvMy7775b5/rKcLPmjwsYM4YorrD333/f48drDIvFohTB0wkM+iC8IBYWFmL37t0AAHNiF9XmNSd2BQBs375d+WXqa+q7wOS/stuAaJ0EizvGbDYDABjnXgPUadOmISMjA9OmTQNjDLzJxe8Fxyn9A+W1EK5DAsiLHDlyBJ999hkAoCbraq+YTpnWAGOW5Ar76KOPfOYKsxU6ehsBFEwusPXr18NiscAalggxzPX+X41hDU+CNSQGNTU1fmMFkgWQ4gITyAVGtB5EsdaN76bFa+3atcjOzsbatWvBcZwS1OwStcdW1kK4DAkgL1FTU4OXX34ZgOz6cj/92VUsMXWusJdfftknvxhkocNzDBoOQSeAqqqqFPeXKbmHupNznDLnunXr/MKtKAud0HoWIAqCJloDgiBZX8DcEx+bNm3CPffcg02bNoEx5l4rjVprm7IWwmVIAHmJ999/H5cuXYKoDXW/3UULMGYMhqgx4MyZMz7pGC8LHT3PwHGAnrff3tpZv349ysvLIRoiYYnJUH1+S2w7iLowFBUVYdOmTarP7yqNucDIAkS0BnQ6yXrPNVeXrRFkV6HbLkPGlJpw8loI1yEB5AVOnjyJNWvWAABqsoYCGh9kDWhDYMwYDABY9cEHShdjb6EIoNofK8EUA1RVVYW1a9cCAIwpVwGcB752vABTSi8AUtafr61AcqyP7PoKJQEUFARLEHRYmFT7hxMtbluBWoRohvxKh4e74T4jAJAA8jhWqxWvvvoqRFGEOaYtrNHq//p3FktsW1ii0mAxm7Fo0SKvBizKQkcWPsHkAvv0009RWloKUR+p1O3xBOb4ThB1YSgoKPB5LFCdC0y6OJAFiGhNREZGguelyydn9v45jDNL59PQ0FDo9e4XUw12SAB5mI0bN+LYsWNgghbGjEG+XQzHoSZzCBgv4MiRI9i+fbvXDt2YAGrtFqCSkhLF+mdM7esZ648ML8DUpg8A4IMPPvBpxlX9GKBQQRJClAVGtAYEQUBsbCwAgHM1g0sFeJP0/YqLi/P6sVsTJIA8SFlZGZYtWwZAuvi5FeimMkwfAVPKVQCAN99802tBqbaNMYHgsQCtWrUKlZWVsIbGwaJC5efmMMd3gNUQhbKyMp/EeslQGjzR2klNlRJZeKP3S0/wNWV2ayDcgwSQB3n//fdRVlYGa0iMUqvFHzAl94Coj0BRURH++9//euWYdTFAta0RgkAAZWdnK5lfxvQBbqfMugTHw5gmtVb55JNPfNYsURY6igWIXGBEKyMjQwpn4KuLvX5svrrEbg2Ee5AA8hCXL1+2ufgNdM/1wURwxnJwxrpfzZyxApyxvGWBd7yg9B/75JNPUFBQ4P5cThKMLrA333wTVqsVlqh0WCPbeO241uh0WCKSYTKZ8M4773jtuLY0cIFp6t5vuSAmQQQyHTp0AAAIVYVePzZfe8z27dt7/ditCRJAHmLlypVS9ePIVLdr/nCmSoT//AnCf1uvbAv/bT3Cf/4EnKllv6Qt0ZmwhifCaDR6pVlqfQuQnA3WWgXQDz/8gP3794NxHGq8XfaA42DMGAQGYOfOnfjll1+8e3w0tADJLjCAagERrYPOnTsDAISKK0pNHq8gihAqpR+tXbqoV1E+GCEB5AEuXryoBBgb0/r5eDWNwHEwpkpr27x5M/Lz8z16OFnoGGqFT2t2gVksFvz73/8GAJgTu4GFRHl9DWJoHMwJnQAAS5Ys8Wq1WMZYAwuQhq/r/0ZusNZLsLTCACQLkMFgAGc1edUNxlcVgGNWREZGkgushZAA8gBr1qyBKIqwRKWr2vJAbayRKbBEJMNiseDTTz/16LEac4G1RmvA559/jvPnz0PUGGBsc5XP1mFK7QcmaHHixAl8+eWXXjuu0WhU3FwhmjrhFUqB0EQrQqPRoFcvqfaWUHbJe8ctlY7Vt2/foKm75ClIAKlMSUkJvvrqKwCAKaWnj1fTPKZkaY1ffPGFR3+Z11mAWncWWElJCVauXAkAMKX1AzS+q9HBtCEw1qbFv/fee14THvLniANTLH5AXU0gEkBEa2HAACmWUlNy0WvH1JReAAD079/fa8dsrZAAUpkvv/wSZrMZ1tA4WMOTfL2cZrFGpcFqiEJ1dTW2bdvmsePUtwAZWmkQ9MqVK1FRUQFraCzM8R19vRyYE7tCNESiuLgYq1ev9soxbeN/bH+gUip86yfYLBLDhg0DAAjluYDF8z/mOFMlhMoCcByHoUOHevx4rR2fC6ClS5eibdu2MBgM6NevH/bu3dvkeKPRiGeffRaZmZnQ6/Vo3749li9frjy+cuVKcBzX4OYNSwNjTHE1mBO7eiftuaVwHMwJUiCdJ90k9S1ArVEAnT17VqnAbEwf5Nmih87CC0oQ9qeffopLlzxvqpcFTpjGPh4kjAQQ0cpo06YNOnToAA4M2mLPtxfSFJ0FAPTo0UMpxEi4j0/P0GvWrMHjjz+OZ599FocOHcLw4cMxbtw4ZGdnN7rPtGnTsGPHDixbtgzHjx/HRx991CASPjIyEjk5OXY3g8Hg6aeDkydPIjs7G4wXYI7N8vjx1MIS1w6M43D8+HFcuHDBI8cIhjT4t99+W2p5Ep0Ja2SKr5ejYI1KhyWyDcxmM9577z2PH0/pA1ZPAFEMENEaue666wAAmsLTHj+WtvYY8jGJluFTAbRo0SLMmjUL999/P7p27YrFixcjPT0db775psPxX331FXbv3o3Nmzfj+uuvR1ZWFgYOHNjAFMhxHJKTk+1u3mDPnj0AAEtUOiAETodepg2BNUKqUyM/B7Vp7RagQ4cO4bvvvgPjOBjT/cw3z3Ewpg8AA7Br1y4cO3bMo4ernwIvE6olAdTaCaYsMJnrr78eHMdBU54LrrZCsyfgq4ogVBVCo9Hg2muv9dhxggmfCSCTyYQff/wRY8aMsds+ZswY7Nu3z+E+GzZsQP/+/fHyyy8jNTUVnTp1wtNPP93gIlpRUYHMzEykpaVhwoQJOHTokMeehy0HDhwAAFh82PDUXSwx0prl56A2DYKgNXXbA/2kyRhTWp6YEzqDGdxMe5cLX9aUgasqlm41ZS0vfAkpLd4SJxVuk9fqKRQBpLVfM1mAiNZIYmKiEpCsLTjhseNor0hzDx06FNHR0R47TjCh8dWBCwoKYLVakZRkHyiclJTUaPn+M2fO4JtvvoHBYMD69etRUFCA2bNno6ioSIkD6tKlC1auXImePXuirKwMr7/+OoYNG4YjR46gY0fHQalGoxFGo1G5X1bmuoovLy/HyZMnAcDtwoe+xBIprfm3336D0WhUvcNwnQtMui8LIavVCpPJFNAdjX/44Qf8+uuvYJyg9FlzB7nwpSMqek0F00e4PTcAGFP7QFN0Gj/88AN++eUX9OzpmSxFRQAJ9V1glAVGtE4mTJiAH374AdorJ6WGxLzQYAzThaGi11SpaKJolTbyAsBxYLqwpg9gNUNbeEo5FqEOPo/SrJ81wBhrNJNAFEVwHIfVq1dj4MCBGD9+PBYtWoSVK1cqF9jBgwfj7rvvRu/evTF8+HCsXbsWnTp1wpIlSxpdw4IFCxAVFaXc0tPTXX4ev//+u7RGfSSYNsTl/X0N00dA1IbAarXi+PHjqs+vWIBqrQB6njV4LFCRs6vMiV38ouFtYzB9hJKZ5smMsDoLEMUAEcHBsGHDEB8fD95SDU3xOceDOB5MHwFmiAQLjZFuhkjph00zCRPawtPgrCa0adOG0t9VxGcCKD4+HoIgNLD25OfnN7AKyaSkpCA1NRVRUXUuhq5du4IxhosXHddh4HkeAwYMUKwzjpg7dy5KS0uVmzuBwKdOSerc6seFD5uE4yCGSms/fVr9YL76QdACD2j5wI8D+v3333HkyBEwjocpuYevl9MspuReYODw3Xff4cyZMx45RmNZYCSAiNaKRqPBxIkTAQC6vN/VnZwxaPOPAgAmTZoEnve53aLV4LNXUqfToV+/fg1qz2zbtq3R+gbDhg3D5cuX7U6gJ06cAM/zSEtLc7gPYwyHDx9GSkrjWTl6vR6RkZF2N1eRRZMYEu3yvv6CtXbtameCWSwWmM1mAFJxPKNVsgK3hkBoueGtJbZd82ZsP4AZIpV4LzllX20oC4wIRiZMmACtVguh8gr4CvVaCwnlORCqi2EwGDB+/HjV5iV87AJ78skn8d5772H58uU4evQonnjiCWRnZ+Ohhx4CIFlm7rnnHmX8nXfeibi4ONx77734/fffsWfPHjzzzDO47777EBIiuZ1eeOEFbNmyBWfOnMHhw4cxa9YsHD58WJnTU8i9tERduEeP40mYXlp7Xl6eqvPaCpwn9sXigd1xMImBL4DKy8uxc+dOAIApsauPV+M85tq1btmyxSP1sRQBJEhiVxa8sgCiXmBEayQuLk5JT9fl/qbavLrcXwEA48aNQ0REy+IACXt8KoBuu+02LF68GPPnz8dVV12FPXv2YPPmzcjMzAQA5OTk2NUECg8Px7Zt21BSUoL+/fvjrrvuwsSJE/HGG28oY0pKSvDggw+ia9euGDNmDC5duoQ9e/Zg4EDPduQuLS0FADCt5+sNeQqmkUSk/FzUQu73JcDeIhDoAmjPnj1S1e+QaL/u+VYfa0QKRH04qqursX//ftXnlwWQThDxwO44RfBSEDTR2pk6dSoAQFN8TsrebCF8dQk0pRfBcRxuvfXWFs9H2OOzLDCZ2bNnY/bs2Q4fk3sq2dKlS5cmWza89tpreO2119RantMov6R5rdePrRZMkD4OalsFbON/qqx1Ae6B3hB19+7dAABLbPvAqPotw3Ewx7aDPudnfP3116rXFLG1ANliawESRZFiGVohwdYKoz4dOnRAv3798OOPP0KX9zuMGYNaNJ+21vozbNiwRsM8CPehM5BKyLVsAruijXTyUrsujyxw6seEyBlhgWgBMhqNOHz4MIC6GkqBhFyr6uDBg0rndrVoLgiaMRaQ7zlBOMO0adMAANorxwGLye15OHO1UvlZnpNQFxJAKiHXseFEdS8m3kReu6dqAOmE1uMCO3r0KEwmE0RtKERDtK+X4zJiWDyYoENlZaWSwagWjQVB64S6zD9yg7VOAr2oqRoMHDgQWVlZ4ESLJILcRJt/FByzokuXLh6r2RXskABSCTlzjLMYmxnpv3C13YzdyYJrCtkCZGhEAAWiC0yulWQNTwgs95cMxyslG06cUK96rclkUjL+6gsgoM4KVF7e8vgIgvBHOI5TYoF0+Ufdq+IuWqHNl1rWTJ06Nehdi56CBJBKJCQkAAB4k2d+2U6YMAGrVq3ChAkTpA73JvVFA2eSsnPk56IWsoWnfkxIILvAzp07BwAQQwK3I7MYGgdA6mKvFrJlhwNrUgBRJhjRmrn++usRGRkJ3lQBTXHjzb0bQ1N0BrylBvHx8RgxYoQHVkgAJIBUQ64ezVeXeGT+adOmISMjA9OmTQNjzCNCS157Roa6MS2yhUdXPwZIsH88kJBLBYgtbE/hS8TasgdyCQc1sHV/8Q5+tIZQJlirhiwVEnq9XimMKBcxdAVd7T4333wzNBqf5yq1WkgAqUT79u0BAHxVgUfmX7t2LbKzs7F27VpwHOeRekNCpbT2du3aqTqv4gLjW08MUF3ZA8+0PfGGxU8ue1BSUqLanI1lgMlQMUQiWLjpppvA8zw05Tku/TDmKwsgVBZAq9VS3y8PQwJIJbp37w4AEKpLwJnVv6Bv2rQJ99xzDzZt2gTGmOo9pzhjBXhTBXieR9eu6hb1q3OB2W8P5Bggk6k2u8NB00M18IbFj9WuXY7ZUQPZtVW/D5gMucCIYCEpKQmDBw8GUNfJ3RnkwOlrrrmGur57GBJAKhETE6NYgYTSS6rPr6TZeyjLQlMq9VLr1q0bQkPVFVeywNHXc4HJMSKBKIA8jTcsfp5AaYTqIP7HdjtZgIhgQLbgaApPAaITwdCiBdqiM3b7Ep6DnIsqMmTIEJw+fRqa4nOwxHfw9XJcQlMsBcI21oetJSid4FtRFpgiEq3u1/loik2bNmHjxo3gOM4jFj8A4KyS5ScsTL0eZooFqBEBFEICiAgiBg4ciJiYGBQXF0MouwhrdNPxlZribHBWM5KSktC7d28vrTJ4IQuQish9YDSlFz3iBvMUnLECQlkOAGDkyJGqz99cGnwgxgDFxMQAAHgPxOYAnrf4AQBnlsSKmmb25ixAYeQCI4IIjUajXBe0Rc1nW2pqrT+jR4+mSulegF5hFWnXrh06deoEjonQFKhbXM6TaAtOgAPQu3dvtGnTRvX5FQHUSCXoQLQAya8Tbyzz8Urch6+RavGkpqaqNqcsbORsr/qQBYgINuRWM5ribEC0Nj7QaoamNnxC7fY0hGNIAKnMpEmTAAC6/N+d8/n6GtGiFNyS1642jVmAQgLYBda2bVsAAF9V6OOVuI9Qu3a5+bAaKBagxrLABOk7QRYgIljo1q0b4uLiwIlmCOW5jY7TlF4Cx6xo06aN6pm4hGNIAKnM9ddfj5iYGPCmSmiKTvt6Oc2ivXICvKUGSUlJuOaaazxyjEZjgALYAtSlSxcAgFBR4F6lV18jWhTxpmbWX50FqOkYIBJARLDA8zyGDBkCANCUXmh0nFD72LBhw6iekpcgAaQyer1eaVynv3zYv61AogW6nJ8BAHfccYfHCm41ZwEym82qN+T0NO3atUNERAQ40Qy+4oqvl+MyQnkuOCYiPj7eIy4wygIjiDoGDBgAABBKLzsewBg0ZZftxhKehwSQB5g0aZJkBTKWQ1vgfjM8T6PNOwreXIWkpCSMGzfOY8dpLggaCDyLgCAI6N+/P4Cmf9X5K5oSqezBwIEDVf216awFKBCtfgThLn369AEACDUl4Mw1DR7nTBXgTZUQBIEan3oREkAeIDQ0FNOnTwcA6C4dAiyeSZVuCZy5GvqcwwCAmTNnqt4B3pbG6gAJfF138EC8IF599dUAarM7AqkLNhOVsgfyc1ALcoERREMiIyORlZUFAOArGraeEWq3derUCSEhnqkuTzSEBJCHuOmmm5CRkQHeUgP95UNuzcF0YajoNRUV3Scr2yq6T0ZFr6lgupbVbtFd/BGc1YyOHTti7NixLZqrKey6gzsIjA0J4FT4oUOHwmAwgDeWg68MHDeYUJYD3lyNiIgI1c3tigBqJAha3l5TUxNwbk+CaAlyrJ3goF2S3IZI7Sr8RNOQAPIQGo0Gjz76KABAm/c7+Koi1yfheDB9BJi+rgow04eD6SMAzv23jq/Ih65AKs3+2GOPebTehK1lp74LDKgLhA5Ei0BISIjSqVl3peWuTk8KXlvkUvujRo2CVqtVbV6g7v1uzgIEBKboJZrGk3WrAp2OHTsCgMNrgbxNHkN4BxJAHmTgwIG45pprwIHBcG6ff7hJmCitBcDYsWM97m+WL3I6nkFw8GkL5GrQgE2p+6IzgKWhb98lPCR47Q5hqoKm5DwAz5Tab84FprFxewai6CUId5HLTQgOGqPyNdI22U1GeAcSQB7m0UcfRUhICITKfGivHPP1cqDL/RVCdREiIyPx8MMPe/x4rT0otkePHujYsSM40Qpdvv8GvMto84+CYwy9evVChw7qtmsxm81Nujtl5MdIABHBRHp6OgCAM5bbl86wmsHXdg5IS0vzxdKCFhJAHiYxMREPPPAAAEB/4SA4o+/Sf7maUikoG8Ds2bO90mm4sQwwmUC3AHEchylTpgAAtPm/A6Ifx7VYzdDlHwUA3HrrrapPbytoGhO8QGDXfyIId4mPj4dWqwUHBs6mhQ5vkq4J4eHhiIiI8NXyghISQF5g0qRJ6NGjBzjRDMN5H7nCGIPh3LfgmBX9+/f3aOCzLc0JoEC3AAFSD7iEhATw5mpo/bgFivbKcXBWE9LS0lTP/gLs3Z18E5n1gVwBnCDched5xMXFAQA4U92PBVkMJSYm+mRdwQwJIC8gCAKeeeYZaLVaaEovQlPo/QrR2ivHoCnPhcFgwFNPPeW1SqPyRa7R7uCt4GKo1WqV4pe63J/9s/ilaIEu9xcAwO233w5BEFQ/RHPuThmyABHBSmxsLAAoLi8ASuNsucEy4T1IAHmJzMxMzJgxAwBgyD7g1W7xnLEC+gsHAQAPPPAAUlJSvHbsxhqhygRyFpgtEyZMQHR0NHhjhV+2QNFeOQHeXI3ExESPWf+as/bJBLrbkyDcJTIyEgDAWetqw3EWo91jhPcgAeRFbr/9dnTo0AGc1Qj9+e+8c1DGYDi/H5xoRvfu3XHzzTd757i1KGnRzdSFCfSLYUhICG677TYAgP7yEf/qD1av5Ynaqe8ysgusOQtQa3nPCXsYY5QG3wzh4bUZnrYCqPZ/5THCa5AA8iIajQZz5swBz/PQFp+FUJLt+WMWnYWm9AI0Wi3mzJnjEddHU8iWneYsQK3hYjhp0iRERUWBN5b5xM3ZGJL1pwoJCQm48cYbPXYcpy1AmsAtfkk0Tk1NTcBbcj2NXOWZs5qVbVxt4gRVgPY+JIC8TKdOnZR4EcP5/YDNF0F1LEbosw8AAKbffbdSh8KbKFaBVm4BAqQWKHfccQcAP2qEK1qgyzkCALj77ruh0+k8dij5vXbWBUYCiAg2lO8fs9ZtFK32jxFegwSQD5g5cyaSk5PBmyqlC2Vz8BqU952O8r7TAd75ju36iz+Ct1QjIyNDuTB7G8UC1IqzwGyxa4Rb6PuMMG3+cfDmaiQlJWH8+PEePRYJIIJoGtn9zIk2AqhWDHnKNU00DgkgH2AwGPDYY48BALR5v4J3UBnUDo4DBK10czJ7i68sUAovPvHEEz77ddFca4TWFhAbEhKiiE3d5cPKrzufYK2L/bn77rs9foKVBY3eSRdYa3nPCcJZHLYdqo2b8mRLIsIx9Ir7iKFDh2LIkCHgGIP+wvfqTs4Y9NkHwEGqUdOnTx9153cBZ3tDtaaL4U033SRZgUwVPrUCaa8cA2+pRnJyMm644QaPH0+xADUTBK3n6xqiEkQwoYgcB8HiJIC8D73iPuSRRx6BIAjQlF6EUHZZtXk1JdnQVORBp9PhoYceUm1ed3C2EnRrCp40GAy48847AQC6y0d8EwtkU/fHG9YfwMYCxDcjgMgFRgQpSpacA0M+ZdB5HxJAPiQtLU1JS9dfPKhOhWgmQnfxRwDA1KlTfV5dtFkLUCtzgclMnDhRsQJpfGAF0l6pi/3xVtVv2aLTnAtMX5uISAKICDbqRE5DBUQCyPuQAPIxd999NwwGA4TKAgilF1s8n6boHISaEoSHh+P2229XYYUtw9lWGLaNNFsDBoOhri5Qzs/erQskWqHLkaw/d911l9eCK+tigJoeJwskcoERwYZDkVMb10kCyPuQAPIxMTExdVagy0daNhljSsrz1KlT/aKxXnNZYLbbW5sV6KabbkJkZKRUF6jonNeOqy08Bd5chfj4eK/E/sg4bwEiAUQEJ1ZrbVIEZ3vp5ewfI7wGCSA/YOrUqdBqtRAq88FX5Ls9j1B2GUJ1MQwGA2655RYVV+g+zQXGCjyg5VunGyw0NFTpuq7L/dk7TXCZqMT+TJs2zavZf7Kg0TkZA0QCiAg2xNp4QLtvSK0FSPSHumFBBgkgPyAuLg6jRo0CAOjyj7o9j7Z233HjxvmF9cdkMilurcYKIQKtuy7MzTffLLk4q4pUDXRvDE1JNviaMoSHh2PChAkeP54tTluAKAuMCFLqgqBtY4DIBeYrSAD5CZMmTQIgxfCgtjmeK3DmamhKLtjN5WtsLTpNFcdrrYHQABAVFaUUINTl/ercTm4WvgQAbe5vAKTPQGhoqEv7thSTSepppGsmBkhb+7jR6PrnnCACmTorj40ACmAL0Lp16zB16lT8+9//9vVS3IIEkJ/QpUsXZGVlgWNWaIvPu7y/pvAMODB07doVWVlZ6i/QDWSLjpZnEJr4pLX2wnhTpkwBx3HQlF5qvugl4FbhS0AqfqmpyINGo8HkyZPdX7CbyBYdbXMuML4u8J3iHohgwrEFqN5jAcR///tfXLlyBZ9++qmvl+IWJID8BI7jcP311wMANMVnXd5fU3wOAJQ5/AFXWyO0VgHUpk0bDB06FACgzfvdY8fR5UnWn2uvvRbx8fEeO05jyBad5lxgOpvHyQpEEIGL7fc3ELN4SQD5EcOHDwcACGU5rjVJtdRAqMgDAFx99dWeWJpbNNcIVSYYuoPLwdDawlOA1aT6/Jy5GpoiSTj7KgBePhlqmzmr2D4uu80Iggg8bK1WgXj+JgHkR2RkZCA5ORkcEyGU5zq9n6b0MjgAbdu2RVJSkucW6CJKDaBmWiO05iBomT59+iAjIwOcaIG28LTq82sLToJjIjp37oyuXbuqPr8zyAKouSwwngM0HLPbhyCCAcetMAKzFxhjzO77G4jV/APrFW/lcByHvn37AoBLAkge269fP4+sy12cbo4ZBAKI4zglOF2bf1zdlHjGoL1yHIBUe8gXMMZsgqCbf27yGLIAEcGEQwEUoM1QTSYTLBaLcr+iosKHq3GPwHrFg4CePXsCAAQX6gEJlfl2+/oLzVWBlmntMUAyo0ePhk6ng1BdBL6yQLV5hfIc8MZyhIaG4rrrrlNtXlewFTI6J84qshuMLEBEMKHRSFmdnG1l+Nr/5ccChfqChyxAbrB06VK0bdsWBoMB/fr1w969e5scbzQa8eyzzyIzMxN6vR7t27fH8uXL7casW7cO3bp1g16vR7du3bB+/XpPPgVVkd0XQlWhc+0TRAv46mIAUiaZP+FqEHRrtgABQGRkJK655hoAkstKLbRXpLlGjRqFkJAQ1eZ1BVsBpGnGBQbUZYqRACKCCaUtDavLfpTFkLda1qhFfQFUXl7uo5W4j08F0Jo1a/D444/j2WefxaFDhzB8+HCMGzcO2dnZje4zbdo07NixA8uWLcPx48fx0Ucf2V349+/fj9tuuw3Tp0/HkSNHMH36dEybNg0HDhzwxlNqMenp6dDpdOBECzhj8yZFvqYUHGOIiIjweePT+jgrgIKpO/i4ceMAANqiM4BoaWa0E1hN0JScs5vbF8gCiAODxonMfa1NKjxBBAtKZXbRpvxD7Xkg0ARQaWmp3f2ysjIfrcR9fCqAFi1ahFmzZuH+++9H165dsXjxYqSnp+PNN990OP6rr77C7t27sXnzZlx//fXIysrCwIEDlRRjAFi8eDFGjx6NuXPnokuXLpg7dy5GjRqFxYsXe+lZtQxBEJCRkQEATtWMkcdkZmaCc6FmjDdQYoCaC4Kutfy2dhcYIAVDJyUlgbOaoClpXOg7i6boHDjRioyMDJ8FPwN1AkjLO1e6SHaBUQwQEUwYDAYAAGfz40f+31fWW3epL3hIALmAyWTCjz/+iDFjxthtHzNmDPbt2+dwnw0bNqB///54+eWXkZqaik6dOuHpp5+2sxzs37+/wZxjx45tdE5AMsOXlZXZ3XxJeno6AIA3ljYzEuBrpLXKosmfUARQM58yQxD1huJ5HqNHjwYAaAtang2mLTwFQPqM+1IAy5YcZ9xftuNIABHBRJ0AsrF8Wi12jwUK9S1A9e8HAj4TQAUFBbBarQ3StpOSkpCb6zgD6syZM/jmm2/w66+/Yv369Vi8eDE+/fRTPPLII8qY3Nxcl+YEgAULFiAqKkq5yQLEV6SkpAAAeGdcYMZyu338CVnQOOsCCwYBBEARQELZRcDi/nPmTJVKBqCvC2DKAqi5GkAy8jjbLBKCaO0o7Wls6rxxtf97u3VNSykpKWnyfiDg8yDo+r9aGWON/pIVRREcx2H16tUYOHAgxo8fj0WLFmHlypV2ViBX5gSAuXPnorS0VLlduHChBc+o5SQnJwNwTgBxpgq7ffwJZ9Pg5dYIwRADBEjuyg4dOoBjDNqic27Poyk6Aw5Ar169fF7/SbEAcc5ZgLQcWYCI4CM8PBxAneiR/jfZPRYoyIInXCva3Q8kfCaA4uPjIQhCA8tMfn5+oyfzlJQUpKamIioqStnWtWtXMMZw8eJFAJIQcGVOANDr9YiMjLS7+ZKEhAQA0i/85uBNUtyMvwVAAy50Bw+iIGgZOV1drt7sDtrafX2V+m6LLGQ0Tp5R5HEUBB34WCwW5OTkIC8vz257Tk4OWfjqUSeAbLIfawVQWFiYL5bkNsXFUvZxepgU0F1UVOTL5biF2wLo1KlT2LJli3LRcrWRm06nQ79+/bBt2za77du2bbMLarZl2LBhuHz5sl363YkTJ8DzPNLS0gAAQ4YMaTDn1q1bG53TH1EEkLmZoGDGwJkr7fbxJ5y1AOmCzAUGSP26AKmIJWd2XfhxxnIIlQXgeV5JrfcldS4w12KASAAFPleuXMEdd9yBmTNn2m2/4447cOXKFd8syk9RBJCl1vLJGDiLJIYiIiJ8tSy3kAVPergkcmVBFEi4LIAKCwtx/fXXo1OnThg/fjxycnIAAPfffz+eeuopl+Z68skn8d5772H58uU4evQonnjiCWRnZ+Ohhx4CILmm7rnnHmX8nXfeibi4ONx77734/fffsWfPHjzzzDO47777lAj6P/3pT9i6dSteeuklHDt2DC+99BK2b9+Oxx9/3NWn6jPkRpa8pcY+XbI+VhO42sfj4uK8sTSXcN4CZD8+GEhJSUHnzp2ltPHi8y7vr6l1nfXu3RuxsbEqr8516oKgnRtPFiAiGJG9C5zVJNV5E83galth2Ho2AgFZAGWES9eg4uJiiKITtev8CJcF0BNPPAGNRoPs7Gy7oK3bbrsNX331lUtz3XbbbVi8eDHmz5+Pq666Cnv27MHmzZuRmZkJQDKh2tYECg8Px7Zt21BSUoL+/fvjrrvuwsSJE/HGG28oY4YOHYqPP/4YK1asQK9evbBy5UqsWbMGgwYNcvWp+oyoqCilJkRT1gG+1kIUHh4OvV7vlbW5Qp0AanpcsAVBy4wYMQIAoCk+5/K+2tp9/MH6A7geA6ShGCAiCLG18nAWIzhz7TlSr/fLc3hTKAIoQrIAWSwWn2dQu4rLtbe3bt2KLVu2KC4nmY4dO+L8edd/yc6ePRuzZ892+NjKlSsbbOvSpUsDF1d9pkyZgilTpri8Fn+B4zjExsYiLy8PnLkKTO84OI6rjf+RLUb+hqsxQGazGRaLJeBKwrvLNddcg3feeQdCeQ5gMQIa506AnKkKQqXkWrj66qs9uUSnkWM9XM0Cs1qbsHASRCtDo9EgMjISZWVl4Cw1SjZYdHS0bxfmImazWRE7cXoRYRoRlRYexcXFAfVcXLYAVVZWOkzXKygoCDgF68/ILi05yNkRcoyQP7q/ABsB1ExciO3jwdQaIS0tDVlZWeAYg6bE+cxDuYBi165d/Sb2S7YACU7GAAkUA0QEKbKrizPXSCIIgef+kuN9BI4hTMsQrZdcX4WFhb5clsu4LICuueYarFq1SrnPcRxEUcTChQuVwE6i5chWHTnI2RG8n1uAZDGjbcYCpOWh+MGDzQ0mW3BcqQotj/UX6w9QZwESnKzFqK0dRwKICDZiYmIAAJylRnGBydsCBdn9Fall4DkgSiedvwMtENplX8PChQsxcuRIHDx4ECaTCXPmzMFvv/2GoqIifPvtt55YY1Aip7U3aQGqTZP3xxR4wPkYII4DdAJgtAaXBQiQMhs//PBDaMouAaII8M38JrGaIZRJiQf+lNnobhYYpUkTwYbsIuLM1UpF6EByGwF1Qieq1vITqRPttgcKLluAunXrhp9//hkDBw7E6NGjUVlZiVtuuQWHDh1C+/btPbHGoESuWyQXOnQEX/uYr4vgOcJisSjxHc25wABAxwenBahz586IiYkBZzVDqGi8WrmMUJYDjlmRkpKCrKwszy/QSWQh40wjVKDOUkQCiAg25KxNzlytWID8IZPTFWShIwufqAAVQG5FmyYnJ+OFF15Qey2EDbKokVtdOELuFu+PVaBthYwzVgG9wFBuDj4BxPM8Bg4ciC1btkBTehHWyDZNjteUSgU/Bw0a5FfNb+tigJwbL6fBUxYYEWwoFiBLjVIROtAsQHLV58jaKtDy31YvgPbs2dPk4/6SlhvoyL29uMbaYTAG3iSJI38UQLIriwNzKjNIFknB5gIDJDGzZcsWCKUXgfSBjQ9kzE4A+RMup8GTC4wIUpQYIHO10gk+0GKAZAEUURv7I/8NtIaoLgugkSNHNthm+0uU0lrVITU1FUBtMUSLCdDo7B7nzFXgRCt4nvdrAaQTpBif5pDjhILRItC/f39wHAehugScqRJM57gkPmcsA2+qgFarxVVXXeXdRTaD4gJz1gJEQdBEkCKLHd4mDT7QBJCcAh+ukSw/4drAFEAuxwAVFxfb3fLz8/HVV19hwIAB2Lp1qyfWGJSEhoYqfmG+puGHiq+RPoDJycl+WTdHdmXpnAyK1QZpDBAgVYft3LkzAEAou9zoOE3pJQBAjx49lMrn/kJdJWhqhUEQTVEXBF2XBRZoLrDycsn7IAsfWQjJ2wMFl6+cjuoVjB49Gnq9Hk888QR+/PFHVRZGAOnp6SgqKgJfUwox3L7eiyyKMjIyfLG0ZpEtOc4KIF0Qu8AAoF+/fjh27Bg0ZTmwxHd0OEbO/urXr583l+YUdS4w58ZrKAiaCFLq6gBVA7UusEAVQGG1Aii09q9tn85AQLVu8AkJCTh+/Lha0xGA0hKErylp8BhfXWI3xt+wdYE5gy6IXWAA0KdPHwC1IsdRY2HGoCmXssT69u3rzaU5hbtp8MH6fhPBi2IBCuA+YJWVUgkWQ22Nt9Dav/L2QMFlC9DPP/9sd58xhpycHPzrX/9C7969VVsYYSOAasWOLXx1sd0Yf0MpgkgWIKfo0aMHBEEAzJXgTBVgevvO0Hx1MTirEQaDAZ06dfLRKhtHFjLOxgBpqRkqEaRERESA53mlcWhoaCh0Ol0ze/kX1dVSj8oQjXTe1mvqftAEUjsjl1d51VVXgeM4sHq/UgcPHozly5ertjACaNu2LQBAqG6YWiiLIn+qBWOLYgHiGawiUGTkYbJpFFxQw0PHA7F6EQJPAshgMKBLly747bffIJTnwlJPAAm11p+ePXv65cnFXQsQCSAi2OB5HuHh4UogsdwhPpCoH+NZv52RP56jHOHyKs+ePWt3n+d5JCQkwGAwqLYoQkIWQJyxXMoWEOQO8TXgLZIC91cBpMQACZL4eWq/fZbD3APS/VeHFCMhRIS21gUWrAIIkMTNb7/9BqEir0EckFCRr4zxR+T321kBRBYgIpiJiooKaAFU//tuW+rEZDIhLMxxJqu/4bIA8leXS2skJiYG0dHRKCkpAV9dogRCy+6vNm3aOGxM6w+46gLTUkwIevToAaBO7Ngib+vevbtX1+QsdVlgcMriR+83EcxEREQ4/D9QqF/2guOkxqhWxgVUYoNTAuiNN95wesLHHnvM7cUQDWnXrh1++ukn8NXFNgJIakQnW4j8EVsXmDMEuwsMkLq7A7XuTTuLXzV4UwU4jkOXLl18uMLGsX2/nbL4kQAigpjw8HCH/wcKcvySbcgfzwFWFli1AJ0SQK+99ppTk3EcRwJIZdq2bYuffvoJQnUxZF3NV0kWoHbt2vluYc1QZwFybryOt98vGImLi0NiYiLy8/MhVBbAGilVA+crCwBIJQ/81bRcZxJ3bjy930QwYyt6/PU73RRKDLCDshf144P9GacEUP24H8J7yCKHtwmEloOi/dkCVBcD5KQFSCALEAB06tQJ+fn54KsKFQEk1AoguViiP+KuyzPY328iOLEVPYFoAeJ56ReMrdaR/xcEJ2uf+AGq1QEiPEMDAcSYkgHmzwLIVRcYuUQk5BR3oapQ2cZXSS7Pjh0dF0j0B+T3W++k4NXbCN5A+sVIEGpgG7vpr3GcTSGLHNHmq2ut/V8WR4GAW7lqFy9exIYNG5Cdnd3ggrVo0SJVFkZIKLWAzNWAxQjOagYnmiEIAtLS0ny8usYhF5h7OLb4SQKoffv2PlmTM9SlxTo3Xi58KYoizGZzwNVBIYiWEOgCSE5ztzDJB2YVAVbrDwuUFHjADQG0Y8cO3HTTTWjbti2OHz+OHj164Ny5c2CM+WWF2kAnNDRUiQvhq0vAiVK2TVpaGrRarY9X1zh1laDJBeYKdQKoFGAiIIpSGQT4t8VPFkDOWoBsLYM1NTUkgIigwrZsjL/19XMGvV4PADDVxjvbZnwGUkkcl21Vc+fOxVNPPYVff/0VBoMB69atw4ULFzBixAhMnTrVE2sMetLT0wEAQk2p3/cAk3G1FxjFhEgkJSVBr9eDY1ZwxnLwNaXgINUK8eeO0a4KIA0PaLjgbYBLBDe2oicQBZAscoxWyepjEqW/HMcp4igQcFkAHT16FDNmzAAgmbqqq6sRHh6O+fPn46WXXlJ9gUSdAOJsBJA/u78A911gwR4DZOva5ANE8Iqi6HIMkO1Yuaw+QQQLQ4YMwVVXXYV+/fqhf//+vl6Oy8hB3NW1AqjaIv0NCQkBxznZEdkPcNkFFhYWppzs2rRpg9OnTyvF2QoKCtRdHQGgTuzwxnJwVrPdNn+FXGDuk5aWhtOnT4OvKQNX2y1aFsH+iK2AMQhM+VXYHHqBodJCAogIPhISErB48WJfL8NtFAFUK3yqav8GWkabywJo8ODB+Pbbb9GtWzfceOONeOqpp/DLL7/gs88+w+DBgz2xxqCnTZs2AOwFkLzNX6FCiO4TaO93VVUVAKkSrLMWP6C2kaKxbn+CIAIDWehUWqQvfKVZ+htoNY1cFkCLFi1CRUUFAOD5559HRUUF1qxZgw4dOjhdMJFwjeTkZADSBRG1FoGUlBRfLqlZbHuBOYOOeoEp1AmgCqA26N2f329ZwBgEBles34Zaq19lZaUnlkUQhIeQ+5dVmKUvfGWtBSjQ+pq5LID+/ve/4+677wZjDKGhoVi6dKkn1kXYkJSUBADgrJKo4Hke8fHxvlxSs9TvFtwcZAGqQ3m/TRWKBUje5o/IP4hCNK7V8wnVkAAiiEAkKioKAFBeK4DKay1A8vZAweUg6MLCQtx4441IS0vDU089hcOHD3tgWYQtYWFhdqbF2NhYv6+14KoLzLYwntxnJlhJTEwEAPCmSnBmybqSkJDgyyU1iSxgQkkAEURQEB0dDQAoM0kSotzE2W0PFFwWQBs2bEBubi7mzZuHH3/8Ef369UO3bt3wz3/+E+fOnfPAEglA6hPl6H9/pSV1YYI9E0x+fzmrCRwT7bb5I7IFyF0BVF5ervqaCILwHHJJjvJaAVRa+9efS3U4wq2a1dHR0XjwwQfx9ddf4/z587j33nvxwQcfoEOHDmqvj6glNjbW4f/+iuICczEGyHbfYCU8PNyuMGBUVJRfF72UBUyY1jXLXZhWEkCygCIIIjCQLT2ltZafsmASQDJmsxkHDx7EgQMHcO7cOb+OUwh0bE2LgWBmVCxATrrAeK6uGGKwCyCO4+xOJP5+UikrKwMAhLtoAQrTiHb7EwQRGMg/wksVC5AkhPz9XFUftwTQrl278MADDyApKQkzZsxAREQEvvjiC1y4cEHt9RG12BbC8+eaMABgtVphNkvBu64UxtORAFIIJMFbZwFyTQCF144nAUQQgYUsdCotPCxinQUoELwTtrgcSZuWlobCwkKMHTsWb7/9NiZOnBhQvT8ClbvuugudOnUCz/N+XznUVsDoBYYaFwvjkQCyTyf198yKkpISAECEiy6w8NrxpaWlai+JIAgPEhkZCUEQYLVaUWriURKgLjCXBdBzzz2HqVOnBtwTDXT0ej2uvvpqXy/DKWQBw8G1wngGao2gYOtO9ucMMMBWALlmAZLHy/sTBBEY8DyPmJgYFBQUIK+KV3qBtXoL0IMPPuiJdRCtCFnAuF4Yz37/YGbmzJlK8cNx48b5eDVNowggnWsWIHk8CSCCCDxiY2NRUFCA8xWSjAgJCUFoaKiPV+Ua/l1MhghI6gSQa/tRc8w64uPjcdddd/l6GU5RXFwMAIhyUQBF6+re75qaGnKlE0QAIVt7LlZIJ/pA9Aq1KAuMIBwhCxhnG6HKGDQkgAINURRtBJCL77fAlMB3eQ6CIAIDWfBcqJTsKIHm/gJIABEeQK7s62prBNkCRM0xA4fy8nJYLFJ/ukgXLUAcV2c1KiwsVH1thPeZMGECVq1ahQkTJoDjOHpfWzFyduqlSsHufiBBAohQHVnAhLhoAQohARRwyBe4cK3oUsC7TLReEkAFBQVqLovwEdOmTUNGRgamTZsGxhjy8vJ8vSTCQ8jZqWYxMNtgACSACA+gxAC5aAGSx5MAChyuXLkCAIjRu9e/LYYEUKti7dq1yM7Oxtq1a8FxHBXHbcXUFzz+Xq7DERQETaiO4gIjC1CrRxYuJIAIANi0aRM2btwIjuPAGPPrHnZEy7CtVQYAERERPlqJ+5AFiFAdxQVG3cFbPfn5+QCAODcFUGztfvI8RGDDGLP7S7Re6gue+oIoECABRKiO3NzSVQEUQgIo4JBdYLFuCqA4AwkggghE6gsgsgARBOoETKjGtYuiPJ4EUOAgB7nGGtwUQGQBIoiApH7Rw0Arggj4gQBaunQp2rZtC4PBgH79+mHv3r2Njv3666/BcVyD27Fjx5QxK1eudDiG+kt5D9kCFOqmC0zen/B/cnNzAQAJBqtb+8fV7ldQUKA00CUIwv+pL3jCwsJ8tBL38WkQ9Jo1a/D4449j6dKlGDZsGN5++22MGzcOv//+u1338/ocP37czt9Yv1dSZGQkjh8/breNqsx6D3cFUAgJoIBCFEXFAhQf4p4FKErHoOUZzKKIK1euoE2bNmoukSAIDxESEtLk/UDApxagRYsWYdasWbj//vvRtWtXLF68GOnp6XjzzTeb3C8xMRHJycnKTRDsey5wHGf3eHJysiefBlEPdwVQGAmggKKgoAAWiwUCxxDjYhFEGY4D4mutQJcvX1ZzeQRBeBBBEKDVapX7Op3Oh6txD58JIJPJhB9//BFjxoyx2z5mzBjs27evyX379OmDlJQUjBo1Crt27WrweEVFBTIzM5GWloYJEybg0KFDTc5nNBpRVlZmdyPcp7y8HECdoHEWWTAZjUaYTCbV10WoiyxY4gwihBacSRJrrUeyO40giMDAVvSQAHKBgoICWK3WBoWykpKSGj0RpqSk4J133sG6devw2WefoXPnzhg1ahT27NmjjOnSpQtWrlyJDRs24KOPPoLBYMCwYcNw8uTJRteyYMECREVFKbf09HR1nmSQoliAtK5ZBUI0DBwkESSLKMJ/ycnJAQAkuhn/I5MQIu1/6dKlFq+JIAjvwXGc8n8gCiCfF0K0fQEBqX5E/W0ynTt3RufOnZX7Q4YMwYULF/DKK6/gmmuuAQAMHjwYgwcPVsYMGzYMffv2xZIlS/DGG284nHfu3Ll48sknlftlZWUkgtzEYrEoWVzhLlqAeE6yAlVaOFRUVFARNT9HFiwJbsb/yMgWIHKBEUTgUj8UJRDwmQUoPj4egiA0sPbk5+e7VD598ODBTVp3eJ7HgAEDmhyj1+sRGRlpdyPcwzZ+x9UYIAAI10r7kBvS/5EFUHJoyyxASWQBIgjCB/hMAOl0OvTr1w/btm2z275t2zYMHTrU6XkOHTqElJSURh9njOHw4cNNjiHUo7S0FIBU08eduJCwWrcZCSD/5+LFiwDqBIy7JNfuf/HiRaogTBCE1/CpC+zJJ5/E9OnT0b9/fwwZMgTvvPMOsrOz8dBDDwGQXFOXLl3CqlWrAACLFy9GVlYWunfvDpPJhA8//BDr1q3DunXrlDlfeOEFDB48GB07dkRZWRneeOMNHD58GP/5z3988hyDDVm4uOr+kiELUGDAGKsTQKEtc4ElhIjgwFBTU4PCwkLEx8ersUSCIDyMbbiKKLbsPOALfCqAbrvtNhQWFmL+/PnIyclBjx49sHnzZmRmZgKQgiyzs7OV8SaTCU8//TQuXbqEkJAQdO/eHZs2bcL48eOVMSUlJXjwwQeRm5uLqKgo9OnTB3v27MHAgQO9/vyCEUUAad0UQLXCSbYkEf5JUVERqqurwYEhsYUWIA0viaD8agEXL14kAUQQAYKtxdZisfhwJe7h8yDo2bNnY/bs2Q4fW7lypd39OXPmYM6cOU3O99prr+G1115Ta3mEi9QJIPd+Dcj7kQDyb+QfJgkhIrQqONJTQq3IrxZw4cIFXHXVVS2fkCAIj2NbvT0QS5f4vBUG0bqQhYvbFiBygQUEFy5cANDyAGgZeR55XoIg/Bur1Qqj0ajcr66u9uFq3IMEEKEqsgCKcLMycKSOLECBgCxUUlQSQPI8ti5vgiD8l/pNqwOxgj8JIEJVFAHUQgsQCSD/hgQQQQQ39a30gXjOJgFEqEqdC8w9C1BE7X4lJSVqLYnwALJQUVsA5ebm2pnVCYLwT4qKipq8HwiQACJURRYu7lqAIsgC5PcYjUalDUabMHUEUJSOIVQjQhRFKohIEAHAlStX7O4XFBT4aCXuQwKIUBVZAEW2MAaovLw8INMqg4FLly6BMUmwRLopdOvDceQGI4hAQv4R1Nj9QIAEEKEqdRYgd9PgpYaojDFqiOqn2Lq/Gmnb5xYkgAgicJDjANPDLHb3AwkSQIRqmM1mJTMgQueeZYDngLBaqwLFAfknskBpo1L8jwwJIIIIHM6ePQsAGJRkUu4HWjVoEkCEashxOzzHEOZmKwyAAqH9HVmgqFUDSCYlTHrfA/GXJEEEE0ajURFAAxON0PIM1dXVAffdJQFEqIYsWMI1DHwLXCOROrIA+TOKCyxM3V97thYgaopKEP7LiRMnYDabEakVkRQiol2E5Ab79ddffbwy1yABRKhGSwOgZSLJAuS3MMZUrwEkkxRiBQfpl2QgptQSRLDw448/AgA6R5vBcdJfADh06JAvl+UyJIAI1WhpEUSZCLIA+S2FhYWqNUGtj9wUFaA4IILwZw4cOAAA6BFrtvv7/fffB1T2LgkgQjWKi4sBuN8GQ4ZigPwX2fqTYFCnCWp95Liiixcvqj85QRAtJj8/H0ePHgUHhj7xUgB0xygLwrUiysrKcOTIER+v0HlIABGqobjAWmoBoiwwv0UuUqh2ALRMcggJIILwZ7Zt2wYA6BRtQbReOlcLPNA/QRJDW7du9dnaXIUEEKEaLW2EKiPHEJEA8j9kAZTkIQGUFCq99ySACML/sFqt2LRpEwBgeLJ9y5rhKdL9r7/+ukGfMH+FBBChGnUxQC0TQNQQ1X+RBVBiiGfqfSTVWoAuX77skfkJgnCfffv24fLlywjTiBiUZC+AOkRakB5ugdFoxMaNG320QtcgAUSohixYIt0sgigjZ4GRAPI/ZGGidgC0jDxvTk4OpcIThB/BGMMHH3wAALg21Qi9YP84xwE3pNcAAD755BPU1NR4e4kuQwKIUA1nOsFPmDABq1atwoQJE8BxHEqMDQsGhevqLEB0EfQfGGNKvx9PWYDiDSI4MNTU1FAqPEH4EXv37sWJEyeg4xluSK92OGZIkhEJBiuKi4uxbt06L6/QdUgAEapRJ4AaFy3Tpk1DRkYGpk2bBsYYCmqEBmPCNdLFVRRFVFRUeGaxhMuUl5crrU7iDZ6xAGl4IEYvvf+5ubkeOQZBEK5hMpnw1ltvAQBuyKhu1Mqv4YFb2lUBAFavXo3CwkKvrdEdSAARqsAYUwLfmhJAa9euRXZ2NtauXQuO4xxeSHUCoOOlOQIlmC4YyMvLAyDFeNU3f6tJvEG0Ox5BEL7lv//9Ly5fvowonYgbMxxbf2SGJJnQLsKCqqoqLF261EsrdA8SQIQqVFZWwmqVxIxswXHEpk2bcM8992DTpk1gjClplPWR3WgkgPwHWZDIAsVTkAAiCP/h9OnTWL36QwDA3R0rEaJpejzPATM6V4ADw44dO7Bv3z4vrNI9SAARqiALFR3PoGvCOiDH9DQX2yNbkUgA+Q9XrlwBAMR6yP0lE1srgOTjEQThG4xGI/75z3/CbLagT7wJAxNNTu3XNtKKGzKkIOiFCxcqRXL9DRJAhCqUl5cDAMJamAIvI3eTl+clfE9BQQGAuhgdTyHPLx+PIAjf8Oabb+L06dOI0Iq4r0sFOBeaXN/atgppYRYUFxfjH//4B0TRs+cNdyABRKiCIoA06mRtyS4wEkD+gyKAWljosjlkAUQWIILwHdu3b8fnn38OAHiwWwWiXCxvohOA2d0roOMZDh48iPfff98Dq2wZJIAIVZCztdQSQKFkAfI75LR0V0+ErhJVK7D81WxOEK2dkydPYuHChQCAiZlV6B1ndmuetHArZnaWrg3vv/8+9u7dq9oa1YAEEKEKsgAKbWEfMBl5HjntmvA9cpmDKA9bgCKpGS5B+IwrV65g7ty5MBqN6BVnwq3tms76ao6rU0wYkybN8Y9/vIgTJ06osUxVIAFEqIIsVEIEdQSQPA8JIP9Btsi0tNdbc8g1RmpqagKimixBtBYqKysxd+5cFBQUIDXMgoe7VYB3Ie6nMW7vUIUesSbU1Bjx17/+1W8yPEkAEaqgCCCVXWAkgPwH2R0ZoZKVrzEMAoPAkQuUILyJ2WzGvHnzcOrUKURqRTzZqxxhKn3XNTzwaI8KpIZZUFBQgDlz5vhFhi8JIEIVqqqk6p8GlSxA8jzyvIRvMZvNijUmVCWR2xgcV3cMqgROEJ5HFEUsWLAABw8ehF5geLJ3GRJUbncTqmF4unc5YvRWnD9/Hn/96199buElAUSoQnW15ONVTQBp6twghO+xtcSpZeVrCgqCJwjvwBjDkiVLsHPnTggcwx97lKNdpGdqfcUZRDzTuxyhGhG//vor5s2bB4vF4pFjOQMJIEIVZKGiV+niqK8VUrKwInyL/D7oeKZKTEBzyO8/CWCC8Czvv/8+1q9fDw4MD3StQC83M76cJS3ciid7lUPHMxw4cAD/+te/fFYjiAQQoQqKAOJVEkA8CSB/wmg0AqgTJs4yYcIErFq1ChMmTADHcSgxOqee5OPIxyUIQn3Wr1+PlStXAgDu7lSFocnOVXpuKZ2iLfhjj3IIHMP27dvxn//8p9nuAJ6ABBChCvKFSqeSC0xb207DZPLOF5JoGlngal0UuNOmTUNGRgamTZsGxhgKapzroqolAUwQHmXXrl144403AAA3Z1VhdJp3ra294814oKsU47du3Tp8+OGHXj0+QAKIUAlZAGlV+kTJ3eBJAPkHcqNbjYvur7Vr1yI7Oxtr164Fx3GId7KPmIa3Py5BEOpx6NAh/POf/wBjDKNSazC5rW9+aAxNNuHujlJ84bJly/Dll1969fjN9HUlCOcwmyW/sasWgsbQkADyK2Qh4kovIADYtGkTNm7cCI7jwBhDtN65z4eso/2xfxBBBDLnz5/H//3f/8FstmBAghHTO1W6/L1WkzHpNSgx8dh4PgSvvPIKEhMT0a9fP68cmyxAhCrIkfyCSl8k2dLgywwBog5ZAPGcawJX9uu76t+XA61JABGEepSWlmLu3LmorKxExygz/qBSocOWMrVdFYYmGWG1WvHcc88hOzvbK8clAUSogixUNC5eIBtD4O3nJXwLz0tvCIN3zpbyp4jz5U9TgmhFWK1WvPjii7h8+TISDFb8qWc5dM6F5HkcjgPu61KBjlFmVFZW4rnnnvNKDTgSQIQq1FkI1JlPrgRMMSD+gSBIZ0rRS4ka8nHk4xIE0TL++9//4ocffoCOZ/hTr3Kl5Yy/oBOAP/YoR4xOxLlz5/Daa695/JgkgAhVUesHu+00vkiPJOzxtgCy1h5HtjwRBOE+x44dU9LdZ3SuREa4f/6wjNYzPNKjHBwYtm3bhl27dnn0eHR2IVRBjtXwhMOCBJDv0ev1AACT1TsuKXPtceTjEgThHlarFa+++iqsVisGJhpxdbJ/19bqFG3BTVlSVtobb7zh0WrwJIAIv4QsQP6FwWAAABhF7wgg+TghISFeOZ6vyc7Oxj//+U/861//wuXLl329HKIV8eWXX+LkyZMI1Yi4x8cZX84yKasaKaFWFBcX44MPPvDYcUgAEapQFySrDra5P+QG8T2yADJZveMGMwaJBaiyshJLlizBrFmzsHXrVnz11VeYOXMm3n77bSoCSbQYi8WiCIib21b7XdxPY2h44M7a+kD/+9//UFxc7JHj0JWFUAU5RsSq0vdLtIkBoUwg3xMeHg5AygKrtnj+/ag0S8eIiIjw+LF8yd/+9jesW7cOZrMZ1tA4WENiYTKZ8NFHH+HFF1/09fKIAOfbb79FXl4eIrUirmsTWH31esWa0S7CAqPRiE2bNnnkGD4XQEuXLkXbtm1hMBjQr18/7N27t9GxX3/9NTiOa3A7duyY3bh169ahW7du0Ov16NatG9avX+/ppxH01AXJqnNxlOehLCD/QKfTKdaYSg8LIMbqjtHaBdDZs2cBAKak7qjqdhOquk+CKaGz3WME4S7bt28HAAxPMfpNyruzcBxwbaok2uTnoTY+rQS9Zs0aPP7441i6dCmGDRuGt99+G+PGjcPvv/+OjIyMRvc7fvw4IiMjlfsJCQnK//v378dtt92Gv//975g8eTLWr1+PadOm4ZtvvsGgQYM8+nyCGY1G+ihZVKpbJ8+j1WrVmZBoMRERETAajagwc0j0YGhOjRWwstYlgKxWK0pKSlBQUIDc3FycP38eR44cUUz7ojYEQnkuREMkREM0AODy5ct45pln0Lt3b2RmZiIpKQnx8fGIioqiHwZEs4iiiMOHDwMA+id6pqJ+UQ2P3GoeySEiYg3qFy3tn2DC8mMM586dQ1FREWJjY1Wd36cCaNGiRZg1axbuv/9+AMDixYuxZcsWvPnmm1iwYEGj+yUmJiI6OtrhY4sXL8bo0aMxd+5cAMDcuXOxe/duLF68GB999JFrC6ysBBydaAQBqI2JUMY1Bs8DtoGcroytqpJ+DjuC44DQUPfGVlcDTVXYDQtzeaxWq4VOFCEaRXAm+/G8CTBYraixeS11ogieMfAmEZzQcH6zlVfmhdEINFUQMTS0Lv++ubEhIdLrDAAmE1DbwqPFYw2Gus+KK2PNZml8Y+j1QK24dGmsxSK9Fo2h0wGyuHRybGxsLIquXEFFJQPXyMmO8YBsWOYZg06s/1moe78Zj7qmXyIDZ5E+v+VVPAxWKwwGA0JEUfrOaLXSOgDp89hUfIxGI70WgPSdaKqgmitjBQFWrRYlJSUoLS1FeW4uysvLUVFRYXerrKxEeVUViqurUVZWhrKyMpiKix0G8xsA1EQkwXDpR+n4HAdLan8IkenQFp/DL999h1+++04ZLwKwaLWIiIhAVFQU4kJCEB4WhvDwcISFhSEiIgLh4eHSLSICYQkJiIyMRHR0NKK0WgiNxdO18BxhaKReF1f/9aypAZqq7WU7b3NjXfneB+E5Ij83F+aSEkTwDFk6EzgTwASurly/lYFrImahubFf5xqw4nQERCbVf7u3cwVGtDHafZcdztvI994RYTzQJsyKS5UanDx+HIN69Wr8dbA9RzgL8xFGo5EJgsA+++wzu+2PPfYYu+aaaxzus2vXLgaAZWVlseTkZHbdddexnTt32o1JT09nixYtstu2aNEilpGR0ehaampqWGlpqXK7cOECA8BKpVNSw9v48fYThIY6HgcwNmKE/dj4+MbH9u9vPzYzs/Gx3brZj+3WrfGxmZn2Y/v3b3xsfLz92BEjGh8bGqoMe+KJJ9i+2NjGxwJsxIgRym1XU68DwPY81oONGDGC3XrrrYzNmNHkWJafX7fe2bObHnv2bN3Yp59ueuyvv9aNnTev6bHff1839uWXmx67a1fd2H//u+mxGzfWjV2xoumxa9fWjV27tumxK1bUjd24semx//43Y4yxP//5z+xPvXs3ObZodBI7+JdebMSIEezBPn2aHFsyMoGdf6EHO/9CD3b5kQ5Nr+Hpp+vWe/Zs02Nnz64bm5/f9NgZM+rGVlQ0OfbrhAS7z3BTY/fFxtqNreJ5h+PydDp27YgRbOHChez8+fNs4cKF7LoRI1ieTudw/NGICLt5c/T6RtdwJjTUbuyZps5TLThH1AwZ0uhYa0iI/bzjxzf9ftgyZUrTYysq6sbSOUKimXNE/rR05TuXPy29ybEFN6cqY/Puymz+c3vtCHZobi+WOzOryXmLRicp8+Y82K7JsSUjE9ijk4ewESNGsD1vvtn061B7jigtLWUAWGlpKWsOn8UAFRQUwGq1IikpyW57UlIScnNzHe6TkpKCd955B+vWrcNnn32Gzp07Y9SoUdizZ48yJjc316U5AWDBggWIiopSbunp6S14ZsGJ2unKcr2ZYEmDDgTi4uJ8vQSfwhhzeR9RFw5LZArAOT7VXgoNhQhg2rRpyMjIwLRp02AFcKmRz72oDYUpoTMsESkQdWEOx3gbXRNuakpgaJ04/NyKQF61+pJCMUJ5oCsAx9z5VqvA5cuXkZqain379mHIkCHK9n/84x/44IMPGgQ2N8bEiRPBcRw2bNgAQArWfP/993HHHXcoY1avXo1Zs2ahpsZxFLzRaITRxgVQVlaG9PR0lF6+bBdrpEAusAZjX3zxRezZuhW3t6vA6DR7d0pBNY+530c7dIEtGFiC+JCG8x8u1eHVX6LQqVMnvLNkCZm3XR3rARfYqlWrsHLZMlybWIWZnR27ihgPWHkeRUYezMpgNUufSS0nvUUxelHp89aYKfyrbD3WnQ3Dtddeiz//+c/S4z52gV26dAmf/e9/+P3MGQBQ3FqVlZUOG7aKHAeTjbupMReRCA4mgceECRMwbdo0rF27Fps2bYLWysAxEVy9whIiAJPN90hvtTZafJTjeWijohAZGYmIiAhozWZ069oVN998M5KTk+sNbvk5orq6GpMnT1Y2f/XVVw3HkgvM9bFuniPOnj2Lhx9+GCEaEa8PLQHHQTUXWJGRxxMH4zD+xrrP7ZebN+LVwcWI1VlVc4ExHnjhcDROl2nx/HPPYWRTcby154iysjJERUWhtLTU8fXbBp/FAMXHx0MQhAaWmfz8/AYWnKYYPHgwPvzwQ+V+cnKyy3Pq9XrH9UbCwuy/kI3hzBh3xtqekNQc64pVxcmxISEhMPE8KjgNmM7+iy1aeTvxA0C5OIg6HsyB27ZG5JV5odfXXaSaw5WxOp3zPmNPjdVq64SImmM1mrqTokpjk5KSIHIccixaMF3jv/QEAAkORK0E77hWFM+B6aSTba5VhxpBQFxGhuPvC887/z3iOFXGpnbqhD8+80yD7YwxVFdX28UAVVVVobKyUokHqqioUGKFysrKUFpaiuLiYhQXFyviadOmTdi4cSM4jgNjDKbaWCqe5xEbG4uYmBhERUUhIiJCuYXZxP6Eh4cjNDRU+T88PBwhISHuW2DcOUfw9b7njl5L2x+OzeHKWDpHNBjbpmNHmHU61FitKBA1DX9oCpwkcpyh3tgYnRTzs3LzRmzcuBECD8zsVFEbCF33XW4WvumxIgMuVEjnprbt27t2/XQCnwkgnU6Hfv36Ydu2bXa/GrZt24ZJkyY5Pc+hQ4eQkpKi3B8yZAi2bduGJ554Qtm2detWDB06VJ2FEw4JrRVgatWIqaqdJ0zlDzzhPvKPiIJqz2YgFdRI4qqBlcIP4TgOoaGhCA0NRWJiokv7yplhFosFhYWFyM3NRXJysuJq1Gg0iI6Opowvwi30ej06deqEo0eP4kihFqPSmrDyusGINkb0jDUjr5pHkoeywI4Va2ASOURERCAtLU31+X2aBfbkk09i+vTp6N+/P4YMGYJ33nkH2dnZeOihhwBIGVyXLl3CqlWrAEgZXllZWejevTtMJhM+/PBDrFu3DuvWrVPm/NOf/oRrrrkGL730EiZNmoT//e9/2L59O7755hufPMdgQU5XrlJZALWWNOjWgHwCKjDysIh1Vmy1ya2SLvipqameOYCfIAiCInaSkpLQrVs3H6+IaG2MGDECR48exd5cPa5LNareBiPW4BnhI7M3V7ICXnPNNR75IeBTAXTbbbehsLAQ8+fPR05ODnr06IHNmzcjMzMTAJCTk4Ps7GxlvMlkwtNPP41Lly4hJCQE3bt3x6ZNmzB+/HhlzNChQ/Hxxx/j//7v//C3v/0N7du3x5o1a6gGkIeRKwWrVSSPLED+R1xcHAwGA2pqanClmkdKmPonPosIXKm1ALV2AdTaMBgMCA8PR0VFha+XQtQyZswYLFu2DGfKgKMlGnSLaSL2yc8oqObxXZ7kJpwwYYJHjuFTAQQAs2fPxuzZsx0+tnLlSrv7c+bMwZw5c5qdc8qUKZgyZYoayyOcRLbUVJgbmgVi9SJeHVIMkwjMPRADAFgwqBg6XnrMEfI8zQWxEd6D4zikpaXh1KlTyKkSPCKArtTwEBkHg8GA+Ph41ecnPIdcmZ/wH2JjY3HjjTfi888/x8enwvB8/1LwAfIWrTkdCivj0LdvX3Tt2tUjx/B5KwyidSAXpiw3N/x2CbwUFBtvYyqNN4hICKnLCKpPWe08jRW8JHxDVlYWAOBylWfiUi5VSr/JMjIyqAkuQajAjBkzEBYWhnPlGmy/6EJguQ/5uVCLA/l68DyPhx9+2GPHoTMMoQpRUVEAgHKTOh8peR55XsI/kN3TslBRm0sVkrCShRZBEC0jJiYGDzzwAADJqnKp0r+D6svNHJYdlUIqJk+ejI4dO3rsWCSACFWIiZFcW+VmTunk3hJKawWQPC/hH8jC5GKFZ06iF2tPzrLQIgILH5WVI5rhpptuQv/+/WEWOfz713AY1a8pqAoiA97+LRzFJh7p6emKcPMUJIAIVYiOjgbP82DgUGZquZO5tHaOYK8+7G906NABAHCpUlCt8a0t2bXCSj4OQRAth+d5zJ07F7GxsbhUqcG7R8NV+aGqNp+dCcHPRTro9XrMmzcPBldqQbkBCSBCFQRBUOJ1Shpxg+l44N0RhXh3RCGaqKMHoxWoqW2GSgLIv0hOTkZYWBgsjEOOynFARmtdCjwJIIJQl7i4ODz//PPQaDT4Pl+P9Wf9q83QvlwdNpyX6sk99dRTXjkHkAAiVEPO2ik2Ov5YcRygF6RbU8ki8v4Gg0EpsEj4BxzHoX379gCA8+XqCqALFRowcIiJiUFsbKyqcxMEAfTq1QtPPfUUAOB/50Kx+7KTFbE9zO9FklUKAO644w6MGTPGK8clAUSoRkJCAgCgqKZlHyt5f1cr6xLeoVOnTgCAc+XqBkKfqxVUnTp1onRqgvAQ48aNw9133w0AWHE8DIcLnGyz4SGyywW8/kskrIzDiBEjPB73YwsJIEI1FAHUiAXIWeT9SQD5J507dwYAnFVZAJ0t09jNTxCEZ5g1axbGjh0LkXH4968ROFHim5KAeVU8Fh6JRLWVQ+/evfHXv/7Vq+UvSAARqiELlsKalrlG5P1JAPknskA5X65RNRD6TK2gki1MROBBlrvAgOM4PPPMMxg8eDBMIodFP0coCQjeosTIYeHhSJSaeLRv3x4vvvii46bkHoQEEKEacvPKgha6wAKpGWYwkpaWhrCwMJhETklbbynVFuBy7VyeqvpKeB5Kgw8cNBoNnn/+efTo0QNVFh4LD0cir8o7kqDSLImf/BoBbdq0wcsvv+yTvo8kgAjVUEsAXSEB5NfwPK+IlDNl6pjOz5ZLAdBJSUmU+UcQXsJgMGDBggVo3749Sk08Xj4ciRKjZ614Riuw6OcIXKjUIC4uDq+++qrPvvMkgAjVSElJASBlcZlb4Bq5Ui1ZApKSktRYFuEBZAF0qlQdAXS6dh6y/hCEd4mIiMDLL7+MNm3a4EqNgFeORCrNqNXGKgL//jUCJ0u1CA8Px8KFC5Xrhi8gAUSoRnR0NAwGAxg4FFS799GyiEBhbRB0mzZt1FweoSLdu3cHAJwqUyeDRJ5HnpcgCO8RFxeHV155BTExMciu0OD1nyNUL3TKGLDyeBiOFOqg0+mwYMECtGvXTt2DuAgJIEI1OI5DamoqACC/2r3YkMLabuA6nY5cIX5Mt27dAEiFCx01wHUFxuosSfK8RGBCQdCBixyLExISgqMlWiw7FgY1Q7q+OB+C3TkG8DyPefPmoWfPnupN7iYkgAhVkQVQnpsCSN6vTZs21A3cj4mMjERGRgaAlrvB8qp5lJt5aLVajzY+JDwPBUEHNh07dsQLL7wAnufxba4BG8+r04rih3wdPj0jFbV97LHHMGzYMFXmbSl0hSFURRZAuW66wGQBJM9D+C89evQA0HIBdLJUcn917twZOp2uxesiCMJ9Bg4ciD/96U8AgE/PhLa4UOKFCgHv1FZ5vvXWW3HzzTe3dImqQQKIUJW0tDQAdT2dXCW3Ng0zPT1dtTURnkGO1zlR2rIT5MlaAeUPJnGCIIBJkybhpptuAgOHt34PxxU3f9BWWzi88UsEjFYO/fr1w8MPP6zySlsGCSBCVVoqgPJq95PnIfwX2QJ0pqxlBRFlAUQB0AThP/zxj39E165dUWXh8Z/fwt36jq84Hoa8agGJiYl47rnnoNH4puJ0Y5AAIlRFttwU1vAwWV3f/3KtACILkP+TkZGByMhImEUO591si1Fh5nCpUtpXFlQEQfgerVaL559/HuHh4ThTpsWGc651j9+fq8N3eXol6DkqKspDK3UfEkCEqsTExCA8PBwMnMuB0CarJJwAKAG2hP/CcZwiWk64GQckW3/S09MRHR2t1tIIglCBpKQkPPHEEwCkLC5n22WUmTisOhEGALjnnnv81rpLAohQFY7jFOtNjotusLxqAQwcwsPD6WIYILRcAGnt5iEIwr8YNWoUrrnmGlgZhxXHwiA6kej30akwVFqkHl9y53l/hAQQoTqy9eayi32i5PEZGRlUTyRAkIXLyRKtWzVDTpaQ+4sg/J3HHnsMoaGhOF2mxf7cpjM1T5Vq8G2uXmm46m9xP7aQACJUJzMzE0BdPI+zyOPl/Qn/p3PnztBqtSgz88h3MVPEItZ1gCcBRBD+S3x8vGLJ+eRMaKOtjhgD1pyW6v3ccMMN6NKli7eW6BYkgAjVcdcClGNjASICA71ej06dOgGoi+dxlvPlGphFzq6oIkEQ/smtt96K+Ph4FBkF7M3ROxxztFiD4yVaaLVa3HvvvV5eoeuQACJUJysrC4CUCu+Mv1jmElmAAhLFDeZiPSBZMPXo0YNcngTh5+j1etx5550AgC+zQxye2zdfkDLFbrzxRiQmJnpzeW5BAohQneTkZGi1WphETsnqag6R1dUOIgEUWNQJINcsQFT/hyACi3HjxiEiIgJ51QJ+LrT/wZNbxePnQh04jsPUqVN9tELXIAFEqI5Go1EywS456Qa7Us3DLHLQarVITk725PIIlZEbmF6qFFBtcd6Sc6qMBBBBBBIhISEYO3YsAGB3PTeY7BYbOHBgwLQyIgFEeARXA6HlcRkZGRAE96pIE74hLi4OycnJYOBwusw5K1BhDY9iowCe59G5c2cPr5DwFtQMtfUzbtw4AMCRAh1+vKLF4QLptj9Pb/d4IOC/+WlEQCMLIGctQPI4OX6ICCy6d++O3NxcnCrVoEesudnxslDq0KEDQkJcqzBLEITvaNeuHTIyMpCdnY3Xf4m0e8xgMGDw4ME+WpnrkAAiPIIsZJzNBJPHUfxPYNKtWzfs2LEDZ5y0AJ2ujf/p2rWrJ5dFeBkKZm/9cByHhx56CKtXr4bVarXbfsMNN8BgMPhwda5BAojwCLap8IwBzZ0XL9f2gyIBFJjI9T5Ol2mcer9lCxAJIIIIPIYOHYqhQ4f6ehkthmKACI+QlpYGnudRbeVRYmr6ashYXQwQucACkw4dOkCj0aDczKOgmcw/qwicKycBRBCEbyEBRHgEnU6nZALI3b4bo8jIo8bKQRCEgMkeIOzR6/Vo164dAOBsM53hL1cJMIkcQkNDlWxBgiAIb0MCiPAYzlaElh9PTU31674xRNPI2Vxnm4kDkh/v1KkTeJ5OQQRB+AY6+xAeQ47naa4rfA4VQGwVKAKovOn3W3Z/yS00iNYDBUETgQQJIMJjOG0BqqIeYK2Bjh07AgCyKzRNdoY/VyuQSAC1PqgOEBFIkAAiPIbTFiBqgtoqaNu2LQRBQIWZR5HR8alFZJJAAuoEE0EQhC8gAUR4DDnAtcTEN9kiIYcsQK0CnU6nZPGdb8QNllfFwyRy0Ov1SEtL8+LqCIIg7CEBRHiM8PBwxMTEAAByqhx/1KotHEpM0mOUERT4yJlgFxvJ/LtQu122FhEEQfgKEkCER5GtOrmNuMFkYRQTE4Pw8HCvrYvwDO3btwcAZFc4fr8v1G6XhRLRuqAgaCKQIAFEeBTZzdGYAMqr3U7Wn9ZB27ZtAQAXGxFAF2vjf0gAEQTha0gAER5FEUDVji+I8naKB2kdyAIor1qARWz4+CWq+E0QhJ/gcwG0dOlStG3bFgaDAf369cPevXud2u/bb7+FRqPBVVddZbd95cqV4Diuwa2mpsYDqyeaQxY2ec1YgEgAtQ4SEhIQEhICK+OQV0/0mkUpCBogAUQQhO/xqQBas2YNHn/8cTz77LM4dOgQhg8fjnHjxiE7O7vJ/UpLS3HPPfdg1KhRDh+PjIxETk6O3S2QOtS2JuTWFvnVjj9qebXbqQVG64DjOEXcXKpX/ym3SgADh7CwMMTFxflgdQRBEHX4VAAtWrQIs2bNwv3334+uXbti8eLFSE9Px5tvvtnkfn/4wx9w5513YsiQIQ4f5zgOycnJdjfCN7Rp0wYAUGnhUWFuGCApWwlIALUe5Hiu+nFfuTblDihYtnVChRCJQMJnAshkMuHHH3/EmDFj7LaPGTMG+/bta3S/FStW4PTp05g3b16jYyoqKpCZmYm0tDRMmDABhw4dUm3dhGsYDAbEx8cDQAOXSJWFQ4VZ+gjKQokIfGQBVL/0QQ4FvBME4Uf4TAAVFBTAarUiKSnJbntSUhJyc3Md7nPy5En85S9/werVqxttmtmlSxesXLkSGzZswEcffQSDwYBhw4bh5MmTja7FaDSirKzM7kaoR0pKCgDgSj03mOwWi46ORmhoqNfXRXiGxi1A0vtN8V6tF7LsEYGEz4Og639hGGMOv0RWqxV33nknXnjhhSZ7CA0ePBh33303evfujeHDh2Pt2rXo1KkTlixZ0ug+CxYsQFRUlHKjX6jqIlt36gugK7UWIVkgEa2DurgvewGUT+5OgiD8CJ8JoPj4eAiC0MDak5+f38AqBADl5eU4ePAgHn30UWg0Gmg0GsyfPx9HjhyBRqPBzp07HR6H53kMGDCgSQvQ3LlzUVpaqtwuXLjQsidH2CHHYNW/IBbUSB8/EkCtC/n9LDfzqLbUbScBRBCEP+EzAaTT6dCvXz9s27bNbvu2bdswdOjQBuMjIyPxyy+/4PDhw8rtoYceQufOnXH48GEMGjTI4XEYYzh8+HCTF1m9Xo/IyEi7G6EesgAqrKlnAaq9T0HqrYvw8HDlOyRb+UxWKC1PSPC2XigImggkHAfSeIknn3wS06dPR//+/fH/7d15WBPX+gfwb4ImgSSsgqAiSwEBARHF/QpetSgV7XWvqCDWjbrWqnUDlLrX5emiVetSbSt6cSlqtdhWW1tEwRJtFUEpCv6EekUUtSpi3t8fNFOGRdECUfJ+nodH58yZM2fmTGbenDmZ6dixIzZs2ICcnByMHz8eQGnPzP/93/9h27ZtkEql8PLyEi1vY2MDhUIhSl+wYAE6dOgAV1dXFBUV4YMPPoBGo8HHH39cp9vG/qYLcG48FPcAFTwona6sx4+93GxtbVFUVIQbD6Rorn4sBL/Gxsb8BYMx9kLQawA0ZMgQFBQUYOHChcjLy4OXlxe+/vprODg4AADy8vKe+kyg8m7duoWxY8ciPz8fZmZmaN26NX788Ue0a9euNjaBVYMuwCl4IAURoBvipbsFxgFQ/WNra4vMzEzceGAE4NFf/5a2NQ+UZYy9CPQaAAFAZGQkIiMjK523devWJy4bExODmJgYUdrq1auxevXqGqodqwm6n8E/0kpw55EEprLSbvKbfwVANjY2eqsbqx1lg14AKHjIwS5j7MWi91+BsfpPJpPBwsICAHDzrwvhw8elD0cEOACqj6ytrQEAhX+1Nwe7jLEXDQdArE7oLny6C+HNMmNCVCqV3urFaocuANIFvLpASJfOGGP6xgEQqxO622C6XwIVFvMFsT7TtXdhuQCI3wHGGHtRcADE6kT5C+Ktv/7VpbP6RRfo3C4uHfiuC3y5vRljLwoOgFid0F0Qy/cIWFpa6q1OrPbo2rVYK8GDxxLcLub2Zoy9WDgAYnVCd+HTXQh1//ItkfpJoVAI73crfChBUXHpT985AGKMvSg4AGJ1oqoAiC+I9Ze5uTmA0rfAE0oDIDMzMz3WiDHG/sYBEKsTfwdAEtG/up/Hs/pHF+zEXVICKH1FRoMGen/0GKtFuhdV89O+2cuAAyBWJ3SBzp2/BsXe4R6ges/R0REA8Mdf7wPTPeGd1V+TJ09GmzZtEB0dre+qMPZU/HWM1Qnd7ZASKh0UW/SoNADiWyL116RJk9CpUyeUlJRAIpHAx8dH31VitczR0RErV67UdzUYqxYOgFidkMvlUCgUePDgAYqKS1+JAfwdGLH6x8TEBP/617/0XQ3GGKsU3wJjdUbX2/PHfSNoiQfFMsYY0x8OgFidKRsAAaU/lZbJZPqsEmOMMQPFARCrM2q1GgDwx5+lhx3/UoQxxpi+cADE6owu4NH1AOkCIsYYY6yucQDE6ozure83/noTPL8FnjHGmL5wAMTqjC7g+R/3ADHGGNMzDoBYndEFQMXa0l+AKZVKfVaHMcaYAeMAiNWZ8gEP3wJjjDGmLxwAsTqjezt4VdOMMcZYXeEAiNUZa2vrJ04zxhhjdYVfhcHqTKtWrTBnzhzcuHEDarUaPXv21HeVGGOMGSgOgFidkUqlePXVV/VdDcYYY4xvgTHGGGPM8HAAxBhjjDGDwwEQY4wxxgwOB0CMMcYYMzgcADHGGGPM4HAAxBhjjDGDwwEQY4wxxgwOB0CMMcYYMzgcADHGGGPM4HAAxBhjjDGDwwEQY4wxxgwOB0CMMcYYMzgcADHGGGPM4PDb4CtBRACAoqIiPdeEMcYYY9Wlu27rruNPwgFQJe7cuQMAsLe313NNGGOMMfas7ty5AzMzsyfmkVB1wiQDo9Vqce3aNajVakgkEn1Xp84UFRXB3t4eubm5MDU11Xd1WC3j9jYs3N6GxVDbm4hw584dNGnSBFLpk0f5cA9QJaRSKZo1a6bvauiNqampQX1gDB23t2Hh9jYshtjeT+v50eFB0IwxxhgzOBwAMcYYY8zgcADEBHK5HNHR0ZDL5fquCqsD3N6GhdvbsHB7Px0PgmaMMcaYweEeIMYYY4wZHA6AGGOMMWZwOABijDHGmMHhAKgOODo6Ys2aNfquBivj8uXLkEgk0Gg0/7is+tq+4eHheP311/VdjVqzdetWmJub67saL7XAwEBMnTpVmK6vnwVWPxlEABQeHg6JRAKJRIIGDRqgefPmmDBhAgoLC/VdtVp38+ZNTJ06FY6OjpDJZLCzs8OoUaOQk5Oj76rVGENt36oCFI1GA4lEgsuXL9d5nQyR7vhbunSpKH3fvn3/+Enyjx8/xpIlS+Du7g5jY2NYWlqiQ4cO2LJlyz8qt7akpKRg7Nix+q7GS+f69esYN24cmjdvDrlcDltbWwQFBeHEiRMASgNLiUSCuLi4Csu2bNkSEokEW7duFaUnJSUhODgYFhYWUCgU8Pb2xsqVK/H48WMApV8AdOfNqv6OHTtWZT6FQlHr+6W2GUQABAC9evVCXl4eLl++jE8//RT79+9HZGSkvqtVq27evIkOHTrg22+/xdq1a3Hp0iXs3LkTWVlZ8Pf3x++//16r63/06FGtll+WPtq3uLi4Vst/2RERSkpK9F2NWqU7xhUKBZYtW1bjQXdMTAzWrFmD2NhYnD9/HkePHsWYMWNe2ODe2toaJiYm+q7GS2fAgAE4c+YMPvvsM2RmZiIhIQGBgYG4efOmkMfe3r5C4JucnIz8/HwolUpR+t69exEQEIBmzZrh6NGjuHDhAqZMmYJFixZh6NChICIMGTIEeXl5wl/Hjh0xZswYUVqnTp0AlD5Numx6Xl4erly5Uvs7praRAQgLC6N+/fqJ0t5++22ytLQUpktKSigiIoIcHR1JoVCQm5sbrVmzptJyVqxYQba2tmRpaUmRkZFUXFws5Pnjjz+oT58+pFAoyNHRkT7//HNycHCg1atXC3muXLlCffv2JaVSSWq1mgYNGkT5+fnC/OjoaGrVqhVt2rSJ7O3tSalU0vjx46mkpISWLVtGjRs3Jmtra3rvvfeeuN3jx48npVJJeXl5ovQ///yTmjZtSr169SIiok8++YSaNGlCjx8/FuULCQmhkSNHCtMJCQnk5+dHcrmcnJycKCYmhh49eiTMB0Dr1q2jvn37komJCUVFRdHNmzdp2LBh1KhRI1IoFOTi4kKbN28Wlpk5cya5urqSsbExOTk50bx580T7szr7Qi6Xk4eHh6juAEipVFKvXr1IoVCQg4MDdevWTWhfJycnAkBpaWnCMv369SMbGxuSyWQklUpJJpPRqFGjhPoEBATQqFGjhGXlcrle27ey45qIKC0tjQBQdnY2ERFt2bKFzMzM6PDhw+Tu7k5KpZKCgoLo2rVrwjIlJSU0bdo0MjMzI0tLS5oxYwaNHDlSVL5Wq6Vly5aRk5MTKRQK8vHxof/+97/C/KNHjxIAOnz4MLVp04YaNmxI33//PWk0GgoMDCSVSkVqtZr8/PwoJSWFiIhu3LhBQ4cOpaZNm5KxsTF5eXnRl19+KdqegIAAmjhxIk2ZMoXMzc3JxsaG1q9fT3fv3qXw8HBSqVTk7OxMX3/9dYW6HDhwgHx8fEgul1O7du3o7NmzQh7dfinreY7xsLAw6tOnD7m7u9OMGTOEvHv37qXyp9j4+Hjy9PQkmUxGDg4O9P7771fRuqVatWpFMTExT8xz6NAh6ty5s9B2r732Gl26dEmYn52dTQBo586d1KVLF1IoFNS2bVvKyMigU6dOUZs2bYRj4vr168JyuuMrJiaGrK2tSa1W09ixY+nhw4eitpkyZYowXf6zAIA2btxIr7/+OhkbG5OLiwt99dVXovp/9dVX5OLiQgqFggIDA2nr1q0EgAoLC5+43fVFYWEhAaBjx45VmcfBwYHeffddksvllJOTI6SPGTOGJk2aRGZmZrRlyxYiIrp79y5ZWVlR//79K5STkJBAACguLq7CvPJtqVPZ56S+MMgAKCsrizw9Palx48ZCWnFxMUVFRdGpU6fo999/p88//5xMTExo586donJMTU1p/PjxlJ6eTvv37ycTExPasGGDkKd3797k5eVFSUlJlJqaSp06dSJjY2PhpKDVaql169bUpUsXSk1NpeTkZPLz86OAgAChjOjoaFKpVDRw4EA6d+4cJSQkkEwmo6CgIJo0aRJduHCBNm/eTADoxIkTlW7z48ePydzcnMaOHVvp/EWLFpFEIqGCggIqKCggmUxG3377rTD/5s2bJJPJ6JtvviEiosOHD5OpqSlt3bqVsrKyKDExkRwdHUUnZwBkY2NDmzZtoqysLLp8+TK99dZb5OvrSykpKZSdnU1HjhyhhIQEYZnY2Fj6+eefKTs7mxISEqhx48a0bNmyZ9oXnTt3Fu2LrKwsAkASiYQ2btxIGRkZNHv2bJJIJLRz5076/fffafXq1QRAWNe1a9dILpeTXC6nIUOG0O7du8nX15ekUqnQvgEBAWRkZESNGjWiHTt2UHx8vN7al+jZAqCGDRtSjx49KCUlhU6fPk0eHh40bNgwYZlly5aRmZkZxcfH0/nz52n06NGkVqtF5c+ZM4fc3d3p8OHDlJWVRVu2bCG5XC6cuHVBh4+PDyUmJtKlS5foxo0b1LJlSxo+fDilp6dTZmYm7dq1izQaDRERXb16lVasWEFpaWmUlZVFH3zwARkZGVFycrKw3oCAAFKr1RQbG0uZmZkUGxtLUqmUevfuTRs2bKDMzEyaMGECWVlZ0b1790R18fDwoMTERDp79iz16dOHHB0dhYC2/In9eY9xXTvs2bOHFAoF5ebmElHFACg1NZWkUiktXLiQMjIyaMuWLWRsbCxcuCoTFBREXbt2FQUm5cXHx9Pu3bspMzOT0tLSKCQkhLy9vYUvNLoASNd258+fpw4dOpCfnx8FBgbSTz/9RL/88gu5uLjQ+PHjhXLDwsJIpVLRkCFD6LfffqMDBw6QtbU1zZkzR9Q2TwuAmjVrRl9++SVdvHiRJk+eTCqVigoKCoS6NWzYkN555x26cOEC7dixg5o2bWpQAdCjR49IpVLR1KlT6cGDB5Xm0e3Xvn37UmxsLBER3bt3j0xNTSktLU0UAO3Zs4cAUFJSUqVlubm5VXre4ACongoLCyMjIyNSKpWkUCgIAAGgVatWPXG5yMhIGjBggKgcBwcHKikpEdIGDRpEQ4YMISKijIwMAiA6eaenpxMA4aSQmJhIRkZGoij+3LlzBIBOnTpFRKUXSBMTEyoqKhLyBAUFkaOjo6iXpkWLFrRkyZJK656fny9ab3m6D8nJkyeJiKhv374UEREhzF+/fj3Z2toK2/qvf/2LFi9eLCpj+/btZGdnJ0wDoKlTp4ryhISE0KhRoyqtQ2WWL19Obdq0Eaarsy/CwsIIAMlkMlH7duzYUVR2+/btacKECUT090Whe/fuREQ0f/58atKkiah9c3NzCQAFBwcTEZG/v/8L07667a5uAARA1Cvw8ccfi74A2NnZ0dKlS4XpR48eUbNmzYTy7969SwqFosJJdfTo0fTGG28Q0d9Bx759+0R51Go1bd26tcrtKC84OJimT58uTAcEBFCXLl2E6ZKSElIqlTRixAghLS8vTxQw6upS9ptuQUEBGRsbC19qyp/Yn/cYL9sOHTp0ED5H5QOgYcOGUc+ePUXLzpgxgzw9PavcF+fOnSMPDw+SSqXk7e1N48aNE/V0Veb69esEgH799Vci+vtY//TTT4U8O3bsIAD03XffCWlLliyhFi1aiLbL0tJSCCqJiNatW0cqlUo4TqsTAM2bN0+Yvnv3LkkkEjp06BAREc2aNYu8vLxE9Z87d65BBUBEpUGshYUFKRQK6tSpE82ePZvOnDkjzNft13379tErr7xCWq2WPvvsM2rdujURkSgAWrp06RP3X9++fSv0mBM9OQDS9aiX/St/LL+MDGYMULdu3aDRaHDy5ElMmjQJQUFBmDRpkijPJ598grZt28La2hoqlQobN26sMFi4ZcuWMDIyEqbt7Oxw/fp1AEB6ejoaNGiAtm3bCvPd3d1FvzRJT0+Hvb097O3thTRPT0+Ym5sjPT1dSHN0dIRarRamGzduDE9PT0ilUlGabt3Piv56ALhukGZoaCh2796Nhw8fAgC++OILDB06VNjW06dPY+HChVCpVMKf7n7xn3/+KZRbdtsBYMKECYiLi4Ovry9mzpyJpKQk0fz4+Hh06dIFtra2UKlUmD9/foV9Xp19YW5ujtDQUKF9AWDMmDGicpRKJbZv3w5ra2u0bNkSAJCfny9sX15eHq5evQozMzOoVCq4u7sDAK5evQoA+PPPPyGRSF6K9i3PxMQEr7zyijBd9ri9ffu2MAZAp/xxfP78eTx48AA9e/YUHQPbtm1DVlaWaF3lj4G3334bb775Jnr06IGlS5eK8j9+/BiLFi2Cj48PrKysoFKpkJiYWOEY8PHxEf5vZGQEKysreHt7C2mNGzcGgAr7q+w2WVpaokWLFqJ2KOt5j/Gyli1bhs8++wznz5+vMC89PR2dO3cWpXXu3BkXL14UBqaW5+npid9++w3JyckYNWoU/vjjD4SEhODNN98U8mRlZWHYsGFwdnaGqakpnJycAOCJ+1C3v8rvw/L7r1WrVqIxPR07dsTdu3eRm5tb5T4or+x6lUol1Gq1sJ6MjAz4+/uL8rdr167aZdcXAwYMwLVr15CQkICgoCAcO3YMfn5+FQY2v/baa7h79y5+/PFHbN68GREREVWWqTvHV5b+rIPz1Wo1NBqN6O9FHYj/LAwmAFIqlXBxcYGPjw8++OADPHz4EAsWLBDm79q1C9OmTUNERAQSExOh0WgwatSoCgNdGzZsKJqWSCTQarUAKgYVlanq4CufXtl6nrTu8qytrWFubl7piRgALly4AIlEIlwUQ0JCoNVqcfDgQeTm5uL48eMYPny4kF+r1WLBggWiD8Cvv/6Kixcvin4NUH4wXu/evXHlyhVMnToV165dQ/fu3fHOO+8AKB3AN3ToUPTu3RsHDhxAWloa5s6dW619Xj7NyMgIpqamQvsCpb/C0dm1axd++OEHNGnSBImJiTh48CCAvwexarVa2NvbC4Gy7i8sLAympqaidb8I7QuUDky8fft2hfRbt24BAMzMzJ64vqpOkJXR1ePgwYOi/XP+/HnEx8eL8pY/BmJiYnDu3Dm89tpr+P777+Hp6Ym9e/cCAFauXInVq1dj5syZ+P7776HRaBAUFPTMx4Bu3z5pf5XPW9k2Ps8xXlbXrl0RFBSEOXPmVJhX2bFRnTaQSqXw9/fHtGnTsHfvXmzduhWbNm1CdnY2gNLPbkFBATZu3IiTJ0/i5MmTACoO0q9sf5VPq87+K7t8dTztnPk8+6Q+UigU6NmzJ6KiopCUlITw8HBER0eL8jRo0AAjRoxAdHQ0Tp48idDQ0ArluLm5AUCVgf6FCxfg6ur6THWTSqVwcXER/TVt2vSZyngRGUwAVF50dDTef/99XLt2DQBw/PhxdOrUCZGRkWjdujVcXFwqfLN9Gg8PD5SUlCA1NVVIy8jIEC5IQOk3upycHNE3qPPnz+P27dvw8PD4ZxtVhlQqxeDBg/Hll18KvRw69+/fx9q1axEUFARLS0sAgLGxMfr3748vvvgCO3bsgJubG9q0aSMs4+fnh4yMjAofAhcXF1GvRWWsra0RHh6Ozz//HGvWrMGGDRsAAD///DMcHBwwd+5ctG3bFq6urjX6y4KDBw+K2lepVKJ79+5o3bo1HB0dRXn9/Pxw69YtmJiYiLbN3Nxc6AUzMTGBVqt9IdoXKO19+u233/DgwQNRekpKCqytrWFhYVGtcszMzGBnZ4fk5GQhraSkBKdPnxamPT09IZfLkZOTU6H9y/Z2VcXNzQ3Tpk1DYmIi+vfvL3x7PH78OPr164fhw4ejVatWcHZ2xsWLF6tV7+oou02FhYXIzMwUevbK+yfHeFlLly7F/v37K/R2enp64qeffhKlJSUlwc3NTdSr/DSenp4AgHv37qGgoADp6emYN28eunfvDg8Pjxr9hdiZM2dw//59YTo5ORkqlQrNmjWrkfLd3d2RkpIiSiv7+TJknp6euHfvXoX0iIgI/PDDD+jXr1+ln/FXX30VlpaWWLlyZYV5CQkJuHjxIt54441aqfPLpoG+K6AvgYGBaNmyJRYvXoyPPvoILi4u2LZtG7755hs4OTlh+/btSElJEbqTq6NFixbo1asXxowZgw0bNqBBgwaYOnUqjI2NhTw9evSAj48PQkNDsWbNGpSUlCAyMhIBAQFP7Fp/HosWLcJ3332Hnj17Yvny5fDy8kJ2djbmzZuHR48e4eOPPxblDw0NRUhICM6dOyfq/QGAqKgo9OnTB/b29hg0aBCkUinOnj2LX3/9Fe+9916VdYiKikKbNm3QsmVLPHz4EAcOHBACARcXF+Tk5CAuLg7+/v44ePCg0DNQEyQSCUaMGIF169bh4sWLKCoqgq+vLzIzM/Hhhx+K8r711ltYuXIlUlNTcerUKTRq1AiXLl3CkSNH0KhRIwClAZCDg8ML076hoaGIjY3FiBEjMGvWLFhYWODEiRNYsmQJZs+e/UxlTZkyBUuXLoWrqys8PDywatUqUWCnVqvxzjvvYNq0adBqtejSpQuKioqQlJQElUqFsLCwSsu9f/8+ZsyYgYEDB8LJyQlXr15FSkoKBgwYAKD0GNi9ezeSkpJgYWGBVatWIT8/v8aCxYULF8LKygqNGzfG3Llz0ahRoyof7vi8x3h53t7eCA0NrXCMTZ8+Hf7+/oiNjcWQIUNw4sQJfPTRR1i7dm2VZQ0cOBCdO3dGp06dYGtri+zsbMyePRtubm5wd3eHVCqFlZUVNmzYADs7O+Tk5ODdd9+tdl2fpri4GKNHj8a8efNw5coVREdHY+LEic8UED7JuHHjsGrVKsyaNQujR4+GRqMRbvv802covSwKCgowaNAgREREwMfHB2q1GqmpqVi+fDn69etXIb+Hhwdu3LhR5eMGlEol1q9fj6FDh2Ls2LGYOHEiTE1N8d133wmfxcGDBz9THYmowhdpALCxsamxY0EfXt6a14C3334bGzduRG5uLsaPH4/+/ftjyJAhaN++PQoKCp7rOTJbtmyBvb09AgIC0L9/f4wdOxY2NjbCfIlEgn379sHCwgJdu3ZFjx494OzsjJ07d9bkpgEAGjVqhOTkZHTr1g3jxo2Ds7MzBg8eDGdnZ6SkpMDZ2VmU/9///jcsLS2RkZGBYcOGieYFBQXhwIEDOHLkCPz9/dGhQwesWrUKDg4OT6yDTCbD7Nmz4ePjg65du8LIyEh4mFe/fv0wbdo0TJw4Eb6+vkhKSsL8+fNrbPuHDx+Oo0ePwtvbG+np6QgICMDMmTPRvn170cUdAJo0aYLg4GAQEYKCguDl5YUpU6ZAJpOJTsQ9e/Z8YdrXzMwMx48fBxHh9ddfR6tWrbB8+XLExsZi+vTpz1TW9OnTMXLkSISHh6Njx45Qq9X4z3/+I8oTGxuLqKgoLFmyBB4eHggKCsL+/fuf+CXByMgIBQUFGDlyJNzc3DB48GD07t1buP08f/58+Pn5ISgoCIGBgbC1ta3Rp08vXboUU6ZMQZs2bZCXl4eEhATIZLJK8z7vMV6Z2NjYCrdy/Pz8sGvXLsTFxcHLywtRUVFYuHAhwsPDqyxHt49DQkLg5uaGsLAwuLu7IzExEQ0aNIBUKkVcXBxOnz4NLy8vTJs2DStWrHjm+lale/fucHV1RdeuXTF48GCEhIQgJiamxsp3cnJCfHw89uzZAx8fH6xbtw5z584FAMjl8hpbz4tMpVKhffv2WL16Nbp27QovLy/Mnz8fY8aMwUcffVTpMlZWVqIvXuUNHDgQR48eRW5uLrp27YoWLVpg1apVmDt3LuLi4p45uCwqKoKdnV2Fv5oao6gvEjLUG66sXpNIJNi7d2+9fpUDq9qxY8fQrVs3FBYW8usunlN4eDhu3bolGktXFxYtWoRPPvnkmQZaM/Y8DPYWGGOMMf1bu3Yt/P39YWVlhZ9//hkrVqzAxIkT9V0tZgA4AGKMMaY3Fy9exHvvvYebN2+iefPmmD59+jOPYWPsefAtMMYYY4wZHIMeBM0YY4wxw8QBEGOMMcYMDgdAjDHGGDM4HAAxxhhjzOBwAMQYY2WEh4eLnh8VGBiIqVOn6q0+jLHawT+DZ4yxJ9izZ0+FF3oyxl5+HAAxxtgT6F4YzBirX/gWGGNMb+Lj4+Ht7Q1jY2NYWVmhR48euHfvHlJSUtCzZ080atQIZmZmCAgIwC+//CJaViKRYP369ejTpw9MTEzg4eGBEydO4NKlSwgMDIRSqUTHjh2RlZUlLBMTEwNfX1+sX78e9vb2MDExwaBBgyq8G66s8rfAHB0dsXjxYkRERECtVqN58+bYsGGDaJmkpCT4+vpCoVCgbdu22LdvHyQSCTQaTU3sNsZYDeAAiDGmF3l5eXjjjTcQERGB9PR0HDt2DP379wcR4c6dOwgLC8Px48eRnJwMV1dXBAcH486dO6IyYmNjMXLkSGg0Gri7u2PYsGEYN24cZs+ejdTUVACo8FqFS5cuYdeuXdi/fz8OHz4MjUaDt95665nqvnLlSrRt2xZpaWmIjIzEhAkTcOHCBQDAnTt3EBISAm9vb/zyyy+IjY3FrFmz/sGeYozVCmKMMT04ffo0AaDLly8/NW9JSQmp1Wrav3+/kAaA5s2bJ0yfOHGCANCmTZuEtB07dpBCoRCmo6OjycjIiHJzc4W0Q4cOkVQqpby8PCIiCgsLo379+gnzAwICaMqUKcK0g4MDDR8+XJjWarVkY2ND69atIyKidevWkZWVFd2/f1/Is3HjRgJAaWlpT91Wxljd4B4gxphetGrVCt27d4e3tzcGDRqEjRs3orCwEABw/fp1jB8/Hm5ubjAzM4OZmRnu3r2LnJwcURk+Pj7C/xs3bgwA8Pb2FqU9ePAARUVFQlrz5s3RrFkzYbpjx47QarXIyMiodt3LrlcikcDW1hbXr18HAGRkZMDHxwcKhULI065du2qXzRirGxwAMcb0wsjICEeOHMGhQ4fg6emJDz/8EC1atEB2djbCw8Nx+vRprFmzBklJSdBoNLCyskJxcbGojLK/zpJIJFWmabXaKuuhy6P7tzrK/ypMIpEI6yCiCmURv3KRsRcOB0CMMb2RSCTo3LkzFixYgLS0NMhkMuzduxfHjx/H5MmTERwcjJYtW0Iul+PGjRs1ss6cnBxcu3ZNmD5x4gSkUinc3NxqpHx3d3ecPXsWDx8+FNJ045EYYy8ODoAYY3px8uRJLF68GKmpqcjJycGePXvwv//9Dx4eHnBxccH27duRnp6OkydPIjQ0FMbGxjWyXoVCgbCwMJw5c0YItAYPHgxbW9saKX/YsGHQarUYO3Ys0tPT8c033+D9998H8Gy9TIyx2sUBEGNML0xNTfHjjz8iODgYbm5umDdvHlauXInevXtj8+bNKCwsROvWrTFixAhMnjwZNjY2NbJeFxcX9O/fH8HBwXj11Vfh5eWFtWvX1kjZQOl27d+/HxqNBr6+vpg7dy6ioqIAQDQuiDGmXxLim9OMMQMRExODffv21fnzeL744guMGjUKt2/frrGeLMbYP8NPgmaMsRq2bds2ODs7o2nTpjhz5gxmzZqFwYMHc/DD2AuEAyDGGKth+fn5iIqKQn5+Puzs7DBo0CAsWrRI39VijJXBt8AYY4wxZnB4EDRjjDHGDA4HQIwxxhgzOBwAMcYYY8zgcADEGGOMMYPDARBjjDHGDA4HQIwxxhgzOBwAMcYYY8zgcADEGGOMMYPDARBjjDHGDM7/A66ykAYQdsWRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.violinplot(data=model_lbfgs_melted[model_lbfgs_melted['met']=='ba'], \n",
    "               x='sampling', y='value', hue='set',)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--')\n",
    "plt.title('BA Values for Baseline Model, lbfgs solver')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### liblinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation took 158.0603621006012 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_liblinear = pd.DataFrame(find_model(X_train, y_train, X_val, y_val, \n",
    "                                          algorithm='LogisticRegression', solver='liblinear',\n",
    "                                          multiclass=True))#.to_csv('da_lr_lbfgs.csv')\n",
    "end_time = time.time()\n",
    "duration_liblinear = end_time-start_time\n",
    "print(f\"Operation took {duration_liblinear} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>scaling</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_ba</th>\n",
       "      <th>train_mcc</th>\n",
       "      <th>train_cf</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_ba</th>\n",
       "      <th>val_mcc</th>\n",
       "      <th>val_cf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.739</td>\n",
       "      <td>[[1636, 402, 180, 48], [370, 1539, 137, 220], ...</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.428</td>\n",
       "      <td>[[60, 22, 15, 0], [142, 506, 39, 68], [7, 1, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>none</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.756</td>\n",
       "      <td>[[1726, 384, 125, 31], [395, 1539, 125, 207], ...</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.412</td>\n",
       "      <td>[[62, 20, 14, 1], [157, 486, 38, 74], [9, 1, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.776</td>\n",
       "      <td>[[76, 15, 5, 2], [10, 75, 2, 11], [4, 2, 88, 4...</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.379</td>\n",
       "      <td>[[66, 17, 12, 2], [192, 423, 42, 98], [8, 1, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>none</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.521</td>\n",
       "      <td>[[63, 215, 14, 0], [23, 2212, 27, 4], [12, 62,...</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.482</td>\n",
       "      <td>[[26, 65, 6, 0], [17, 728, 6, 4], [9, 23, 36, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.322</td>\n",
       "      <td>[[878, 331, 811, 246], [481, 597, 820, 368], [...</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.085</td>\n",
       "      <td>[[0, 42, 1, 54], [0, 380, 2, 373], [0, 25, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.288</td>\n",
       "      <td>[[800, 364, 837, 265], [473, 669, 761, 363], [...</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.048</td>\n",
       "      <td>[[0, 87, 0, 10], [0, 653, 0, 102], [0, 60, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.749</td>\n",
       "      <td>[[1669, 327, 192, 78], [377, 1568, 126, 195], ...</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.042</td>\n",
       "      <td>[[47, 0, 50, 0], [302, 0, 453, 0], [19, 0, 49,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.751</td>\n",
       "      <td>[[1678, 334, 183, 71], [379, 1570, 126, 191], ...</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.037</td>\n",
       "      <td>[[38, 0, 59, 0], [259, 0, 496, 0], [14, 0, 54,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.733</td>\n",
       "      <td>[[1722, 307, 182, 55], [404, 1484, 133, 245], ...</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.044</td>\n",
       "      <td>[[32, 0, 65, 0], [177, 0, 578, 0], [10, 0, 58,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.784</td>\n",
       "      <td>[[1755, 337, 145, 29], [375, 1602, 119, 170], ...</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.040</td>\n",
       "      <td>[[32, 0, 65, 0], [190, 2, 563, 0], [11, 0, 57,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.476</td>\n",
       "      <td>[[48, 233, 11, 0], [19, 2218, 28, 1], [10, 66,...</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.039</td>\n",
       "      <td>[[31, 0, 66, 0], [170, 0, 585, 0], [11, 0, 57,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.444</td>\n",
       "      <td>[[71, 212, 9, 0], [30, 2221, 12, 3], [4, 121, ...</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.038</td>\n",
       "      <td>[[33, 0, 64, 0], [172, 0, 583, 0], [13, 0, 55,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.732</td>\n",
       "      <td>[[1716, 313, 178, 59], [404, 1476, 139, 247], ...</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.047</td>\n",
       "      <td>[[24, 0, 73, 0], [94, 0, 661, 0], [7, 0, 61, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.482</td>\n",
       "      <td>[[49, 229, 14, 0], [17, 2220, 28, 1], [10, 67,...</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.038</td>\n",
       "      <td>[[28, 0, 69, 0], [143, 0, 612, 0], [10, 0, 58,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.783</td>\n",
       "      <td>[[1758, 335, 143, 30], [375, 1597, 121, 173], ...</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.039</td>\n",
       "      <td>[[25, 0, 72, 0], [132, 0, 623, 0], [8, 0, 60, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.685</td>\n",
       "      <td>[[1581, 368, 234, 83], [420, 1411, 146, 289], ...</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.050</td>\n",
       "      <td>[[20, 0, 77, 0], [69, 0, 686, 0], [5, 0, 63, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.840</td>\n",
       "      <td>[[1846, 337, 69, 14], [347, 1716, 97, 106], [5...</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.029</td>\n",
       "      <td>[[42, 0, 55, 0], [255, 0, 500, 0], [21, 0, 47,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.687</td>\n",
       "      <td>[[1559, 390, 239, 78], [425, 1412, 147, 282], ...</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.050</td>\n",
       "      <td>[[17, 0, 80, 0], [50, 0, 705, 0], [4, 0, 64, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.594</td>\n",
       "      <td>[[1277, 219, 752, 18], [266, 1139, 708, 153], ...</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.061</td>\n",
       "      <td>[[0, 6, 91, 0], [0, 138, 617, 0], [0, 5, 63, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.311</td>\n",
       "      <td>[[9, 277, 6, 0], [2, 2254, 10, 0], [2, 132, 69...</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.042</td>\n",
       "      <td>[[14, 0, 83, 0], [39, 0, 716, 0], [4, 0, 64, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.192</td>\n",
       "      <td>[[31, 24, 33, 10], [19, 33, 28, 18], [33, 11, ...</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.037</td>\n",
       "      <td>[[7, 0, 0, 90], [21, 0, 0, 734], [1, 0, 0, 67]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.311</td>\n",
       "      <td>[[9, 277, 6, 0], [2, 2254, 10, 0], [1, 133, 69...</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.031</td>\n",
       "      <td>[[8, 0, 89, 0], [24, 0, 731, 0], [2, 0, 66, 0]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.854</td>\n",
       "      <td>[[85, 7, 4, 2], [10, 82, 2, 4], [3, 1, 92, 2],...</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.024</td>\n",
       "      <td>[[7, 0, 90, 0], [28, 0, 727, 0], [2, 0, 66, 0]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.755</td>\n",
       "      <td>[[76, 14, 5, 3], [10, 77, 3, 8], [8, 2, 84, 4]...</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.033</td>\n",
       "      <td>[[3, 0, 94, 0], [7, 0, 748, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.755</td>\n",
       "      <td>[[76, 14, 5, 3], [11, 75, 4, 8], [7, 2, 85, 4]...</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.033</td>\n",
       "      <td>[[3, 0, 94, 0], [7, 0, 748, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.595</td>\n",
       "      <td>[[1278, 217, 754, 17], [267, 1138, 705, 156], ...</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.029</td>\n",
       "      <td>[[0, 0, 97, 0], [0, 17, 738, 0], [0, 0, 68, 0]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.624</td>\n",
       "      <td>[[70, 13, 9, 6], [19, 56, 5, 18], [10, 2, 80, ...</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.053</td>\n",
       "      <td>[[2, 0, 95, 0], [0, 0, 755, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.432</td>\n",
       "      <td>[[38, 242, 12, 0], [13, 2226, 24, 3], [8, 86, ...</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.053</td>\n",
       "      <td>[[2, 0, 95, 0], [0, 0, 755, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.739</td>\n",
       "      <td>[[1660, 355, 187, 64], [382, 1562, 122, 200], ...</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.036</td>\n",
       "      <td>[[2, 0, 95, 0], [2, 0, 753, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.805</td>\n",
       "      <td>[[1751, 355, 123, 37], [369, 1659, 108, 130], ...</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.004</td>\n",
       "      <td>[[66, 0, 31, 0], [506, 0, 249, 0], [45, 0, 23,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.564</td>\n",
       "      <td>[[83, 198, 11, 0], [33, 2202, 27, 4], [11, 54,...</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.004</td>\n",
       "      <td>[[66, 0, 31, 0], [512, 0, 239, 4], [45, 0, 23,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.775</td>\n",
       "      <td>[[1751, 335, 152, 28], [383, 1616, 106, 161], ...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.701</td>\n",
       "      <td>[[73, 13, 8, 4], [13, 71, 3, 11], [7, 4, 82, 5...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.688</td>\n",
       "      <td>[[1353, 234, 675, 4], [291, 1232, 662, 81], [2...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.668</td>\n",
       "      <td>[[1317, 224, 719, 6], [294, 1202, 675, 95], [4...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.633</td>\n",
       "      <td>[[67, 14, 11, 6], [16, 61, 5, 16], [10, 3, 81,...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 292, 0, 0], [0, 2266, 0, 0], [0, 203, 0, ...</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 97, 0, 0], [0, 755, 0, 0], [0, 68, 0, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.574</td>\n",
       "      <td>[[51, 12, 34, 1], [10, 60, 25, 3], [5, 2, 86, ...</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.249</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>[[0, 0, 66, 31], [0, 0, 520, 235], [0, 0, 45, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.308</td>\n",
       "      <td>[[22, 264, 6, 0], [8, 2247, 9, 2], [4, 147, 52...</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.246</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>[[0, 31, 66, 0], [0, 243, 512, 0], [0, 23, 45,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.578</td>\n",
       "      <td>[[51, 12, 34, 1], [10, 60, 25, 3], [5, 2, 87, ...</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>[[0, 0, 66, 31], [0, 0, 558, 197], [0, 0, 45, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.717</td>\n",
       "      <td>[[63, 3, 31, 1], [4, 68, 25, 1], [3, 1, 92, 2]...</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>[[0, 0, 67, 30], [0, 0, 570, 185], [0, 0, 45, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.303</td>\n",
       "      <td>[[21, 265, 6, 0], [9, 2247, 9, 1], [4, 148, 51...</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>[[0, 31, 66, 0], [0, 202, 553, 0], [0, 23, 45,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.578</td>\n",
       "      <td>[[1181, 277, 778, 30], [275, 1120, 713, 158], ...</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>[[0, 30, 67, 0], [0, 186, 569, 0], [0, 23, 45,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.577</td>\n",
       "      <td>[[1181, 277, 778, 30], [277, 1119, 714, 156], ...</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>[[0, 30, 67, 0], [0, 185, 570, 0], [0, 23, 45,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sampling                      scaling  train_accuracy  train_f1  \\\n",
       "22   RandomOverSampler                         none           0.804     0.801   \n",
       "0                SMOTE                         none           0.817     0.815   \n",
       "11  RandomUnderSampler                         none           0.832     0.831   \n",
       "33         no_sampling                         none           0.853     0.828   \n",
       "4                SMOTE                   Normalizer           0.483     0.471   \n",
       "26   RandomOverSampler                   Normalizer           0.460     0.451   \n",
       "23   RandomOverSampler                 MaxAbsScaler           0.812     0.809   \n",
       "24   RandomOverSampler                 MinMaxScaler           0.813     0.811   \n",
       "8                SMOTE    MaxAbsScaler + Normalizer           0.799     0.797   \n",
       "1                SMOTE                 MaxAbsScaler           0.838     0.835   \n",
       "34         no_sampling                 MaxAbsScaler           0.844     0.810   \n",
       "40         no_sampling  Normalizer + StandardScaler           0.838     0.807   \n",
       "9                SMOTE    MinMaxScaler + Normalizer           0.798     0.795   \n",
       "35         no_sampling                 MinMaxScaler           0.845     0.812   \n",
       "2                SMOTE                 MinMaxScaler           0.837     0.835   \n",
       "30   RandomOverSampler    MaxAbsScaler + Normalizer           0.763     0.760   \n",
       "3                SMOTE               StandardScaler           0.880     0.878   \n",
       "31   RandomOverSampler    MinMaxScaler + Normalizer           0.764     0.761   \n",
       "5                SMOTE    Normalizer + MaxAbsScaler           0.676     0.677   \n",
       "41         no_sampling    MaxAbsScaler + Normalizer           0.816     0.751   \n",
       "15  RandomUnderSampler                   Normalizer           0.393     0.395   \n",
       "42         no_sampling    MinMaxScaler + Normalizer           0.816     0.751   \n",
       "14  RandomUnderSampler               StandardScaler           0.890     0.890   \n",
       "12  RandomUnderSampler                 MaxAbsScaler           0.816     0.816   \n",
       "13  RandomUnderSampler                 MinMaxScaler           0.816     0.816   \n",
       "6                SMOTE    Normalizer + MinMaxScaler           0.676     0.677   \n",
       "19  RandomUnderSampler    MaxAbsScaler + Normalizer           0.717     0.715   \n",
       "43         no_sampling  StandardScaler + Normalizer           0.835     0.795   \n",
       "32   RandomOverSampler  StandardScaler + Normalizer           0.804     0.802   \n",
       "25   RandomOverSampler               StandardScaler           0.853     0.851   \n",
       "36         no_sampling               StandardScaler           0.864     0.845   \n",
       "10               SMOTE  StandardScaler + Normalizer           0.831     0.830   \n",
       "21  RandomUnderSampler  StandardScaler + Normalizer           0.776     0.775   \n",
       "7                SMOTE  Normalizer + StandardScaler           0.751     0.749   \n",
       "29   RandomOverSampler  Normalizer + StandardScaler           0.736     0.734   \n",
       "20  RandomUnderSampler    MinMaxScaler + Normalizer           0.724     0.723   \n",
       "37         no_sampling                   Normalizer           0.793     0.701   \n",
       "17  RandomUnderSampler    Normalizer + MinMaxScaler           0.666     0.670   \n",
       "38         no_sampling    Normalizer + MaxAbsScaler           0.815     0.758   \n",
       "16  RandomUnderSampler    Normalizer + MaxAbsScaler           0.668     0.673   \n",
       "18  RandomUnderSampler  Normalizer + StandardScaler           0.773     0.782   \n",
       "39         no_sampling    Normalizer + MinMaxScaler           0.814     0.756   \n",
       "27   RandomOverSampler    Normalizer + MaxAbsScaler           0.665     0.665   \n",
       "28   RandomOverSampler    Normalizer + MinMaxScaler           0.664     0.664   \n",
       "\n",
       "    train_ba  train_mcc                                           train_cf  \\\n",
       "22     0.804      0.739  [[1636, 402, 180, 48], [370, 1539, 137, 220], ...   \n",
       "0      0.817      0.756  [[1726, 384, 125, 31], [395, 1539, 125, 207], ...   \n",
       "11     0.832      0.776  [[76, 15, 5, 2], [10, 75, 2, 11], [4, 2, 88, 4...   \n",
       "33     0.551      0.521  [[63, 215, 14, 0], [23, 2212, 27, 4], [12, 62,...   \n",
       "4      0.483      0.322  [[878, 331, 811, 246], [481, 597, 820, 368], [...   \n",
       "26     0.460      0.288  [[800, 364, 837, 265], [473, 669, 761, 363], [...   \n",
       "23     0.812      0.749  [[1669, 327, 192, 78], [377, 1568, 126, 195], ...   \n",
       "24     0.813      0.751  [[1678, 334, 183, 71], [379, 1570, 126, 191], ...   \n",
       "8      0.799      0.733  [[1722, 307, 182, 55], [404, 1484, 133, 245], ...   \n",
       "1      0.838      0.784  [[1755, 337, 145, 29], [375, 1602, 119, 170], ...   \n",
       "34     0.493      0.476  [[48, 233, 11, 0], [19, 2218, 28, 1], [10, 66,...   \n",
       "40     0.468      0.444  [[71, 212, 9, 0], [30, 2221, 12, 3], [4, 121, ...   \n",
       "9      0.798      0.732  [[1716, 313, 178, 59], [404, 1476, 139, 247], ...   \n",
       "35     0.498      0.482  [[49, 229, 14, 0], [17, 2220, 28, 1], [10, 67,...   \n",
       "2      0.837      0.783  [[1758, 335, 143, 30], [375, 1597, 121, 173], ...   \n",
       "30     0.763      0.685  [[1581, 368, 234, 83], [420, 1411, 146, 289], ...   \n",
       "3      0.880      0.840  [[1846, 337, 69, 14], [347, 1716, 97, 106], [5...   \n",
       "31     0.764      0.687  [[1559, 390, 239, 78], [425, 1412, 147, 282], ...   \n",
       "5      0.676      0.594  [[1277, 219, 752, 18], [266, 1139, 708, 153], ...   \n",
       "41     0.341      0.311  [[9, 277, 6, 0], [2, 2254, 10, 0], [2, 132, 69...   \n",
       "15     0.393      0.192  [[31, 24, 33, 10], [19, 33, 28, 18], [33, 11, ...   \n",
       "42     0.341      0.311  [[9, 277, 6, 0], [2, 2254, 10, 0], [1, 133, 69...   \n",
       "14     0.890      0.854  [[85, 7, 4, 2], [10, 82, 2, 4], [3, 1, 92, 2],...   \n",
       "12     0.816      0.755  [[76, 14, 5, 3], [10, 77, 3, 8], [8, 2, 84, 4]...   \n",
       "13     0.816      0.755  [[76, 14, 5, 3], [11, 75, 4, 8], [7, 2, 85, 4]...   \n",
       "6      0.676      0.595  [[1278, 217, 754, 17], [267, 1138, 705, 156], ...   \n",
       "19     0.717      0.624  [[70, 13, 9, 6], [19, 56, 5, 18], [10, 2, 80, ...   \n",
       "43     0.451      0.432  [[38, 242, 12, 0], [13, 2226, 24, 3], [8, 86, ...   \n",
       "32     0.804      0.739  [[1660, 355, 187, 64], [382, 1562, 122, 200], ...   \n",
       "25     0.853      0.805  [[1751, 355, 123, 37], [369, 1659, 108, 130], ...   \n",
       "36     0.601      0.564  [[83, 198, 11, 0], [33, 2202, 27, 4], [11, 54,...   \n",
       "10     0.831      0.775  [[1751, 335, 152, 28], [383, 1616, 106, 161], ...   \n",
       "21     0.776      0.701  [[73, 13, 8, 4], [13, 71, 3, 11], [7, 4, 82, 5...   \n",
       "7      0.751      0.688  [[1353, 234, 675, 4], [291, 1232, 662, 81], [2...   \n",
       "29     0.736      0.668  [[1317, 224, 719, 6], [294, 1202, 675, 95], [4...   \n",
       "20     0.724      0.633  [[67, 14, 11, 6], [16, 61, 5, 16], [10, 3, 81,...   \n",
       "37     0.250      0.000  [[0, 292, 0, 0], [0, 2266, 0, 0], [0, 203, 0, ...   \n",
       "17     0.666      0.574  [[51, 12, 34, 1], [10, 60, 25, 3], [5, 2, 86, ...   \n",
       "38     0.354      0.308  [[22, 264, 6, 0], [8, 2247, 9, 2], [4, 147, 52...   \n",
       "16     0.668      0.578  [[51, 12, 34, 1], [10, 60, 25, 3], [5, 2, 87, ...   \n",
       "18     0.773      0.717  [[63, 3, 31, 1], [4, 68, 25, 1], [3, 1, 92, 2]...   \n",
       "39     0.352      0.303  [[21, 265, 6, 0], [9, 2247, 9, 1], [4, 148, 51...   \n",
       "27     0.665      0.578  [[1181, 277, 778, 30], [275, 1120, 713, 158], ...   \n",
       "28     0.664      0.577  [[1181, 277, 778, 30], [277, 1119, 714, 156], ...   \n",
       "\n",
       "    val_accuracy  val_f1  val_ba  val_mcc  \\\n",
       "22         0.678   0.719   0.706    0.428   \n",
       "0          0.657   0.702   0.697    0.412   \n",
       "11         0.596   0.649   0.694    0.379   \n",
       "33         0.841   0.820   0.524    0.482   \n",
       "4          0.429   0.503   0.346    0.085   \n",
       "26         0.700   0.663   0.322    0.048   \n",
       "23         0.101   0.031   0.301    0.042   \n",
       "24         0.097   0.029   0.296    0.037   \n",
       "8          0.094   0.030   0.296    0.044   \n",
       "1          0.095   0.034   0.293    0.040   \n",
       "34         0.092   0.030   0.289    0.039   \n",
       "40         0.092   0.031   0.287    0.038   \n",
       "9          0.089   0.031   0.286    0.047   \n",
       "35         0.090   0.030   0.285    0.038   \n",
       "2          0.089   0.029   0.285    0.039   \n",
       "30         0.087   0.031   0.283    0.050   \n",
       "3          0.093   0.030   0.281    0.029   \n",
       "31         0.085   0.030   0.279    0.050   \n",
       "5          0.211   0.250   0.277    0.061   \n",
       "41         0.082   0.028   0.271    0.042   \n",
       "15         0.042   0.014   0.268    0.037   \n",
       "42         0.078   0.022   0.263    0.031   \n",
       "14         0.077   0.020   0.261    0.024   \n",
       "12         0.075   0.015   0.258    0.033   \n",
       "13         0.075   0.015   0.258    0.033   \n",
       "6          0.089   0.044   0.256    0.029   \n",
       "19         0.073   0.014   0.255    0.053   \n",
       "43         0.073   0.014   0.255    0.053   \n",
       "32         0.073   0.014   0.255    0.036   \n",
       "25         0.093   0.027   0.255    0.004   \n",
       "36         0.093   0.027   0.255    0.004   \n",
       "10         0.071   0.010   0.250    0.000   \n",
       "21         0.071   0.010   0.250    0.000   \n",
       "7          0.071   0.010   0.250    0.000   \n",
       "29         0.071   0.010   0.250    0.000   \n",
       "20         0.071   0.010   0.250    0.000   \n",
       "37         0.792   0.700   0.250    0.000   \n",
       "17         0.059   0.011   0.249   -0.003   \n",
       "38         0.302   0.371   0.246   -0.005   \n",
       "16         0.058   0.011   0.241   -0.010   \n",
       "18         0.058   0.011   0.241   -0.011   \n",
       "39         0.259   0.322   0.232   -0.035   \n",
       "27         0.242   0.302   0.227   -0.047   \n",
       "28         0.241   0.301   0.227   -0.048   \n",
       "\n",
       "                                               val_cf  \n",
       "22  [[60, 22, 15, 0], [142, 506, 39, 68], [7, 1, 5...  \n",
       "0   [[62, 20, 14, 1], [157, 486, 38, 74], [9, 1, 5...  \n",
       "11  [[66, 17, 12, 2], [192, 423, 42, 98], [8, 1, 5...  \n",
       "33  [[26, 65, 6, 0], [17, 728, 6, 4], [9, 23, 36, ...  \n",
       "4   [[0, 42, 1, 54], [0, 380, 2, 373], [0, 25, 0, ...  \n",
       "26  [[0, 87, 0, 10], [0, 653, 0, 102], [0, 60, 0, ...  \n",
       "23  [[47, 0, 50, 0], [302, 0, 453, 0], [19, 0, 49,...  \n",
       "24  [[38, 0, 59, 0], [259, 0, 496, 0], [14, 0, 54,...  \n",
       "8   [[32, 0, 65, 0], [177, 0, 578, 0], [10, 0, 58,...  \n",
       "1   [[32, 0, 65, 0], [190, 2, 563, 0], [11, 0, 57,...  \n",
       "34  [[31, 0, 66, 0], [170, 0, 585, 0], [11, 0, 57,...  \n",
       "40  [[33, 0, 64, 0], [172, 0, 583, 0], [13, 0, 55,...  \n",
       "9   [[24, 0, 73, 0], [94, 0, 661, 0], [7, 0, 61, 0...  \n",
       "35  [[28, 0, 69, 0], [143, 0, 612, 0], [10, 0, 58,...  \n",
       "2   [[25, 0, 72, 0], [132, 0, 623, 0], [8, 0, 60, ...  \n",
       "30  [[20, 0, 77, 0], [69, 0, 686, 0], [5, 0, 63, 0...  \n",
       "3   [[42, 0, 55, 0], [255, 0, 500, 0], [21, 0, 47,...  \n",
       "31  [[17, 0, 80, 0], [50, 0, 705, 0], [4, 0, 64, 0...  \n",
       "5   [[0, 6, 91, 0], [0, 138, 617, 0], [0, 5, 63, 0...  \n",
       "41  [[14, 0, 83, 0], [39, 0, 716, 0], [4, 0, 64, 0...  \n",
       "15  [[7, 0, 0, 90], [21, 0, 0, 734], [1, 0, 0, 67]...  \n",
       "42  [[8, 0, 89, 0], [24, 0, 731, 0], [2, 0, 66, 0]...  \n",
       "14  [[7, 0, 90, 0], [28, 0, 727, 0], [2, 0, 66, 0]...  \n",
       "12  [[3, 0, 94, 0], [7, 0, 748, 0], [0, 0, 68, 0],...  \n",
       "13  [[3, 0, 94, 0], [7, 0, 748, 0], [0, 0, 68, 0],...  \n",
       "6   [[0, 0, 97, 0], [0, 17, 738, 0], [0, 0, 68, 0]...  \n",
       "19  [[2, 0, 95, 0], [0, 0, 755, 0], [0, 0, 68, 0],...  \n",
       "43  [[2, 0, 95, 0], [0, 0, 755, 0], [0, 0, 68, 0],...  \n",
       "32  [[2, 0, 95, 0], [2, 0, 753, 0], [0, 0, 68, 0],...  \n",
       "25  [[66, 0, 31, 0], [506, 0, 249, 0], [45, 0, 23,...  \n",
       "36  [[66, 0, 31, 0], [512, 0, 239, 4], [45, 0, 23,...  \n",
       "10  [[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...  \n",
       "21  [[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...  \n",
       "7   [[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...  \n",
       "29  [[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...  \n",
       "20  [[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...  \n",
       "37  [[0, 97, 0, 0], [0, 755, 0, 0], [0, 68, 0, 0],...  \n",
       "17  [[0, 0, 66, 31], [0, 0, 520, 235], [0, 0, 45, ...  \n",
       "38  [[0, 31, 66, 0], [0, 243, 512, 0], [0, 23, 45,...  \n",
       "16  [[0, 0, 66, 31], [0, 0, 558, 197], [0, 0, 45, ...  \n",
       "18  [[0, 0, 67, 30], [0, 0, 570, 185], [0, 0, 45, ...  \n",
       "39  [[0, 31, 66, 0], [0, 202, 553, 0], [0, 23, 45,...  \n",
       "27  [[0, 30, 67, 0], [0, 186, 569, 0], [0, 23, 45,...  \n",
       "28  [[0, 30, 67, 0], [0, 185, 570, 0], [0, 23, 45,...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liblinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>scaling</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_ba</th>\n",
       "      <th>train_mcc</th>\n",
       "      <th>train_cf</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_ba</th>\n",
       "      <th>val_mcc</th>\n",
       "      <th>val_cf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.200</td>\n",
       "      <td>[[2060, 0, 6, 0, 30], [1632, 225, 53, 41, 145]...</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.017</td>\n",
       "      <td>[[0, 0, 0, 27, 1], [1, 19, 0, 564, 114], [0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.245</td>\n",
       "      <td>[[1949, 0, 96, 26, 25], [1258, 448, 170, 108, ...</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.021</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [0, 23, 0, 660, 15], [0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.008</td>\n",
       "      <td>[[0, 126, 1970, 0, 0], [119, 233, 1743, 1, 0],...</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.022</td>\n",
       "      <td>[[28, 0, 0, 0, 0], [674, 24, 0, 0, 0], [57, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.084</td>\n",
       "      <td>[[2001, 56, 5, 2, 32], [1664, 211, 17, 3, 201]...</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.022</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [0, 18, 4, 0, 676], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.201</td>\n",
       "      <td>[[3, 0, 49, 0, 0], [0, 12, 40, 0, 0], [0, 3, 4...</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.030</td>\n",
       "      <td>[[0, 0, 28, 0, 0], [5, 30, 663, 0, 0], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.288</td>\n",
       "      <td>[[2005, 1, 82, 0, 8], [1309, 452, 125, 73, 137...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.017</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [0, 17, 0, 0, 681], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.046</td>\n",
       "      <td>[[0, 3, 49, 0, 0], [0, 7, 45, 0, 0], [0, 3, 49...</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.028</td>\n",
       "      <td>[[0, 0, 28, 0, 0], [1, 38, 659, 0, 0], [1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.201</td>\n",
       "      <td>[[2062, 0, 6, 0, 28], [1630, 235, 53, 37, 141]...</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.013</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [1, 20, 0, 621, 56], [0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.305</td>\n",
       "      <td>[[46, 0, 2, 3, 1], [30, 14, 2, 3, 3], [27, 3, ...</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [0, 0, 55, 0, 643], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.157</td>\n",
       "      <td>[[2, 80, 0, 0, 0], [0, 2095, 0, 1, 0], [0, 171...</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.021</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [0, 37, 0, 661, 0], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.176</td>\n",
       "      <td>[[1949, 0, 127, 0, 20], [1273, 252, 467, 39, 6...</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.020</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [1, 36, 0, 660, 1], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.630</td>\n",
       "      <td>[[40, 2, 5, 4, 1], [3, 38, 3, 3, 5], [0, 4, 37...</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [11, 638, 49, 0, 0], [0, 53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.568</td>\n",
       "      <td>[[1592, 139, 160, 137, 68], [361, 735, 376, 32...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.506</td>\n",
       "      <td>[[1492, 164, 187, 137, 116], [366, 678, 350, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.503</td>\n",
       "      <td>[[1492, 168, 189, 136, 111], [353, 663, 370, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.496</td>\n",
       "      <td>[[1536, 107, 166, 158, 129], [363, 674, 375, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.441</td>\n",
       "      <td>[[1385, 179, 144, 158, 230], [357, 632, 383, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.049</td>\n",
       "      <td>[[0, 81, 1, 0, 0], [1, 2094, 0, 1, 0], [1, 171...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.046</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>none</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 2096, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 2...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 0, 52, 0], [0, 0, 0, 52, 0], [0, 0, 0,...</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [0, 0, 0, 698, 0], [0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 2096, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 2...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>none</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.508</td>\n",
       "      <td>[[1536, 152, 184, 132, 92], [367, 685, 378, 33...</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [1, 697, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.425</td>\n",
       "      <td>[[1354, 162, 144, 232, 204], [361, 631, 383, 3...</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [2, 696, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.192</td>\n",
       "      <td>[[3, 0, 49, 0, 0], [0, 12, 40, 0, 0], [0, 3, 4...</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [2, 696, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.004</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [3, 695, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.440</td>\n",
       "      <td>[[1474, 162, 164, 158, 138], [398, 653, 346, 3...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [3, 695, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.174</td>\n",
       "      <td>[[1949, 0, 127, 0, 20], [1294, 250, 447, 40, 6...</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.013</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [1, 31, 0, 665, 1], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [12, 686, 0, 0, 0], [0, 58,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.450</td>\n",
       "      <td>[[34, 5, 3, 6, 4], [5, 25, 5, 5, 12], [6, 9, 2...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [18, 0, 18, 662, 0], [0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.454</td>\n",
       "      <td>[[35, 4, 3, 6, 4], [4, 25, 6, 5, 12], [6, 8, 2...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [16, 0, 20, 662, 0], [0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.325</td>\n",
       "      <td>[[36, 5, 4, 4, 3], [6, 25, 2, 3, 16], [15, 10,...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [51, 0, 0, 647, 0], [2, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.340</td>\n",
       "      <td>[[38, 5, 4, 4, 1], [11, 23, 4, 1, 13], [15, 10...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [50, 0, 0, 648, 0], [2, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.405</td>\n",
       "      <td>[[36, 6, 2, 4, 4], [8, 31, 3, 1, 9], [9, 13, 1...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [30, 0, 0, 668, 0], [1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.374</td>\n",
       "      <td>[[1283, 225, 96, 283, 209], [395, 588, 325, 39...</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [37, 661, 0, 0, 0], [1, 57,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.368</td>\n",
       "      <td>[[1228, 225, 125, 307, 211], [387, 597, 321, 4...</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [38, 660, 0, 0, 0], [1, 57,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.453</td>\n",
       "      <td>[[1443, 169, 146, 206, 132], [399, 680, 294, 3...</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>[[1, 27, 0, 0, 0], [77, 617, 0, 0, 4], [6, 52,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.448</td>\n",
       "      <td>[[1417, 173, 155, 212, 139], [382, 690, 294, 3...</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>[[1, 27, 0, 0, 0], [78, 617, 0, 0, 3], [6, 52,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sampling                      scaling  train_accuracy  train_f1  \\\n",
       "6                SMOTE    Normalizer + MinMaxScaler           0.290     0.226   \n",
       "29   RandomOverSampler  Normalizer + StandardScaler           0.350     0.321   \n",
       "26   RandomOverSampler                   Normalizer           0.203     0.099   \n",
       "4                SMOTE                   Normalizer           0.236     0.141   \n",
       "16  RandomUnderSampler    Normalizer + MaxAbsScaler           0.292     0.247   \n",
       "7                SMOTE  Normalizer + StandardScaler           0.372     0.346   \n",
       "15  RandomUnderSampler                   Normalizer           0.215     0.106   \n",
       "5                SMOTE    Normalizer + MaxAbsScaler           0.290     0.226   \n",
       "18  RandomUnderSampler  Normalizer + StandardScaler           0.404     0.395   \n",
       "40         no_sampling  Normalizer + StandardScaler           0.835     0.764   \n",
       "27   RandomOverSampler    Normalizer + MaxAbsScaler           0.304     0.250   \n",
       "14  RandomUnderSampler               StandardScaler           0.704     0.704   \n",
       "3                SMOTE               StandardScaler           0.652     0.638   \n",
       "2                SMOTE                 MinMaxScaler           0.602     0.588   \n",
       "1                SMOTE                 MaxAbsScaler           0.600     0.586   \n",
       "25   RandomOverSampler               StandardScaler           0.594     0.578   \n",
       "24   RandomOverSampler                 MinMaxScaler           0.550     0.536   \n",
       "36         no_sampling               StandardScaler           0.830     0.754   \n",
       "38         no_sampling    Normalizer + MaxAbsScaler           0.830     0.754   \n",
       "0                SMOTE                         none           0.200     0.067   \n",
       "11  RandomUnderSampler                         none           0.200     0.067   \n",
       "22   RandomOverSampler                         none           0.200     0.067   \n",
       "33         no_sampling                         none           0.830     0.753   \n",
       "34         no_sampling                 MaxAbsScaler           0.830     0.753   \n",
       "35         no_sampling                 MinMaxScaler           0.830     0.753   \n",
       "37         no_sampling                   Normalizer           0.830     0.753   \n",
       "39         no_sampling    Normalizer + MinMaxScaler           0.830     0.753   \n",
       "41         no_sampling    MaxAbsScaler + Normalizer           0.830     0.753   \n",
       "10               SMOTE  StandardScaler + Normalizer           0.604     0.592   \n",
       "23   RandomOverSampler                 MaxAbsScaler           0.537     0.522   \n",
       "17  RandomUnderSampler    Normalizer + MinMaxScaler           0.288     0.241   \n",
       "42         no_sampling    MinMaxScaler + Normalizer           0.830     0.753   \n",
       "32   RandomOverSampler  StandardScaler + Normalizer           0.550     0.536   \n",
       "28   RandomOverSampler    Normalizer + MinMaxScaler           0.302     0.249   \n",
       "43         no_sampling  StandardScaler + Normalizer           0.830     0.753   \n",
       "12  RandomUnderSampler                 MaxAbsScaler           0.558     0.551   \n",
       "13  RandomUnderSampler                 MinMaxScaler           0.562     0.557   \n",
       "19  RandomUnderSampler    MaxAbsScaler + Normalizer           0.454     0.439   \n",
       "20  RandomUnderSampler    MinMaxScaler + Normalizer           0.465     0.448   \n",
       "21  RandomUnderSampler  StandardScaler + Normalizer           0.519     0.510   \n",
       "30   RandomOverSampler    MaxAbsScaler + Normalizer           0.496     0.480   \n",
       "31   RandomOverSampler    MinMaxScaler + Normalizer           0.492     0.479   \n",
       "8                SMOTE    MaxAbsScaler + Normalizer           0.559     0.545   \n",
       "9                SMOTE    MinMaxScaler + Normalizer           0.556     0.542   \n",
       "\n",
       "    train_ba  train_mcc                                           train_cf  \\\n",
       "6      0.290      0.200  [[2060, 0, 6, 0, 30], [1632, 225, 53, 41, 145]...   \n",
       "29     0.350      0.245  [[1949, 0, 96, 26, 25], [1258, 448, 170, 108, ...   \n",
       "26     0.203      0.008  [[0, 126, 1970, 0, 0], [119, 233, 1743, 1, 0],...   \n",
       "4      0.236      0.084  [[2001, 56, 5, 2, 32], [1664, 211, 17, 3, 201]...   \n",
       "16     0.292      0.201  [[3, 0, 49, 0, 0], [0, 12, 40, 0, 0], [0, 3, 4...   \n",
       "7      0.372      0.288  [[2005, 1, 82, 0, 8], [1309, 452, 125, 73, 137...   \n",
       "15     0.215      0.046  [[0, 3, 49, 0, 0], [0, 7, 45, 0, 0], [0, 3, 49...   \n",
       "5      0.290      0.201  [[2062, 0, 6, 0, 28], [1630, 235, 53, 37, 141]...   \n",
       "18     0.404      0.305  [[46, 0, 2, 3, 1], [30, 14, 2, 3, 3], [27, 3, ...   \n",
       "40     0.226      0.157  [[2, 80, 0, 0, 0], [0, 2095, 0, 1, 0], [0, 171...   \n",
       "27     0.304      0.176  [[1949, 0, 127, 0, 20], [1273, 252, 467, 39, 6...   \n",
       "14     0.704      0.630  [[40, 2, 5, 4, 1], [3, 38, 3, 3, 5], [0, 4, 37...   \n",
       "3      0.652      0.568  [[1592, 139, 160, 137, 68], [361, 735, 376, 32...   \n",
       "2      0.602      0.506  [[1492, 164, 187, 137, 116], [366, 678, 350, 3...   \n",
       "1      0.600      0.503  [[1492, 168, 189, 136, 111], [353, 663, 370, 3...   \n",
       "25     0.594      0.496  [[1536, 107, 166, 158, 129], [363, 674, 375, 3...   \n",
       "24     0.550      0.441  [[1385, 179, 144, 158, 230], [357, 632, 383, 3...   \n",
       "36     0.202      0.049  [[0, 81, 1, 0, 0], [1, 2094, 0, 1, 0], [1, 171...   \n",
       "38     0.202      0.046  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "0      0.200      0.000  [[0, 2096, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 2...   \n",
       "11     0.200      0.000  [[0, 0, 0, 52, 0], [0, 0, 0, 52, 0], [0, 0, 0,...   \n",
       "22     0.200      0.000  [[0, 2096, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 2...   \n",
       "33     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "34     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "35     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "37     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "39     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "41     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "10     0.604      0.508  [[1536, 152, 184, 132, 92], [367, 685, 378, 33...   \n",
       "23     0.537      0.425  [[1354, 162, 144, 232, 204], [361, 631, 383, 3...   \n",
       "17     0.288      0.192  [[3, 0, 49, 0, 0], [0, 12, 40, 0, 0], [0, 3, 4...   \n",
       "42     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "32     0.550      0.440  [[1474, 162, 164, 158, 138], [398, 653, 346, 3...   \n",
       "28     0.302      0.174  [[1949, 0, 127, 0, 20], [1294, 250, 447, 40, 6...   \n",
       "43     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "12     0.558      0.450  [[34, 5, 3, 6, 4], [5, 25, 5, 5, 12], [6, 9, 2...   \n",
       "13     0.562      0.454  [[35, 4, 3, 6, 4], [4, 25, 6, 5, 12], [6, 8, 2...   \n",
       "19     0.454      0.325  [[36, 5, 4, 4, 3], [6, 25, 2, 3, 16], [15, 10,...   \n",
       "20     0.465      0.340  [[38, 5, 4, 4, 1], [11, 23, 4, 1, 13], [15, 10...   \n",
       "21     0.519      0.405  [[36, 6, 2, 4, 4], [8, 31, 3, 1, 9], [9, 13, 1...   \n",
       "30     0.496      0.374  [[1283, 225, 96, 283, 209], [395, 588, 325, 39...   \n",
       "31     0.492      0.368  [[1228, 225, 125, 307, 211], [387, 597, 321, 4...   \n",
       "8      0.559      0.453  [[1443, 169, 146, 206, 132], [399, 680, 294, 3...   \n",
       "9      0.556      0.448  [[1417, 173, 155, 212, 139], [382, 690, 294, 3...   \n",
       "\n",
       "    val_accuracy  val_f1  val_ba  val_mcc  \\\n",
       "6          0.069   0.049   0.216    0.017   \n",
       "29         0.075   0.058   0.209    0.021   \n",
       "26         0.062   0.057   0.207    0.022   \n",
       "4          0.042   0.042   0.205    0.022   \n",
       "16         0.103   0.077   0.205    0.030   \n",
       "7          0.040   0.040   0.205    0.017   \n",
       "15         0.112   0.094   0.204    0.028   \n",
       "5          0.070   0.051   0.203    0.013   \n",
       "18         0.024   0.005   0.202   -0.000   \n",
       "40         0.090   0.088   0.201    0.021   \n",
       "27         0.089   0.085   0.201    0.020   \n",
       "14         0.764   0.725   0.200   -0.016   \n",
       "3          0.829   0.751   0.200    0.000   \n",
       "2          0.829   0.751   0.200    0.000   \n",
       "1          0.829   0.751   0.200    0.000   \n",
       "25         0.829   0.751   0.200    0.000   \n",
       "24         0.829   0.751   0.200    0.000   \n",
       "36         0.829   0.751   0.200    0.000   \n",
       "38         0.829   0.751   0.200    0.000   \n",
       "0          0.829   0.751   0.200    0.000   \n",
       "11         0.049   0.005   0.200    0.000   \n",
       "22         0.829   0.751   0.200    0.000   \n",
       "33         0.829   0.751   0.200    0.000   \n",
       "34         0.829   0.751   0.200    0.000   \n",
       "35         0.829   0.751   0.200    0.000   \n",
       "37         0.829   0.751   0.200    0.000   \n",
       "39         0.829   0.751   0.200    0.000   \n",
       "41         0.829   0.751   0.200    0.000   \n",
       "10         0.828   0.751   0.200   -0.009   \n",
       "23         0.827   0.750   0.199   -0.013   \n",
       "17         0.827   0.750   0.199   -0.013   \n",
       "42         0.825   0.750   0.199    0.004   \n",
       "32         0.825   0.750   0.199   -0.016   \n",
       "28         0.083   0.075   0.199    0.013   \n",
       "43         0.815   0.745   0.197   -0.010   \n",
       "12         0.048   0.006   0.194   -0.008   \n",
       "13         0.048   0.006   0.194   -0.008   \n",
       "19         0.046   0.005   0.190   -0.007   \n",
       "20         0.046   0.005   0.190   -0.007   \n",
       "21         0.046   0.004   0.190   -0.011   \n",
       "30         0.785   0.731   0.189   -0.031   \n",
       "31         0.784   0.730   0.189   -0.032   \n",
       "8          0.734   0.707   0.184   -0.033   \n",
       "9          0.734   0.707   0.184   -0.033   \n",
       "\n",
       "                                               val_cf  \n",
       "6   [[0, 0, 0, 27, 1], [1, 19, 0, 564, 114], [0, 0...  \n",
       "29  [[0, 0, 0, 28, 0], [0, 23, 0, 660, 15], [0, 0,...  \n",
       "26  [[28, 0, 0, 0, 0], [674, 24, 0, 0, 0], [57, 1,...  \n",
       "4   [[0, 0, 0, 0, 28], [0, 18, 4, 0, 676], [0, 0, ...  \n",
       "16  [[0, 0, 28, 0, 0], [5, 30, 663, 0, 0], [0, 1, ...  \n",
       "7   [[0, 0, 0, 0, 28], [0, 17, 0, 0, 681], [0, 0, ...  \n",
       "15  [[0, 0, 28, 0, 0], [1, 38, 659, 0, 0], [1, 1, ...  \n",
       "5   [[0, 0, 0, 28, 0], [1, 20, 0, 621, 56], [0, 0,...  \n",
       "18  [[0, 0, 0, 0, 28], [0, 0, 55, 0, 643], [0, 0, ...  \n",
       "40  [[0, 0, 0, 28, 0], [0, 37, 0, 661, 0], [0, 1, ...  \n",
       "27  [[0, 0, 0, 28, 0], [1, 36, 0, 660, 1], [0, 1, ...  \n",
       "14  [[0, 28, 0, 0, 0], [11, 638, 49, 0, 0], [0, 53...  \n",
       "3   [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "2   [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "1   [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "25  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "24  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "36  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "38  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "0   [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "11  [[0, 0, 0, 28, 0], [0, 0, 0, 698, 0], [0, 0, 0...  \n",
       "22  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "33  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "34  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "35  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "37  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "39  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "41  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "10  [[0, 28, 0, 0, 0], [1, 697, 0, 0, 0], [0, 58, ...  \n",
       "23  [[0, 28, 0, 0, 0], [2, 696, 0, 0, 0], [0, 58, ...  \n",
       "17  [[0, 28, 0, 0, 0], [2, 696, 0, 0, 0], [0, 58, ...  \n",
       "42  [[0, 28, 0, 0, 0], [3, 695, 0, 0, 0], [0, 58, ...  \n",
       "32  [[0, 28, 0, 0, 0], [3, 695, 0, 0, 0], [0, 58, ...  \n",
       "28  [[0, 0, 0, 28, 0], [1, 31, 0, 665, 1], [0, 1, ...  \n",
       "43  [[0, 28, 0, 0, 0], [12, 686, 0, 0, 0], [0, 58,...  \n",
       "12  [[0, 0, 0, 28, 0], [18, 0, 18, 662, 0], [0, 0,...  \n",
       "13  [[0, 0, 0, 28, 0], [16, 0, 20, 662, 0], [0, 0,...  \n",
       "19  [[0, 0, 0, 28, 0], [51, 0, 0, 647, 0], [2, 0, ...  \n",
       "20  [[0, 0, 0, 28, 0], [50, 0, 0, 648, 0], [2, 0, ...  \n",
       "21  [[0, 0, 0, 28, 0], [30, 0, 0, 668, 0], [1, 0, ...  \n",
       "30  [[0, 28, 0, 0, 0], [37, 661, 0, 0, 0], [1, 57,...  \n",
       "31  [[0, 28, 0, 0, 0], [38, 660, 0, 0, 0], [1, 57,...  \n",
       "8   [[1, 27, 0, 0, 0], [77, 617, 0, 0, 4], [6, 52,...  \n",
       "9   [[1, 27, 0, 0, 0], [78, 617, 0, 0, 3], [6, 52,...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liblinear.to_csv('db_lr_liblinear.csv')\n",
    "model_liblinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>scaling</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_ba</th>\n",
       "      <th>train_mcc</th>\n",
       "      <th>train_cf</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_ba</th>\n",
       "      <th>val_mcc</th>\n",
       "      <th>val_cf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.344</td>\n",
       "      <td>[[1381, 714], [660, 1435]]</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.177</td>\n",
       "      <td>[[44, 28], [225, 474]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.263</td>\n",
       "      <td>[[139, 78], [82, 135]]</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.150</td>\n",
       "      <td>[[51, 21], [315, 384]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.221</td>\n",
       "      <td>[[133, 84], [85, 132]]</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.140</td>\n",
       "      <td>[[50, 22], [317, 382]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 217], [0, 2095]]</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.115</td>\n",
       "      <td>[[47, 25], [318, 381]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.401</td>\n",
       "      <td>[[150, 67], [63, 154]]</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.112</td>\n",
       "      <td>[[42, 30], [275, 424]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.240</td>\n",
       "      <td>[[1261, 834], [758, 1337]]</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.105</td>\n",
       "      <td>[[49, 23], [350, 349]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.256</td>\n",
       "      <td>[[1276, 819], [741, 1354]]</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.096</td>\n",
       "      <td>[[47, 25], [341, 358]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>none</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.375</td>\n",
       "      <td>[[1449, 646], [663, 1432]]</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.099</td>\n",
       "      <td>[[36, 36], [236, 463]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.198</td>\n",
       "      <td>[[129, 88], [86, 131]]</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.105</td>\n",
       "      <td>[[29, 43], [171, 528]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.185</td>\n",
       "      <td>[[1210, 885], [822, 1273]]</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.094</td>\n",
       "      <td>[[64, 8], [525, 174]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.291</td>\n",
       "      <td>[[135, 82], [72, 145]]</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.102</td>\n",
       "      <td>[[17, 55], [83, 616]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.313</td>\n",
       "      <td>[[1416, 679], [760, 1335]]</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.063</td>\n",
       "      <td>[[69, 3], [624, 75]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.277</td>\n",
       "      <td>[[135, 82], [75, 142]]</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.025</td>\n",
       "      <td>[[9, 63], [69, 630]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.300</td>\n",
       "      <td>[[138, 79], [73, 144]]</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.024</td>\n",
       "      <td>[[9, 63], [70, 629]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 217], [0, 2095]]</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.047</td>\n",
       "      <td>[[3, 69], [13, 686]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 217], [0, 2095]]</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.023</td>\n",
       "      <td>[[7, 65], [53, 646]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.276</td>\n",
       "      <td>[[1329, 766], [751, 1344]]</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.017</td>\n",
       "      <td>[[6, 66], [48, 651]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 217], [0, 2095]]</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.020</td>\n",
       "      <td>[[4, 68], [29, 670]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>none</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.071</td>\n",
       "      <td>[[2, 215], [1, 2094]]</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.071</td>\n",
       "      <td>[[1, 71], [1, 698]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 217], [0, 2095]]</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.013</td>\n",
       "      <td>[[4, 68], [32, 667]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.299</td>\n",
       "      <td>[[1383, 712], [757, 1338]]</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.014</td>\n",
       "      <td>[[3, 69], [23, 676]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.272</td>\n",
       "      <td>[[137, 80], [78, 139]]</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.005</td>\n",
       "      <td>[[6, 66], [55, 644]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.330</td>\n",
       "      <td>[[1450, 645], [759, 1336]]</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.012</td>\n",
       "      <td>[[72, 0], [698, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.208</td>\n",
       "      <td>[[1298, 797], [863, 1232]]</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.012</td>\n",
       "      <td>[[72, 0], [698, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.397</td>\n",
       "      <td>[[1524, 571], [693, 1402]]</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[72, 0], [699, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.375</td>\n",
       "      <td>[[1462, 633], [676, 1419]]</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72], [0, 699]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.350</td>\n",
       "      <td>[[150, 67], [74, 143]]</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72], [0, 699]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.341</td>\n",
       "      <td>[[1461, 634], [747, 1348]]</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[72, 0], [699, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.328</td>\n",
       "      <td>[[1449, 646], [763, 1332]]</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[72, 0], [699, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.319</td>\n",
       "      <td>[[1382, 713], [714, 1381]]</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72], [0, 699]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.313</td>\n",
       "      <td>[[1339, 756], [684, 1411]]</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72], [0, 699]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.286</td>\n",
       "      <td>[[137, 80], [75, 142]]</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72], [0, 699]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.271</td>\n",
       "      <td>[[1313, 782], [746, 1349]]</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72], [0, 699]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.263</td>\n",
       "      <td>[[138, 79], [81, 136]]</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72], [0, 699]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.041</td>\n",
       "      <td>[[1, 216], [1, 2094]]</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72], [0, 699]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 217], [0, 2095]]</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72], [0, 699]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 217], [0, 2095]]</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72], [0, 699]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 217], [0, 2095]]</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72], [0, 699]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>[[0, 217], [2, 2093]]</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72], [0, 699]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.305</td>\n",
       "      <td>[[1335, 760], [696, 1399]]</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.499</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>[[0, 72], [2, 697]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.277</td>\n",
       "      <td>[[1297, 798], [718, 1377]]</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.493</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>[[1, 71], [20, 679]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.293</td>\n",
       "      <td>[[1316, 779], [703, 1392]]</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>[[0, 72], [11, 688]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.314</td>\n",
       "      <td>[[1364, 731], [706, 1389]]</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.491</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>[[0, 72], [12, 687]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.310</td>\n",
       "      <td>[[1393, 702], [744, 1351]]</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.487</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>[[0, 72], [18, 681]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sampling                      scaling  train_accuracy  train_f1  \\\n",
       "22   RandomOverSampler                         none           0.672     0.676   \n",
       "20  RandomUnderSampler    MinMaxScaler + Normalizer           0.631     0.628   \n",
       "19  RandomUnderSampler    MaxAbsScaler + Normalizer           0.611     0.610   \n",
       "43         no_sampling  StandardScaler + Normalizer           0.906     0.951   \n",
       "11  RandomUnderSampler                         none           0.700     0.703   \n",
       "30   RandomOverSampler    MaxAbsScaler + Normalizer           0.620     0.627   \n",
       "31   RandomOverSampler    MinMaxScaler + Normalizer           0.628     0.634   \n",
       "0                SMOTE                         none           0.688     0.686   \n",
       "15  RandomUnderSampler                   Normalizer           0.599     0.601   \n",
       "26   RandomOverSampler                   Normalizer           0.593     0.599   \n",
       "21  RandomUnderSampler  StandardScaler + Normalizer           0.645     0.653   \n",
       "5                SMOTE    Normalizer + MaxAbsScaler           0.657     0.650   \n",
       "12  RandomUnderSampler                 MaxAbsScaler           0.638     0.644   \n",
       "13  RandomUnderSampler                 MinMaxScaler           0.650     0.655   \n",
       "41         no_sampling    MaxAbsScaler + Normalizer           0.906     0.951   \n",
       "35         no_sampling                 MinMaxScaler           0.906     0.951   \n",
       "28   RandomOverSampler    Normalizer + MinMaxScaler           0.638     0.639   \n",
       "42         no_sampling    MinMaxScaler + Normalizer           0.906     0.951   \n",
       "33         no_sampling                         none           0.907     0.951   \n",
       "34         no_sampling                 MaxAbsScaler           0.906     0.951   \n",
       "2                SMOTE                 MinMaxScaler           0.649     0.646   \n",
       "16  RandomUnderSampler    Normalizer + MaxAbsScaler           0.636     0.638   \n",
       "9                SMOTE    MinMaxScaler + Normalizer           0.665     0.656   \n",
       "4                SMOTE                   Normalizer           0.604     0.597   \n",
       "7                SMOTE  Normalizer + StandardScaler           0.698     0.689   \n",
       "3                SMOTE               StandardScaler           0.688     0.684   \n",
       "18  RandomUnderSampler  Normalizer + StandardScaler           0.675     0.670   \n",
       "6                SMOTE    Normalizer + MinMaxScaler           0.670     0.661   \n",
       "8                SMOTE    MaxAbsScaler + Normalizer           0.664     0.654   \n",
       "29   RandomOverSampler  Normalizer + StandardScaler           0.659     0.659   \n",
       "25   RandomOverSampler               StandardScaler           0.656     0.662   \n",
       "14  RandomUnderSampler               StandardScaler           0.643     0.647   \n",
       "27   RandomOverSampler    Normalizer + MaxAbsScaler           0.635     0.638   \n",
       "17  RandomUnderSampler    Normalizer + MinMaxScaler           0.631     0.630   \n",
       "40         no_sampling  Normalizer + StandardScaler           0.906     0.951   \n",
       "37         no_sampling                   Normalizer           0.906     0.951   \n",
       "38         no_sampling    Normalizer + MaxAbsScaler           0.906     0.951   \n",
       "39         no_sampling    Normalizer + MinMaxScaler           0.906     0.951   \n",
       "36         no_sampling               StandardScaler           0.905     0.950   \n",
       "10               SMOTE  StandardScaler + Normalizer           0.653     0.658   \n",
       "24   RandomOverSampler                 MinMaxScaler           0.638     0.645   \n",
       "23   RandomOverSampler                 MaxAbsScaler           0.646     0.653   \n",
       "32   RandomOverSampler  StandardScaler + Normalizer           0.657     0.659   \n",
       "1                SMOTE                 MaxAbsScaler           0.655     0.651   \n",
       "\n",
       "    train_ba  train_mcc                    train_cf  val_accuracy  val_f1  \\\n",
       "22     0.672      0.344  [[1381, 714], [660, 1435]]         0.672   0.789   \n",
       "20     0.631      0.263      [[139, 78], [82, 135]]         0.564   0.696   \n",
       "19     0.611      0.221      [[133, 84], [85, 132]]         0.560   0.693   \n",
       "43     0.500      0.000       [[0, 217], [0, 2095]]         0.555   0.690   \n",
       "11     0.700      0.401      [[150, 67], [63, 154]]         0.604   0.735   \n",
       "30     0.620      0.240  [[1261, 834], [758, 1337]]         0.516   0.652   \n",
       "31     0.628      0.256  [[1276, 819], [741, 1354]]         0.525   0.662   \n",
       "0      0.688      0.375  [[1449, 646], [663, 1432]]         0.647   0.773   \n",
       "15     0.599      0.198      [[129, 88], [86, 131]]         0.722   0.831   \n",
       "26     0.593      0.185  [[1210, 885], [822, 1273]]         0.309   0.395   \n",
       "21     0.645      0.291      [[135, 82], [72, 145]]         0.821   0.899   \n",
       "5      0.657      0.313  [[1416, 679], [760, 1335]]         0.187   0.193   \n",
       "12     0.638      0.277      [[135, 82], [75, 142]]         0.829   0.905   \n",
       "13     0.650      0.300      [[138, 79], [73, 144]]         0.827   0.904   \n",
       "41     0.500      0.000       [[0, 217], [0, 2095]]         0.894   0.944   \n",
       "35     0.500      0.000       [[0, 217], [0, 2095]]         0.847   0.916   \n",
       "28     0.638      0.276  [[1329, 766], [751, 1344]]         0.852   0.919   \n",
       "42     0.500      0.000       [[0, 217], [0, 2095]]         0.874   0.932   \n",
       "33     0.504      0.071       [[2, 215], [1, 2094]]         0.907   0.951   \n",
       "34     0.500      0.000       [[0, 217], [0, 2095]]         0.870   0.930   \n",
       "2      0.649      0.299  [[1383, 712], [757, 1338]]         0.881   0.936   \n",
       "16     0.636      0.272      [[137, 80], [78, 139]]         0.843   0.914   \n",
       "9      0.665      0.330  [[1450, 645], [759, 1336]]         0.095   0.003   \n",
       "4      0.604      0.208  [[1298, 797], [863, 1232]]         0.095   0.003   \n",
       "7      0.698      0.397  [[1524, 571], [693, 1402]]         0.093   0.000   \n",
       "3      0.688      0.375  [[1462, 633], [676, 1419]]         0.907   0.951   \n",
       "18     0.675      0.350      [[150, 67], [74, 143]]         0.907   0.951   \n",
       "6      0.670      0.341  [[1461, 634], [747, 1348]]         0.093   0.000   \n",
       "8      0.664      0.328  [[1449, 646], [763, 1332]]         0.093   0.000   \n",
       "29     0.659      0.319  [[1382, 713], [714, 1381]]         0.907   0.951   \n",
       "25     0.656      0.313  [[1339, 756], [684, 1411]]         0.907   0.951   \n",
       "14     0.643      0.286      [[137, 80], [75, 142]]         0.907   0.951   \n",
       "27     0.635      0.271  [[1313, 782], [746, 1349]]         0.907   0.951   \n",
       "17     0.631      0.263      [[138, 79], [81, 136]]         0.907   0.951   \n",
       "40     0.502      0.041       [[1, 216], [1, 2094]]         0.907   0.951   \n",
       "37     0.500      0.000       [[0, 217], [0, 2095]]         0.907   0.951   \n",
       "38     0.500      0.000       [[0, 217], [0, 2095]]         0.907   0.951   \n",
       "39     0.500      0.000       [[0, 217], [0, 2095]]         0.907   0.951   \n",
       "36     0.500     -0.009       [[0, 217], [2, 2093]]         0.907   0.951   \n",
       "10     0.653      0.305  [[1335, 760], [696, 1399]]         0.904   0.950   \n",
       "24     0.638      0.277  [[1297, 798], [718, 1377]]         0.882   0.937   \n",
       "23     0.646      0.293  [[1316, 779], [703, 1392]]         0.892   0.943   \n",
       "32     0.657      0.314  [[1364, 731], [706, 1389]]         0.891   0.942   \n",
       "1      0.655      0.310  [[1393, 702], [744, 1351]]         0.883   0.938   \n",
       "\n",
       "    val_ba  val_mcc                  val_cf  \n",
       "22   0.645    0.177  [[44, 28], [225, 474]]  \n",
       "20   0.629    0.150  [[51, 21], [315, 384]]  \n",
       "19   0.620    0.140  [[50, 22], [317, 382]]  \n",
       "43   0.599    0.115  [[47, 25], [318, 381]]  \n",
       "11   0.595    0.112  [[42, 30], [275, 424]]  \n",
       "30   0.590    0.105  [[49, 23], [350, 349]]  \n",
       "31   0.582    0.096  [[47, 25], [341, 358]]  \n",
       "0    0.581    0.099  [[36, 36], [236, 463]]  \n",
       "15   0.579    0.105  [[29, 43], [171, 528]]  \n",
       "26   0.569    0.094   [[64, 8], [525, 174]]  \n",
       "21   0.559    0.102   [[17, 55], [83, 616]]  \n",
       "5    0.533    0.063    [[69, 3], [624, 75]]  \n",
       "12   0.513    0.025    [[9, 63], [69, 630]]  \n",
       "13   0.512    0.024    [[9, 63], [70, 629]]  \n",
       "41   0.512    0.047    [[3, 69], [13, 686]]  \n",
       "35   0.511    0.023    [[7, 65], [53, 646]]  \n",
       "28   0.507    0.017    [[6, 66], [48, 651]]  \n",
       "42   0.507    0.020    [[4, 68], [29, 670]]  \n",
       "33   0.506    0.071     [[1, 71], [1, 698]]  \n",
       "34   0.505    0.013    [[4, 68], [32, 667]]  \n",
       "2    0.504    0.014    [[3, 69], [23, 676]]  \n",
       "16   0.502    0.005    [[6, 66], [55, 644]]  \n",
       "9    0.501    0.012     [[72, 0], [698, 1]]  \n",
       "4    0.501    0.012     [[72, 0], [698, 1]]  \n",
       "7    0.500    0.000     [[72, 0], [699, 0]]  \n",
       "3    0.500    0.000     [[0, 72], [0, 699]]  \n",
       "18   0.500    0.000     [[0, 72], [0, 699]]  \n",
       "6    0.500    0.000     [[72, 0], [699, 0]]  \n",
       "8    0.500    0.000     [[72, 0], [699, 0]]  \n",
       "29   0.500    0.000     [[0, 72], [0, 699]]  \n",
       "25   0.500    0.000     [[0, 72], [0, 699]]  \n",
       "14   0.500    0.000     [[0, 72], [0, 699]]  \n",
       "27   0.500    0.000     [[0, 72], [0, 699]]  \n",
       "17   0.500    0.000     [[0, 72], [0, 699]]  \n",
       "40   0.500    0.000     [[0, 72], [0, 699]]  \n",
       "37   0.500    0.000     [[0, 72], [0, 699]]  \n",
       "38   0.500    0.000     [[0, 72], [0, 699]]  \n",
       "39   0.500    0.000     [[0, 72], [0, 699]]  \n",
       "36   0.500    0.000     [[0, 72], [0, 699]]  \n",
       "10   0.499   -0.016     [[0, 72], [2, 697]]  \n",
       "24   0.493   -0.026    [[1, 71], [20, 679]]  \n",
       "23   0.492   -0.039    [[0, 72], [11, 688]]  \n",
       "32   0.491   -0.040    [[0, 72], [12, 687]]  \n",
       "1    0.487   -0.050    [[0, 72], [18, 681]]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liblinear.to_csv('da_lr_liblinear.csv')\n",
    "model_liblinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>scaling</th>\n",
       "      <th>value</th>\n",
       "      <th>set</th>\n",
       "      <th>met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.764</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.754</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.754</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>none</td>\n",
       "      <td>0.753</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.753</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.000</td>\n",
       "      <td>val</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000</td>\n",
       "      <td>val</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>val</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>val</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>val</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sampling                      scaling  value    set  met\n",
       "53   No Sampling  Normalizer + StandardScaler  0.764  train   f1\n",
       "61   No Sampling               StandardScaler  0.754  train   f1\n",
       "62   No Sampling    Normalizer + MaxAbsScaler  0.754  train   f1\n",
       "66   No Sampling                         none  0.753  train   f1\n",
       "67   No Sampling                 MaxAbsScaler  0.753  train   f1\n",
       "..           ...                          ...    ...    ...  ...\n",
       "322        SMOTE                 MaxAbsScaler  0.000    val  mcc\n",
       "327        SMOTE                         none  0.000    val  mcc\n",
       "336        SMOTE  StandardScaler + Normalizer -0.009    val  mcc\n",
       "350        SMOTE    MaxAbsScaler + Normalizer -0.033    val  mcc\n",
       "351        SMOTE    MinMaxScaler + Normalizer -0.033    val  mcc\n",
       "\n",
       "[264 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liblinear_melted = pd.melt(model_liblinear, id_vars=['sampling', 'scaling'], value_vars=['train_accuracy', 'train_f1', 'train_ba', 'train_mcc', 'val_accuracy', 'val_f1', 'val_ba', 'val_mcc',], var_name='metrics', value_name='value')\n",
    "model_liblinear_melted = model_liblinear_melted.drop(model_liblinear_melted[model_liblinear_melted['metrics'].isin(['train_accuracy', 'val_accuracy'])].index)\n",
    "model_liblinear_melted['set'] = np.where(model_liblinear_melted['metrics'].str.startswith('train'), 'train', 'val')\n",
    "model_liblinear_melted['met'] = np.where(model_liblinear_melted['metrics'].str.endswith('f1'), 'f1', \n",
    "                                     np.where(model_liblinear_melted['metrics'].str.endswith('ba'), 'ba', 'mcc'))\n",
    "model_liblinear_melted['sampling'] = np.where(model_liblinear_melted['sampling'].str.startswith('RandomOver'), 'Random Oversampler', \n",
    "                                          np.where(model_liblinear_melted['sampling'].str.startswith('RandomUnder'), 'Random Undersampler', \n",
    "                                                   np.where(model_liblinear_melted['sampling'].str.startswith('SMOTE'), 'SMOTE', 'No Sampling'\n",
    "                                          )))\n",
    "model_liblinear_melted = model_liblinear_melted.drop(columns=['metrics']).sort_values(['sampling', 'set'])\n",
    "model_liblinear_melted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.violinplot(data=model_liblinear_melted[model_liblinear_melted['met']=='mcc'], \n",
    "               x='sampling', y='value', hue='set',)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('MCC Values for Baseline Model')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.violinplot(data=model_liblinear_melted[model_liblinear_melted['met']=='ba'], \n",
    "               x='sampling', y='value', hue='set',)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--')\n",
    "plt.title('BA Values for Baseline Model')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation took 1638.3135950565338 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>scaling</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_ba</th>\n",
       "      <th>train_mcc</th>\n",
       "      <th>train_cf</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_ba</th>\n",
       "      <th>val_mcc</th>\n",
       "      <th>val_cf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.046</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.077</td>\n",
       "      <td>[[0, 7, 0, 21, 0], [0, 374, 0, 324, 0], [0, 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.176</td>\n",
       "      <td>[[3, 79, 0, 0, 0], [0, 2095, 0, 1, 0], [0, 171...</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.043</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [0, 38, 9, 651, 0], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.031</td>\n",
       "      <td>[[28, 0, 0, 0, 0], [656, 42, 0, 0, 0], [56, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.683</td>\n",
       "      <td>[[42, 2, 5, 2, 1], [3, 38, 3, 3, 5], [0, 4, 39...</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.015</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [4, 0, 58, 636, 0], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.239</td>\n",
       "      <td>[[1949, 0, 72, 75, 0], [1244, 436, 179, 133, 1...</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.022</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [0, 29, 0, 645, 24], [0, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.010</td>\n",
       "      <td>[[0, 126, 1970, 0, 0], [135, 221, 1740, 0, 0],...</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.033</td>\n",
       "      <td>[[28, 0, 0, 0, 0], [677, 21, 0, 0, 0], [58, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.203</td>\n",
       "      <td>[[42, 0, 9, 0, 1], [24, 12, 16, 0, 0], [26, 2,...</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.027</td>\n",
       "      <td>[[0, 0, 28, 0, 0], [4, 32, 662, 0, 0], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.280</td>\n",
       "      <td>[[1969, 6, 89, 32, 0], [1302, 440, 147, 87, 12...</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.020</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [0, 19, 0, 0, 679], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.044</td>\n",
       "      <td>[[0, 3, 49, 0, 0], [1, 7, 44, 0, 0], [0, 3, 49...</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.024</td>\n",
       "      <td>[[0, 0, 28, 0, 0], [5, 30, 663, 0, 0], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.208</td>\n",
       "      <td>[[2063, 0, 5, 0, 28], [1623, 236, 50, 37, 150]...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.015</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [2, 17, 0, 1, 678], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.207</td>\n",
       "      <td>[[2062, 0, 5, 0, 29], [1623, 236, 48, 36, 153]...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.015</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [2, 17, 0, 1, 678], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.203</td>\n",
       "      <td>[[42, 0, 9, 0, 1], [24, 12, 16, 0, 0], [27, 2,...</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.027</td>\n",
       "      <td>[[0, 0, 28, 0, 0], [5, 28, 665, 0, 0], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.087</td>\n",
       "      <td>[[1999, 55, 6, 2, 34], [1658, 172, 2, 3, 261],...</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.009</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [0, 7, 7, 1, 683], [0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.577</td>\n",
       "      <td>[[1600, 150, 152, 141, 53], [356, 762, 371, 33...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.522</td>\n",
       "      <td>[[1546, 155, 179, 129, 87], [348, 733, 388, 32...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.516</td>\n",
       "      <td>[[1534, 167, 159, 132, 104], [364, 702, 355, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.513</td>\n",
       "      <td>[[1534, 169, 159, 129, 105], [368, 706, 348, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.507</td>\n",
       "      <td>[[1536, 107, 166, 158, 129], [356, 691, 380, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.455</td>\n",
       "      <td>[[1385, 179, 144, 158, 230], [344, 670, 393, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.455</td>\n",
       "      <td>[[1411, 179, 144, 158, 204], [345, 676, 389, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.115</td>\n",
       "      <td>[[2, 80, 0, 0, 0], [2, 2093, 0, 1, 0], [1, 169...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.046</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>none</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 2096, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 2...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 0, 52, 0], [0, 0, 0, 52, 0], [0, 0, 0,...</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [0, 0, 0, 698, 0], [0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 2096, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 2...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>none</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.186</td>\n",
       "      <td>[[2044, 0, 32, 0, 20], [1384, 256, 354, 40, 62...</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.016</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [1, 33, 0, 664, 0], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.180</td>\n",
       "      <td>[[2018, 0, 58, 0, 20], [1389, 257, 355, 40, 55...</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.016</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [1, 33, 0, 664, 0], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.045</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 173...</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [2, 696, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.450</td>\n",
       "      <td>[[1450, 162, 164, 158, 162], [380, 686, 368, 3...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [3, 695, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.045</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 173...</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [4, 694, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.266</td>\n",
       "      <td>[[44, 0, 2, 5, 1], [28, 12, 4, 3, 5], [27, 2, ...</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [0, 0, 51, 0, 647], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [11, 687, 0, 0, 0], [0, 58,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.195</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [18, 680, 0, 0, 0], [0, 58,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.477</td>\n",
       "      <td>[[36, 4, 3, 5, 4], [4, 26, 6, 6, 10], [5, 8, 2...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [14, 0, 19, 665, 0], [0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.492</td>\n",
       "      <td>[[35, 4, 3, 6, 4], [4, 30, 6, 3, 9], [6, 8, 23...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [12, 0, 20, 666, 0], [0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.338</td>\n",
       "      <td>[[36, 5, 4, 4, 3], [6, 25, 3, 4, 14], [13, 10,...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [51, 0, 0, 647, 0], [2, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.358</td>\n",
       "      <td>[[38, 5, 4, 4, 1], [9, 25, 4, 2, 12], [14, 10,...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [46, 0, 0, 652, 0], [2, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.426</td>\n",
       "      <td>[[34, 6, 3, 5, 4], [7, 30, 3, 3, 9], [8, 10, 2...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [29, 0, 0, 669, 0], [1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.394</td>\n",
       "      <td>[[1338, 225, 140, 239, 154], [394, 602, 343, 3...</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [36, 662, 0, 0, 0], [1, 57,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [36, 662, 0, 0, 0], [1, 57,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.372</td>\n",
       "      <td>[[1254, 280, 176, 286, 100], [387, 614, 333, 3...</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [38, 660, 0, 0, 0], [1, 57,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.475</td>\n",
       "      <td>[[1484, 160, 169, 168, 115], [369, 741, 311, 3...</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>[[1, 27, 0, 0, 0], [97, 585, 0, 0, 16], [7, 48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.467</td>\n",
       "      <td>[[1436, 156, 212, 172, 120], [339, 733, 327, 3...</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.172</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>[[1, 27, 0, 0, 0], [111, 577, 0, 0, 10], [10, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sampling                      scaling  train_accuracy  train_f1  \\\n",
       "38         no_sampling    Normalizer + MaxAbsScaler           0.830     0.754   \n",
       "40         no_sampling  Normalizer + StandardScaler           0.836     0.767   \n",
       "37         no_sampling                   Normalizer           0.830     0.753   \n",
       "14  RandomUnderSampler               StandardScaler           0.746     0.746   \n",
       "29   RandomOverSampler  Normalizer + StandardScaler           0.348     0.319   \n",
       "26   RandomOverSampler                   Normalizer           0.204     0.098   \n",
       "17  RandomUnderSampler    Normalizer + MinMaxScaler           0.338     0.301   \n",
       "7                SMOTE  Normalizer + StandardScaler           0.368     0.346   \n",
       "15  RandomUnderSampler                   Normalizer           0.215     0.106   \n",
       "5                SMOTE    Normalizer + MaxAbsScaler           0.294     0.232   \n",
       "6                SMOTE    Normalizer + MinMaxScaler           0.293     0.231   \n",
       "16  RandomUnderSampler    Normalizer + MaxAbsScaler           0.338     0.304   \n",
       "4                SMOTE                   Normalizer           0.238     0.142   \n",
       "3                SMOTE               StandardScaler           0.660     0.648   \n",
       "10               SMOTE  StandardScaler + Normalizer           0.616     0.605   \n",
       "2                SMOTE                 MinMaxScaler           0.611     0.597   \n",
       "1                SMOTE                 MaxAbsScaler           0.608     0.595   \n",
       "25   RandomOverSampler               StandardScaler           0.603     0.587   \n",
       "24   RandomOverSampler                 MinMaxScaler           0.562     0.548   \n",
       "23   RandomOverSampler                 MaxAbsScaler           0.561     0.548   \n",
       "36         no_sampling               StandardScaler           0.832     0.761   \n",
       "39         no_sampling    Normalizer + MinMaxScaler           0.830     0.754   \n",
       "0                SMOTE                         none           0.200     0.067   \n",
       "11  RandomUnderSampler                         none           0.200     0.067   \n",
       "22   RandomOverSampler                         none           0.200     0.067   \n",
       "33         no_sampling                         none           0.830     0.753   \n",
       "28   RandomOverSampler    Normalizer + MinMaxScaler           0.304     0.246   \n",
       "27   RandomOverSampler    Normalizer + MaxAbsScaler           0.300     0.244   \n",
       "34         no_sampling                 MaxAbsScaler           0.830     0.754   \n",
       "32   RandomOverSampler  StandardScaler + Normalizer           0.558     0.546   \n",
       "35         no_sampling                 MinMaxScaler           0.830     0.754   \n",
       "18  RandomUnderSampler  Normalizer + StandardScaler           0.381     0.368   \n",
       "43         no_sampling  StandardScaler + Normalizer           0.830     0.753   \n",
       "41         no_sampling    MaxAbsScaler + Normalizer           0.830     0.753   \n",
       "12  RandomUnderSampler                 MaxAbsScaler           0.581     0.576   \n",
       "13  RandomUnderSampler                 MinMaxScaler           0.592     0.588   \n",
       "19  RandomUnderSampler    MaxAbsScaler + Normalizer           0.465     0.454   \n",
       "20  RandomUnderSampler    MinMaxScaler + Normalizer           0.481     0.466   \n",
       "21  RandomUnderSampler  StandardScaler + Normalizer           0.538     0.534   \n",
       "30   RandomOverSampler    MaxAbsScaler + Normalizer           0.512     0.498   \n",
       "42         no_sampling    MinMaxScaler + Normalizer           0.830     0.753   \n",
       "31   RandomOverSampler    MinMaxScaler + Normalizer           0.495     0.484   \n",
       "8                SMOTE    MaxAbsScaler + Normalizer           0.577     0.565   \n",
       "9                SMOTE    MinMaxScaler + Normalizer           0.572     0.561   \n",
       "\n",
       "    train_ba  train_mcc                                           train_cf  \\\n",
       "38     0.202      0.046  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "40     0.231      0.176  [[3, 79, 0, 0, 0], [0, 2095, 0, 1, 0], [0, 171...   \n",
       "37     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "14     0.746      0.683  [[42, 2, 5, 2, 1], [3, 38, 3, 3, 5], [0, 4, 39...   \n",
       "29     0.348      0.239  [[1949, 0, 72, 75, 0], [1244, 436, 179, 133, 1...   \n",
       "26     0.204      0.010  [[0, 126, 1970, 0, 0], [135, 221, 1740, 0, 0],...   \n",
       "17     0.338      0.203  [[42, 0, 9, 0, 1], [24, 12, 16, 0, 0], [26, 2,...   \n",
       "7      0.368      0.280  [[1969, 6, 89, 32, 0], [1302, 440, 147, 87, 12...   \n",
       "15     0.215      0.044  [[0, 3, 49, 0, 0], [1, 7, 44, 0, 0], [0, 3, 49...   \n",
       "5      0.294      0.208  [[2063, 0, 5, 0, 28], [1623, 236, 50, 37, 150]...   \n",
       "6      0.293      0.207  [[2062, 0, 5, 0, 29], [1623, 236, 48, 36, 153]...   \n",
       "16     0.338      0.203  [[42, 0, 9, 0, 1], [24, 12, 16, 0, 0], [27, 2,...   \n",
       "4      0.238      0.087  [[1999, 55, 6, 2, 34], [1658, 172, 2, 3, 261],...   \n",
       "3      0.660      0.577  [[1600, 150, 152, 141, 53], [356, 762, 371, 33...   \n",
       "10     0.616      0.522  [[1546, 155, 179, 129, 87], [348, 733, 388, 32...   \n",
       "2      0.611      0.516  [[1534, 167, 159, 132, 104], [364, 702, 355, 3...   \n",
       "1      0.608      0.513  [[1534, 169, 159, 129, 105], [368, 706, 348, 3...   \n",
       "25     0.603      0.507  [[1536, 107, 166, 158, 129], [356, 691, 380, 3...   \n",
       "24     0.562      0.455  [[1385, 179, 144, 158, 230], [344, 670, 393, 3...   \n",
       "23     0.561      0.455  [[1411, 179, 144, 158, 204], [345, 676, 389, 3...   \n",
       "36     0.219      0.115  [[2, 80, 0, 0, 0], [2, 2093, 0, 1, 0], [1, 169...   \n",
       "39     0.202      0.046  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "0      0.200      0.000  [[0, 2096, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 2...   \n",
       "11     0.200      0.000  [[0, 0, 0, 52, 0], [0, 0, 0, 52, 0], [0, 0, 0,...   \n",
       "22     0.200      0.000  [[0, 2096, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 2...   \n",
       "33     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "28     0.304      0.186  [[2044, 0, 32, 0, 20], [1384, 256, 354, 40, 62...   \n",
       "27     0.300      0.180  [[2018, 0, 58, 0, 20], [1389, 257, 355, 40, 55...   \n",
       "34     0.201      0.045  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 173...   \n",
       "32     0.558      0.450  [[1450, 162, 164, 158, 162], [380, 686, 368, 3...   \n",
       "35     0.201      0.045  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 173...   \n",
       "18     0.381      0.266  [[44, 0, 2, 5, 1], [28, 12, 4, 3, 5], [27, 2, ...   \n",
       "43     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "41     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "12     0.581      0.477  [[36, 4, 3, 5, 4], [4, 26, 6, 6, 10], [5, 8, 2...   \n",
       "13     0.592      0.492  [[35, 4, 3, 6, 4], [4, 30, 6, 3, 9], [6, 8, 23...   \n",
       "19     0.465      0.338  [[36, 5, 4, 4, 3], [6, 25, 3, 4, 14], [13, 10,...   \n",
       "20     0.481      0.358  [[38, 5, 4, 4, 1], [9, 25, 4, 2, 12], [14, 10,...   \n",
       "21     0.538      0.426  [[34, 6, 3, 5, 4], [7, 30, 3, 3, 9], [8, 10, 2...   \n",
       "30     0.512      0.394  [[1338, 225, 140, 239, 154], [394, 602, 343, 3...   \n",
       "42     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "31     0.495      0.372  [[1254, 280, 176, 286, 100], [387, 614, 333, 3...   \n",
       "8      0.577      0.475  [[1484, 160, 169, 168, 115], [369, 741, 311, 3...   \n",
       "9      0.572      0.467  [[1436, 156, 212, 172, 120], [339, 733, 327, 3...   \n",
       "\n",
       "    val_accuracy  val_f1  val_ba  val_mcc  \\\n",
       "38         0.476   0.556   0.239    0.077   \n",
       "40         0.096   0.097   0.215    0.043   \n",
       "37         0.083   0.096   0.212    0.031   \n",
       "14         0.053   0.011   0.211    0.015   \n",
       "29         0.082   0.071   0.210    0.022   \n",
       "26         0.058   0.051   0.206    0.033   \n",
       "17         0.106   0.081   0.206    0.027   \n",
       "7          0.043   0.045   0.205    0.020   \n",
       "15         0.103   0.077   0.205    0.024   \n",
       "5          0.040   0.040   0.205    0.015   \n",
       "6          0.040   0.040   0.205    0.015   \n",
       "16         0.101   0.073   0.205    0.027   \n",
       "4          0.029   0.017   0.202    0.009   \n",
       "3          0.829   0.751   0.200    0.000   \n",
       "10         0.829   0.751   0.200    0.000   \n",
       "2          0.829   0.751   0.200    0.000   \n",
       "1          0.829   0.751   0.200    0.000   \n",
       "25         0.829   0.751   0.200    0.000   \n",
       "24         0.829   0.751   0.200    0.000   \n",
       "23         0.829   0.751   0.200    0.000   \n",
       "36         0.829   0.751   0.200    0.000   \n",
       "39         0.829   0.751   0.200    0.000   \n",
       "0          0.829   0.751   0.200    0.000   \n",
       "11         0.049   0.005   0.200    0.000   \n",
       "22         0.829   0.751   0.200    0.000   \n",
       "33         0.829   0.751   0.200    0.000   \n",
       "28         0.086   0.079   0.200    0.016   \n",
       "27         0.086   0.079   0.200    0.016   \n",
       "34         0.827   0.750   0.199   -0.013   \n",
       "32         0.825   0.750   0.199   -0.016   \n",
       "35         0.824   0.750   0.199   -0.000   \n",
       "18         0.023   0.004   0.199   -0.005   \n",
       "43         0.816   0.746   0.197   -0.008   \n",
       "41         0.808   0.742   0.195   -0.013   \n",
       "12         0.048   0.006   0.194   -0.009   \n",
       "13         0.048   0.006   0.194   -0.009   \n",
       "19         0.046   0.005   0.190   -0.007   \n",
       "20         0.046   0.005   0.190   -0.008   \n",
       "21         0.046   0.004   0.190   -0.012   \n",
       "30         0.786   0.732   0.190   -0.030   \n",
       "42         0.786   0.732   0.190   -0.030   \n",
       "31         0.784   0.730   0.189   -0.032   \n",
       "8          0.696   0.688   0.175   -0.038   \n",
       "9          0.686   0.683   0.172   -0.038   \n",
       "\n",
       "                                               val_cf  \n",
       "38  [[0, 7, 0, 21, 0], [0, 374, 0, 324, 0], [0, 28...  \n",
       "40  [[0, 0, 0, 28, 0], [0, 38, 9, 651, 0], [0, 1, ...  \n",
       "37  [[28, 0, 0, 0, 0], [656, 42, 0, 0, 0], [56, 2,...  \n",
       "14  [[0, 0, 0, 28, 0], [4, 0, 58, 636, 0], [0, 0, ...  \n",
       "29  [[0, 0, 0, 28, 0], [0, 29, 0, 645, 24], [0, 1,...  \n",
       "26  [[28, 0, 0, 0, 0], [677, 21, 0, 0, 0], [58, 0,...  \n",
       "17  [[0, 0, 28, 0, 0], [4, 32, 662, 0, 0], [0, 1, ...  \n",
       "7   [[0, 0, 0, 0, 28], [0, 19, 0, 0, 679], [0, 0, ...  \n",
       "15  [[0, 0, 28, 0, 0], [5, 30, 663, 0, 0], [0, 1, ...  \n",
       "5   [[0, 0, 0, 0, 28], [2, 17, 0, 1, 678], [0, 0, ...  \n",
       "6   [[0, 0, 0, 0, 28], [2, 17, 0, 1, 678], [0, 0, ...  \n",
       "16  [[0, 0, 28, 0, 0], [5, 28, 665, 0, 0], [0, 1, ...  \n",
       "4   [[0, 0, 0, 0, 28], [0, 7, 7, 1, 683], [0, 0, 0...  \n",
       "3   [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "10  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "2   [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "1   [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "25  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "24  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "23  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "36  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "39  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "0   [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "11  [[0, 0, 0, 28, 0], [0, 0, 0, 698, 0], [0, 0, 0...  \n",
       "22  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "33  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "28  [[0, 0, 0, 28, 0], [1, 33, 0, 664, 0], [0, 1, ...  \n",
       "27  [[0, 0, 0, 28, 0], [1, 33, 0, 664, 0], [0, 1, ...  \n",
       "34  [[0, 28, 0, 0, 0], [2, 696, 0, 0, 0], [0, 58, ...  \n",
       "32  [[0, 28, 0, 0, 0], [3, 695, 0, 0, 0], [0, 58, ...  \n",
       "35  [[0, 28, 0, 0, 0], [4, 694, 0, 0, 0], [0, 58, ...  \n",
       "18  [[0, 0, 0, 0, 28], [0, 0, 51, 0, 647], [0, 0, ...  \n",
       "43  [[0, 28, 0, 0, 0], [11, 687, 0, 0, 0], [0, 58,...  \n",
       "41  [[0, 28, 0, 0, 0], [18, 680, 0, 0, 0], [0, 58,...  \n",
       "12  [[0, 0, 0, 28, 0], [14, 0, 19, 665, 0], [0, 0,...  \n",
       "13  [[0, 0, 0, 28, 0], [12, 0, 20, 666, 0], [0, 0,...  \n",
       "19  [[0, 0, 0, 28, 0], [51, 0, 0, 647, 0], [2, 0, ...  \n",
       "20  [[0, 0, 0, 28, 0], [46, 0, 0, 652, 0], [2, 0, ...  \n",
       "21  [[0, 0, 0, 28, 0], [29, 0, 0, 669, 0], [1, 0, ...  \n",
       "30  [[0, 28, 0, 0, 0], [36, 662, 0, 0, 0], [1, 57,...  \n",
       "42  [[0, 28, 0, 0, 0], [36, 662, 0, 0, 0], [1, 57,...  \n",
       "31  [[0, 28, 0, 0, 0], [38, 660, 0, 0, 0], [1, 57,...  \n",
       "8   [[1, 27, 0, 0, 0], [97, 585, 0, 0, 16], [7, 48...  \n",
       "9   [[1, 27, 0, 0, 0], [111, 577, 0, 0, 10], [10, ...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_saga = pd.DataFrame(find_model(X_train, y_train, X_val, y_val, \n",
    "                                     multiclass=True,\n",
    "                                     algorithm='LogisticRegression', solver='saga'))#.to_csv('da_lr_saga.csv')\n",
    "end_time = time.time()\n",
    "duration_saga = end_time-start_time\n",
    "print(f\"Operation took {duration_saga} seconds.\")\n",
    "model_saga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saga.to_csv('db_lr_saga.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>scaling</th>\n",
       "      <th>value</th>\n",
       "      <th>set</th>\n",
       "      <th>met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.754</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.767</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.753</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.761</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>No Sampling</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.754</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.000</td>\n",
       "      <td>val</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.000</td>\n",
       "      <td>val</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000</td>\n",
       "      <td>val</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>val</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>val</td>\n",
       "      <td>mcc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sampling                      scaling  value    set  met\n",
       "44   No Sampling    Normalizer + MaxAbsScaler  0.754  train   f1\n",
       "45   No Sampling  Normalizer + StandardScaler  0.767  train   f1\n",
       "46   No Sampling                   Normalizer  0.753  train   f1\n",
       "64   No Sampling               StandardScaler  0.761  train   f1\n",
       "65   No Sampling    Normalizer + MinMaxScaler  0.754  train   f1\n",
       "..           ...                          ...    ...    ...  ...\n",
       "323        SMOTE                 MinMaxScaler  0.000    val  mcc\n",
       "324        SMOTE                 MaxAbsScaler  0.000    val  mcc\n",
       "330        SMOTE                         none  0.000    val  mcc\n",
       "350        SMOTE    MaxAbsScaler + Normalizer -0.038    val  mcc\n",
       "351        SMOTE    MinMaxScaler + Normalizer -0.038    val  mcc\n",
       "\n",
       "[264 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_saga_melted = pd.melt(model_saga, id_vars=['sampling', 'scaling'], value_vars=['train_accuracy', 'train_f1', 'train_ba', 'train_mcc', 'val_accuracy', 'val_f1', 'val_ba', 'val_mcc',], var_name='metrics', value_name='value')\n",
    "model_saga_melted = model_saga_melted.drop(model_saga_melted[model_saga_melted['metrics'].isin(['train_accuracy', 'val_accuracy'])].index)\n",
    "model_saga_melted['set'] = np.where(model_saga_melted['metrics'].str.startswith('train'), 'train', 'val')\n",
    "model_saga_melted['met'] = np.where(model_saga_melted['metrics'].str.endswith('f1'), 'f1', \n",
    "                                     np.where(model_saga_melted['metrics'].str.endswith('ba'), 'ba', 'mcc'))\n",
    "model_saga_melted['sampling'] = np.where(model_saga_melted['sampling'].str.startswith('RandomOver'), 'Random Oversampler', \n",
    "                                          np.where(model_saga_melted['sampling'].str.startswith('RandomUnder'), 'Random Undersampler', \n",
    "                                                   np.where(model_saga_melted['sampling'].str.startswith('SMOTE'), 'SMOTE', 'No Sampling'\n",
    "                                          )))\n",
    "model_saga_melted = model_saga_melted.drop(columns=['metrics']).sort_values(['sampling', 'set'])\n",
    "model_saga_melted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.violinplot(data=model_saga_melted[model_saga_melted['met']=='mcc'], \n",
    "               x='sampling', y='value', hue='set',)\n",
    "plt.title('MCC Values for Baseline Model, saga solver')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.violinplot(data=model_saga_melted[model_saga_melted['met']=='ba'], \n",
    "               x='sampling', y='value', hue='set',)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--')\n",
    "plt.title('BA Values for Baseline Model, saga solver')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot for all solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>scaling</th>\n",
       "      <th>value</th>\n",
       "      <th>set</th>\n",
       "      <th>met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.184</td>\n",
       "      <td>val</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.184</td>\n",
       "      <td>val</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Random Oversampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.189</td>\n",
       "      <td>val</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Random Oversampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.189</td>\n",
       "      <td>val</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Random Undersampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.190</td>\n",
       "      <td>val</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.600</td>\n",
       "      <td>train</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.602</td>\n",
       "      <td>train</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.604</td>\n",
       "      <td>train</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.652</td>\n",
       "      <td>train</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Random Undersampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.704</td>\n",
       "      <td>train</td>\n",
       "      <td>ba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                sampling                      scaling  value    set met\n",
       "307                SMOTE    MinMaxScaler + Normalizer  0.184    val  ba\n",
       "306                SMOTE    MaxAbsScaler + Normalizer  0.184    val  ba\n",
       "304   Random Oversampler    MaxAbsScaler + Normalizer  0.189    val  ba\n",
       "305   Random Oversampler    MinMaxScaler + Normalizer  0.189    val  ba\n",
       "301  Random Undersampler    MaxAbsScaler + Normalizer  0.190    val  ba\n",
       "..                   ...                          ...    ...    ...  ..\n",
       "102                SMOTE                 MaxAbsScaler  0.600  train  ba\n",
       "101                SMOTE                 MinMaxScaler  0.602  train  ba\n",
       "116                SMOTE  StandardScaler + Normalizer  0.604  train  ba\n",
       "100                SMOTE               StandardScaler  0.652  train  ba\n",
       "99   Random Undersampler               StandardScaler  0.704  train  ba\n",
       "\n",
       "[88 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liblinear_melted[model_liblinear_melted['met']=='ba'].sort_values(['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(ncols=3, nrows=2, figsize=(12, 6), sharex=True, sharey=True)\n",
    "\n",
    "ax[0, 0].set_title(f'lbfgs, t = {round(duration_lbfgs, 2)} s')\n",
    "ax[0, 1].set_title(f'liblinear, t = {round(duration_liblinear, 2)} s')\n",
    "ax[0, 2].set_title(f'saga, t = {round(duration_saga, 2)} s')\n",
    "\n",
    "for i, j in enumerate([model_lbfgs_melted, model_liblinear_melted, model_saga_melted]):\n",
    "    sns.violinplot(data=j[j['met']=='mcc'].sort_values(['sampling', 'set']), x='sampling', y='value', hue='set', ax=ax[0, i])\n",
    "    sns.violinplot(data=j[j['met']=='ba'].sort_values(['sampling', 'set']), x='sampling', y='value', hue='set', ax=ax[1, i])\n",
    "    ax[0, i].axhline(y=0, color='r', linestyle='--')\n",
    "    ax[1, i].axhline(y=0.5, color='r', linestyle='--')\n",
    "    ax[1, i].set_xticklabels(ax[1, i].get_xticklabels(), rotation=90, ha='center')\n",
    "    ax[0, i].set_xlabel('')\n",
    "    ax[1, i].set_xlabel('')\n",
    "    ax[0, i].set_ylabel('')\n",
    "    ax[1, i].set_ylabel('')\n",
    "    ax[0, 0].set_ylabel('Matthews Correlation\\nCoefficient')\n",
    "    ax[1, 0].set_ylabel('Balanced Accuracy')\n",
    "plt.setp(ax,\n",
    "         yticks=[-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1],\n",
    "         xticklabels=['No\\nSampling',  'Random\\nOversampling', 'Random\\nUndersampling', 'SMOTE'],\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>scaling</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_ba</th>\n",
       "      <th>train_mcc</th>\n",
       "      <th>train_cf</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_ba</th>\n",
       "      <th>val_mcc</th>\n",
       "      <th>val_cf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.200</td>\n",
       "      <td>[[2060, 0, 6, 0, 30], [1632, 225, 53, 41, 145]...</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.017</td>\n",
       "      <td>[[0, 0, 0, 27, 1], [1, 19, 0, 564, 114], [0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.245</td>\n",
       "      <td>[[1949, 0, 96, 26, 25], [1258, 448, 170, 108, ...</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.021</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [0, 23, 0, 660, 15], [0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.008</td>\n",
       "      <td>[[0, 126, 1970, 0, 0], [119, 233, 1743, 1, 0],...</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.022</td>\n",
       "      <td>[[28, 0, 0, 0, 0], [674, 24, 0, 0, 0], [57, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.084</td>\n",
       "      <td>[[2001, 56, 5, 2, 32], [1664, 211, 17, 3, 201]...</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.022</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [0, 18, 4, 0, 676], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.201</td>\n",
       "      <td>[[3, 0, 49, 0, 0], [0, 12, 40, 0, 0], [0, 3, 4...</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.030</td>\n",
       "      <td>[[0, 0, 28, 0, 0], [5, 30, 663, 0, 0], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.288</td>\n",
       "      <td>[[2005, 1, 82, 0, 8], [1309, 452, 125, 73, 137...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.017</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [0, 17, 0, 0, 681], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.046</td>\n",
       "      <td>[[0, 3, 49, 0, 0], [0, 7, 45, 0, 0], [0, 3, 49...</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.028</td>\n",
       "      <td>[[0, 0, 28, 0, 0], [1, 38, 659, 0, 0], [1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.201</td>\n",
       "      <td>[[2062, 0, 6, 0, 28], [1630, 235, 53, 37, 141]...</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.013</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [1, 20, 0, 621, 56], [0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.305</td>\n",
       "      <td>[[46, 0, 2, 3, 1], [30, 14, 2, 3, 3], [27, 3, ...</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>[[0, 0, 0, 0, 28], [0, 0, 55, 0, 643], [0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.157</td>\n",
       "      <td>[[2, 80, 0, 0, 0], [0, 2095, 0, 1, 0], [0, 171...</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.021</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [0, 37, 0, 661, 0], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.176</td>\n",
       "      <td>[[1949, 0, 127, 0, 20], [1273, 252, 467, 39, 6...</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.020</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [1, 36, 0, 660, 1], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.630</td>\n",
       "      <td>[[40, 2, 5, 4, 1], [3, 38, 3, 3, 5], [0, 4, 37...</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [11, 638, 49, 0, 0], [0, 53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.568</td>\n",
       "      <td>[[1592, 139, 160, 137, 68], [361, 735, 376, 32...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.506</td>\n",
       "      <td>[[1492, 164, 187, 137, 116], [366, 678, 350, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.503</td>\n",
       "      <td>[[1492, 168, 189, 136, 111], [353, 663, 370, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.496</td>\n",
       "      <td>[[1536, 107, 166, 158, 129], [363, 674, 375, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.441</td>\n",
       "      <td>[[1385, 179, 144, 158, 230], [357, 632, 383, 3...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.049</td>\n",
       "      <td>[[0, 81, 1, 0, 0], [1, 2094, 0, 1, 0], [1, 171...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.046</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>none</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 2096, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 2...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 0, 52, 0], [0, 0, 0, 52, 0], [0, 0, 0,...</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [0, 0, 0, 698, 0], [0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 2096, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 2...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>none</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.508</td>\n",
       "      <td>[[1536, 152, 184, 132, 92], [367, 685, 378, 33...</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [1, 697, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.425</td>\n",
       "      <td>[[1354, 162, 144, 232, 204], [361, 631, 383, 3...</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [2, 696, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.192</td>\n",
       "      <td>[[3, 0, 49, 0, 0], [0, 12, 40, 0, 0], [0, 3, 4...</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [2, 696, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.004</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [3, 695, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.440</td>\n",
       "      <td>[[1474, 162, 164, 158, 138], [398, 653, 346, 3...</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.199</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [3, 695, 0, 0, 0], [0, 58, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.174</td>\n",
       "      <td>[[1949, 0, 127, 0, 20], [1294, 250, 447, 40, 6...</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.013</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [1, 31, 0, 665, 1], [0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [12, 686, 0, 0, 0], [0, 58,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.450</td>\n",
       "      <td>[[34, 5, 3, 6, 4], [5, 25, 5, 5, 12], [6, 9, 2...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [18, 0, 18, 662, 0], [0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.454</td>\n",
       "      <td>[[35, 4, 3, 6, 4], [4, 25, 6, 5, 12], [6, 8, 2...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.194</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [16, 0, 20, 662, 0], [0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.325</td>\n",
       "      <td>[[36, 5, 4, 4, 3], [6, 25, 2, 3, 16], [15, 10,...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [51, 0, 0, 647, 0], [2, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.340</td>\n",
       "      <td>[[38, 5, 4, 4, 1], [11, 23, 4, 1, 13], [15, 10...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [50, 0, 0, 648, 0], [2, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.405</td>\n",
       "      <td>[[36, 6, 2, 4, 4], [8, 31, 3, 1, 9], [9, 13, 1...</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.190</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>[[0, 0, 0, 28, 0], [30, 0, 0, 668, 0], [1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.374</td>\n",
       "      <td>[[1283, 225, 96, 283, 209], [395, 588, 325, 39...</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [37, 661, 0, 0, 0], [1, 57,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.368</td>\n",
       "      <td>[[1228, 225, 125, 307, 211], [387, 597, 321, 4...</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>[[0, 28, 0, 0, 0], [38, 660, 0, 0, 0], [1, 57,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.453</td>\n",
       "      <td>[[1443, 169, 146, 206, 132], [399, 680, 294, 3...</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>[[1, 27, 0, 0, 0], [77, 617, 0, 0, 4], [6, 52,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.448</td>\n",
       "      <td>[[1417, 173, 155, 212, 139], [382, 690, 294, 3...</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.184</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>[[1, 27, 0, 0, 0], [78, 617, 0, 0, 3], [6, 52,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sampling                      scaling  train_accuracy  train_f1  \\\n",
       "6                SMOTE    Normalizer + MinMaxScaler           0.290     0.226   \n",
       "29   RandomOverSampler  Normalizer + StandardScaler           0.350     0.321   \n",
       "26   RandomOverSampler                   Normalizer           0.203     0.099   \n",
       "4                SMOTE                   Normalizer           0.236     0.141   \n",
       "16  RandomUnderSampler    Normalizer + MaxAbsScaler           0.292     0.247   \n",
       "7                SMOTE  Normalizer + StandardScaler           0.372     0.346   \n",
       "15  RandomUnderSampler                   Normalizer           0.215     0.106   \n",
       "5                SMOTE    Normalizer + MaxAbsScaler           0.290     0.226   \n",
       "18  RandomUnderSampler  Normalizer + StandardScaler           0.404     0.395   \n",
       "40         no_sampling  Normalizer + StandardScaler           0.835     0.764   \n",
       "27   RandomOverSampler    Normalizer + MaxAbsScaler           0.304     0.250   \n",
       "14  RandomUnderSampler               StandardScaler           0.704     0.704   \n",
       "3                SMOTE               StandardScaler           0.652     0.638   \n",
       "2                SMOTE                 MinMaxScaler           0.602     0.588   \n",
       "1                SMOTE                 MaxAbsScaler           0.600     0.586   \n",
       "25   RandomOverSampler               StandardScaler           0.594     0.578   \n",
       "24   RandomOverSampler                 MinMaxScaler           0.550     0.536   \n",
       "36         no_sampling               StandardScaler           0.830     0.754   \n",
       "38         no_sampling    Normalizer + MaxAbsScaler           0.830     0.754   \n",
       "0                SMOTE                         none           0.200     0.067   \n",
       "11  RandomUnderSampler                         none           0.200     0.067   \n",
       "22   RandomOverSampler                         none           0.200     0.067   \n",
       "33         no_sampling                         none           0.830     0.753   \n",
       "34         no_sampling                 MaxAbsScaler           0.830     0.753   \n",
       "35         no_sampling                 MinMaxScaler           0.830     0.753   \n",
       "37         no_sampling                   Normalizer           0.830     0.753   \n",
       "39         no_sampling    Normalizer + MinMaxScaler           0.830     0.753   \n",
       "41         no_sampling    MaxAbsScaler + Normalizer           0.830     0.753   \n",
       "10               SMOTE  StandardScaler + Normalizer           0.604     0.592   \n",
       "23   RandomOverSampler                 MaxAbsScaler           0.537     0.522   \n",
       "17  RandomUnderSampler    Normalizer + MinMaxScaler           0.288     0.241   \n",
       "42         no_sampling    MinMaxScaler + Normalizer           0.830     0.753   \n",
       "32   RandomOverSampler  StandardScaler + Normalizer           0.550     0.536   \n",
       "28   RandomOverSampler    Normalizer + MinMaxScaler           0.302     0.249   \n",
       "43         no_sampling  StandardScaler + Normalizer           0.830     0.753   \n",
       "12  RandomUnderSampler                 MaxAbsScaler           0.558     0.551   \n",
       "13  RandomUnderSampler                 MinMaxScaler           0.562     0.557   \n",
       "19  RandomUnderSampler    MaxAbsScaler + Normalizer           0.454     0.439   \n",
       "20  RandomUnderSampler    MinMaxScaler + Normalizer           0.465     0.448   \n",
       "21  RandomUnderSampler  StandardScaler + Normalizer           0.519     0.510   \n",
       "30   RandomOverSampler    MaxAbsScaler + Normalizer           0.496     0.480   \n",
       "31   RandomOverSampler    MinMaxScaler + Normalizer           0.492     0.479   \n",
       "8                SMOTE    MaxAbsScaler + Normalizer           0.559     0.545   \n",
       "9                SMOTE    MinMaxScaler + Normalizer           0.556     0.542   \n",
       "\n",
       "    train_ba  train_mcc                                           train_cf  \\\n",
       "6      0.290      0.200  [[2060, 0, 6, 0, 30], [1632, 225, 53, 41, 145]...   \n",
       "29     0.350      0.245  [[1949, 0, 96, 26, 25], [1258, 448, 170, 108, ...   \n",
       "26     0.203      0.008  [[0, 126, 1970, 0, 0], [119, 233, 1743, 1, 0],...   \n",
       "4      0.236      0.084  [[2001, 56, 5, 2, 32], [1664, 211, 17, 3, 201]...   \n",
       "16     0.292      0.201  [[3, 0, 49, 0, 0], [0, 12, 40, 0, 0], [0, 3, 4...   \n",
       "7      0.372      0.288  [[2005, 1, 82, 0, 8], [1309, 452, 125, 73, 137...   \n",
       "15     0.215      0.046  [[0, 3, 49, 0, 0], [0, 7, 45, 0, 0], [0, 3, 49...   \n",
       "5      0.290      0.201  [[2062, 0, 6, 0, 28], [1630, 235, 53, 37, 141]...   \n",
       "18     0.404      0.305  [[46, 0, 2, 3, 1], [30, 14, 2, 3, 3], [27, 3, ...   \n",
       "40     0.226      0.157  [[2, 80, 0, 0, 0], [0, 2095, 0, 1, 0], [0, 171...   \n",
       "27     0.304      0.176  [[1949, 0, 127, 0, 20], [1273, 252, 467, 39, 6...   \n",
       "14     0.704      0.630  [[40, 2, 5, 4, 1], [3, 38, 3, 3, 5], [0, 4, 37...   \n",
       "3      0.652      0.568  [[1592, 139, 160, 137, 68], [361, 735, 376, 32...   \n",
       "2      0.602      0.506  [[1492, 164, 187, 137, 116], [366, 678, 350, 3...   \n",
       "1      0.600      0.503  [[1492, 168, 189, 136, 111], [353, 663, 370, 3...   \n",
       "25     0.594      0.496  [[1536, 107, 166, 158, 129], [363, 674, 375, 3...   \n",
       "24     0.550      0.441  [[1385, 179, 144, 158, 230], [357, 632, 383, 3...   \n",
       "36     0.202      0.049  [[0, 81, 1, 0, 0], [1, 2094, 0, 1, 0], [1, 171...   \n",
       "38     0.202      0.046  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "0      0.200      0.000  [[0, 2096, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 2...   \n",
       "11     0.200      0.000  [[0, 0, 0, 52, 0], [0, 0, 0, 52, 0], [0, 0, 0,...   \n",
       "22     0.200      0.000  [[0, 2096, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 2...   \n",
       "33     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "34     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "35     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "37     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "39     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "41     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "10     0.604      0.508  [[1536, 152, 184, 132, 92], [367, 685, 378, 33...   \n",
       "23     0.537      0.425  [[1354, 162, 144, 232, 204], [361, 631, 383, 3...   \n",
       "17     0.288      0.192  [[3, 0, 49, 0, 0], [0, 12, 40, 0, 0], [0, 3, 4...   \n",
       "42     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "32     0.550      0.440  [[1474, 162, 164, 158, 138], [398, 653, 346, 3...   \n",
       "28     0.302      0.174  [[1949, 0, 127, 0, 20], [1294, 250, 447, 40, 6...   \n",
       "43     0.200      0.000  [[0, 82, 0, 0, 0], [0, 2096, 0, 0, 0], [0, 174...   \n",
       "12     0.558      0.450  [[34, 5, 3, 6, 4], [5, 25, 5, 5, 12], [6, 9, 2...   \n",
       "13     0.562      0.454  [[35, 4, 3, 6, 4], [4, 25, 6, 5, 12], [6, 8, 2...   \n",
       "19     0.454      0.325  [[36, 5, 4, 4, 3], [6, 25, 2, 3, 16], [15, 10,...   \n",
       "20     0.465      0.340  [[38, 5, 4, 4, 1], [11, 23, 4, 1, 13], [15, 10...   \n",
       "21     0.519      0.405  [[36, 6, 2, 4, 4], [8, 31, 3, 1, 9], [9, 13, 1...   \n",
       "30     0.496      0.374  [[1283, 225, 96, 283, 209], [395, 588, 325, 39...   \n",
       "31     0.492      0.368  [[1228, 225, 125, 307, 211], [387, 597, 321, 4...   \n",
       "8      0.559      0.453  [[1443, 169, 146, 206, 132], [399, 680, 294, 3...   \n",
       "9      0.556      0.448  [[1417, 173, 155, 212, 139], [382, 690, 294, 3...   \n",
       "\n",
       "    val_accuracy  val_f1  val_ba  val_mcc  \\\n",
       "6          0.069   0.049   0.216    0.017   \n",
       "29         0.075   0.058   0.209    0.021   \n",
       "26         0.062   0.057   0.207    0.022   \n",
       "4          0.042   0.042   0.205    0.022   \n",
       "16         0.103   0.077   0.205    0.030   \n",
       "7          0.040   0.040   0.205    0.017   \n",
       "15         0.112   0.094   0.204    0.028   \n",
       "5          0.070   0.051   0.203    0.013   \n",
       "18         0.024   0.005   0.202   -0.000   \n",
       "40         0.090   0.088   0.201    0.021   \n",
       "27         0.089   0.085   0.201    0.020   \n",
       "14         0.764   0.725   0.200   -0.016   \n",
       "3          0.829   0.751   0.200    0.000   \n",
       "2          0.829   0.751   0.200    0.000   \n",
       "1          0.829   0.751   0.200    0.000   \n",
       "25         0.829   0.751   0.200    0.000   \n",
       "24         0.829   0.751   0.200    0.000   \n",
       "36         0.829   0.751   0.200    0.000   \n",
       "38         0.829   0.751   0.200    0.000   \n",
       "0          0.829   0.751   0.200    0.000   \n",
       "11         0.049   0.005   0.200    0.000   \n",
       "22         0.829   0.751   0.200    0.000   \n",
       "33         0.829   0.751   0.200    0.000   \n",
       "34         0.829   0.751   0.200    0.000   \n",
       "35         0.829   0.751   0.200    0.000   \n",
       "37         0.829   0.751   0.200    0.000   \n",
       "39         0.829   0.751   0.200    0.000   \n",
       "41         0.829   0.751   0.200    0.000   \n",
       "10         0.828   0.751   0.200   -0.009   \n",
       "23         0.827   0.750   0.199   -0.013   \n",
       "17         0.827   0.750   0.199   -0.013   \n",
       "42         0.825   0.750   0.199    0.004   \n",
       "32         0.825   0.750   0.199   -0.016   \n",
       "28         0.083   0.075   0.199    0.013   \n",
       "43         0.815   0.745   0.197   -0.010   \n",
       "12         0.048   0.006   0.194   -0.008   \n",
       "13         0.048   0.006   0.194   -0.008   \n",
       "19         0.046   0.005   0.190   -0.007   \n",
       "20         0.046   0.005   0.190   -0.007   \n",
       "21         0.046   0.004   0.190   -0.011   \n",
       "30         0.785   0.731   0.189   -0.031   \n",
       "31         0.784   0.730   0.189   -0.032   \n",
       "8          0.734   0.707   0.184   -0.033   \n",
       "9          0.734   0.707   0.184   -0.033   \n",
       "\n",
       "                                               val_cf  \n",
       "6   [[0, 0, 0, 27, 1], [1, 19, 0, 564, 114], [0, 0...  \n",
       "29  [[0, 0, 0, 28, 0], [0, 23, 0, 660, 15], [0, 0,...  \n",
       "26  [[28, 0, 0, 0, 0], [674, 24, 0, 0, 0], [57, 1,...  \n",
       "4   [[0, 0, 0, 0, 28], [0, 18, 4, 0, 676], [0, 0, ...  \n",
       "16  [[0, 0, 28, 0, 0], [5, 30, 663, 0, 0], [0, 1, ...  \n",
       "7   [[0, 0, 0, 0, 28], [0, 17, 0, 0, 681], [0, 0, ...  \n",
       "15  [[0, 0, 28, 0, 0], [1, 38, 659, 0, 0], [1, 1, ...  \n",
       "5   [[0, 0, 0, 28, 0], [1, 20, 0, 621, 56], [0, 0,...  \n",
       "18  [[0, 0, 0, 0, 28], [0, 0, 55, 0, 643], [0, 0, ...  \n",
       "40  [[0, 0, 0, 28, 0], [0, 37, 0, 661, 0], [0, 1, ...  \n",
       "27  [[0, 0, 0, 28, 0], [1, 36, 0, 660, 1], [0, 1, ...  \n",
       "14  [[0, 28, 0, 0, 0], [11, 638, 49, 0, 0], [0, 53...  \n",
       "3   [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "2   [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "1   [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "25  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "24  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "36  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "38  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "0   [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "11  [[0, 0, 0, 28, 0], [0, 0, 0, 698, 0], [0, 0, 0...  \n",
       "22  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "33  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "34  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "35  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "37  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "39  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "41  [[0, 28, 0, 0, 0], [0, 698, 0, 0, 0], [0, 58, ...  \n",
       "10  [[0, 28, 0, 0, 0], [1, 697, 0, 0, 0], [0, 58, ...  \n",
       "23  [[0, 28, 0, 0, 0], [2, 696, 0, 0, 0], [0, 58, ...  \n",
       "17  [[0, 28, 0, 0, 0], [2, 696, 0, 0, 0], [0, 58, ...  \n",
       "42  [[0, 28, 0, 0, 0], [3, 695, 0, 0, 0], [0, 58, ...  \n",
       "32  [[0, 28, 0, 0, 0], [3, 695, 0, 0, 0], [0, 58, ...  \n",
       "28  [[0, 0, 0, 28, 0], [1, 31, 0, 665, 1], [0, 1, ...  \n",
       "43  [[0, 28, 0, 0, 0], [12, 686, 0, 0, 0], [0, 58,...  \n",
       "12  [[0, 0, 0, 28, 0], [18, 0, 18, 662, 0], [0, 0,...  \n",
       "13  [[0, 0, 0, 28, 0], [16, 0, 20, 662, 0], [0, 0,...  \n",
       "19  [[0, 0, 0, 28, 0], [51, 0, 0, 647, 0], [2, 0, ...  \n",
       "20  [[0, 0, 0, 28, 0], [50, 0, 0, 648, 0], [2, 0, ...  \n",
       "21  [[0, 0, 0, 28, 0], [30, 0, 0, 668, 0], [1, 0, ...  \n",
       "30  [[0, 28, 0, 0, 0], [37, 661, 0, 0, 0], [1, 57,...  \n",
       "31  [[0, 28, 0, 0, 0], [38, 660, 0, 0, 0], [1, 57,...  \n",
       "8   [[1, 27, 0, 0, 0], [77, 617, 0, 0, 4], [6, 52,...  \n",
       "9   [[1, 27, 0, 0, 0], [78, 617, 0, 0, 3], [6, 52,...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_liblinear#_melted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scores \n",
      "\n",
      "f1: 0.628\n",
      "balanced accuracy: 0.631\n",
      "matthews corrcoeff: 0.263\n",
      "cf:\n",
      "[[139  78]\n",
      " [ 82 135]]\n",
      "\n",
      "val scores \n",
      "\n",
      "f1: 0.696\n",
      "balanced accuracy: 0.629\n",
      "matthews corrcoeff: 0.150\n",
      "cf:\n",
      "[[ 51  21]\n",
      " [315 384]]\n"
     ]
    }
   ],
   "source": [
    "solver='liblinear'\n",
    "max_iter=10000\n",
    "random_state=0\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, descnm = data_preprocessing(data_db)\n",
    "\n",
    "X_train, y_train  = RandomUnderSampler(random_state=random_state).fit_resample(X_train, y_train)\n",
    "X_train = preprocessing.MinMaxScaler().fit_transform(X_train)\n",
    "X_train = preprocessing.Normalizer().fit_transform(X_train)\n",
    "\n",
    "# create final model in linreg\n",
    "lr = LogisticRegression(solver=solver,max_iter=max_iter, random_state=random_state)\n",
    "fit = lr.fit(X_train, y_train)\n",
    "y_pred = fit.predict(X_train)\n",
    "y_val_pred = fit.predict(X_val)\n",
    "\n",
    "# calculate statistical metrics for training set\n",
    "train_f1 = metrics.f1_score(y_train, y_pred, average = 'binary')\n",
    "train_ba = metrics.balanced_accuracy_score(y_train, y_pred)\n",
    "train_mcc = metrics.matthews_corrcoef(y_train, y_pred)\n",
    "train_cf = metrics.confusion_matrix(y_train, y_pred)\n",
    "\n",
    "# calculate statistical metrics for val set\n",
    "val_f1 = metrics.f1_score(y_val, y_val_pred, average = 'binary')\n",
    "val_ba = metrics.balanced_accuracy_score(y_val, y_val_pred)\n",
    "val_mcc = metrics.matthews_corrcoef(y_val, y_val_pred)\n",
    "val_cf = metrics.confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "print(f'train scores \\n')\n",
    "print(f'f1: {train_f1:.3f}')\n",
    "print(f'balanced accuracy: {train_ba:.3f}')\n",
    "print(f'matthews corrcoeff: {train_mcc:.3f}')\n",
    "print(f'cf:\\n{train_cf}')\n",
    "print('')\n",
    "print(f'val scores \\n')\n",
    "print(f'f1: {val_f1:.3f}')\n",
    "print(f'balanced accuracy: {val_ba:.3f}')\n",
    "print(f'matthews corrcoeff: {val_mcc:.3f}')\n",
    "print(f'cf:\\n{val_cf}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = permutation_importance(fit, X_val, y_val, n_repeats=10, random_state=random_state)\n",
    "\n",
    "feature_importance = pd.DataFrame({'Feature': descnm,\n",
    "                                   'Importance': result.importances_mean,\n",
    "                                   'Standard Deviation': result.importances_std})\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=True)\n",
    "\n",
    "\n",
    "ax = feature_importance.plot(x='Feature', y='Importance', kind='barh', \n",
    "                             \n",
    "                            yerr='Standard Deviation', capsize=4)\n",
    "ax.set_xlabel('Permutation Importance')\n",
    "ax.set_title('Permutation Importance with Standard Deviation')\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fr_NH2',\n",
       " 'NHOHCount',\n",
       " 'fr_priamide',\n",
       " 'PEOE_VSA1',\n",
       " 'NumSaturatedHeterocycles',\n",
       " 'fr_Ndealkylation1',\n",
       " 'VSA_EState7',\n",
       " 'fr_piperzine',\n",
       " 'SMR_VSA4',\n",
       " 'PEOE_VSA14',\n",
       " 'SlogP_VSA3',\n",
       " 'SlogP_VSA11',\n",
       " 'SlogP_VSA8',\n",
       " 'EState_VSA8',\n",
       " 'SMR_VSA6',\n",
       " 'SMR_VSA9',\n",
       " 'PEOE_VSA8',\n",
       " 'EState_VSA6',\n",
       " 'PEOE_VSA11',\n",
       " 'EState_VSA4',\n",
       " 'SlogP_VSA2',\n",
       " 'EState_VSA5']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance[feature_importance['Importance'] > 0].Feature.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scores \n",
      "\n",
      "f1: 0.593\n",
      "balanced accuracy: 0.604\n",
      "matthews corrcoeff: 0.209\n",
      "cf:\n",
      "[[127  74]\n",
      " [ 85 116]]\n",
      "\n",
      "val scores \n",
      "\n",
      "f1: 0.159\n",
      "balanced accuracy: 0.521\n",
      "matthews corrcoeff: 0.047\n",
      "cf:\n",
      "[[ 64   3]\n",
      " [505  48]]\n"
     ]
    }
   ],
   "source": [
    "solver='liblinear'\n",
    "max_iter=10000\n",
    "random_state=0\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, descnm = data_preprocessing(data_da[features_])\n",
    "\n",
    "X_train, y_train  = RandomUnderSampler(random_state=random_state).fit_resample(X_train, y_train)\n",
    "X_train = preprocessing.MinMaxScaler().fit_transform(X_train)\n",
    "X_train = preprocessing.Normalizer().fit_transform(X_train)\n",
    "\n",
    "# create final model in linreg\n",
    "lr = LogisticRegression(solver=solver,max_iter=max_iter, random_state=random_state)\n",
    "fit = lr.fit(X_train, y_train)\n",
    "y_pred = fit.predict(X_train)\n",
    "y_val_pred = fit.predict(X_val)\n",
    "\n",
    "# calculate statistical metrics for training set\n",
    "train_f1 = metrics.f1_score(y_train, y_pred, average = 'binary')\n",
    "train_ba = metrics.balanced_accuracy_score(y_train, y_pred)\n",
    "train_mcc = metrics.matthews_corrcoef(y_train, y_pred)\n",
    "train_cf = metrics.confusion_matrix(y_train, y_pred)\n",
    "\n",
    "# calculate statistical metrics for val set\n",
    "val_f1 = metrics.f1_score(y_val, y_val_pred, average = 'binary')\n",
    "val_ba = metrics.balanced_accuracy_score(y_val, y_val_pred)\n",
    "val_mcc = metrics.matthews_corrcoef(y_val, y_val_pred)\n",
    "val_cf = metrics.confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "print(f'train scores \\n')\n",
    "print(f'f1: {train_f1:.3f}')\n",
    "print(f'balanced accuracy: {train_ba:.3f}')\n",
    "print(f'matthews corrcoeff: {train_mcc:.3f}')\n",
    "print(f'cf:\\n{train_cf}')\n",
    "print('')\n",
    "print(f'val scores \\n')\n",
    "print(f'f1: {val_f1:.3f}')\n",
    "print(f'balanced accuracy: {val_ba:.3f}')\n",
    "print(f'matthews corrcoeff: {val_mcc:.3f}')\n",
    "print(f'cf:\\n{val_cf}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter tuning using gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X_train, y_train,\n",
    "                param_grid,\n",
    "                algorithm = 'LogisticRegression',\n",
    "                fold = 3,\n",
    "                scoring='balanced_accuracy',\n",
    "                random_state=0,\n",
    "                ):\n",
    "    \n",
    "    if algorithm == 'LogisticRegression':\n",
    "        model = LogisticRegression(random_state=random_state)\n",
    "    elif algorithm == 'SVC':\n",
    "        model = SVC(random_state=random_state)\n",
    "    elif algorithm == 'RandomForestClassifier':\n",
    "        model = RandomForestClassifier(random_state=random_state)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    cv_ = model_selection.GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=fold,\n",
    "        verbose=3,\n",
    "        scoring=scoring,\n",
    "        )\n",
    "    cv_.fit(X_train, y_train)\n",
    "\n",
    "    return cv_.cv_results_, cv_.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 504 candidates, totalling 1512 fits\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.8s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.7s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.509 total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.392 total time= 3.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.518 total time= 3.1min\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.423 total time=  58.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.331 total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.409 total time= 1.5min\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.4s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.558 total time= 4.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.441 total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.523 total time= 5.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.349 total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.309 total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.380 total time= 2.1min\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.1s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.9s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.8s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   1.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.8s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.8s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.8s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.509 total time= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.392 total time= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.518 total time= 2.3min\n",
      "[CV 1/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.423 total time=  37.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.331 total time=  41.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.001, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.409 total time= 1.2min\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.317 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.274 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.279 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.318 total time=   0.1s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.275 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.279 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.604 total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.511 total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.620 total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.448 total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.434 total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.476 total time= 2.0min\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.311 total time=   0.4s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.303 total time=   0.5s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.295 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.311 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.304 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.293 total time=   0.4s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.607 total time= 4.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.471 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.611 total time= 3.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.477 total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.468 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.474 total time= 2.0min\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.317 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.274 total time=   0.1s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.279 total time=   0.1s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.318 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.275 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.279 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.604 total time=  53.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.511 total time=  51.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.620 total time=  56.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.448 total time=  56.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.434 total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.001, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.476 total time= 1.6min\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.509 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.392 total time=  42.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.518 total time=  45.8s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.423 total time=  20.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.331 total time=  28.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.409 total time= 1.1min\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.558 total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.441 total time=  57.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.523 total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.349 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.309 total time=  56.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.380 total time= 1.7min\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.5s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.1s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.509 total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.392 total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.518 total time= 2.2min\n",
      "[CV 1/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.423 total time=  36.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.331 total time=  26.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.409 total time=  36.8s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.3s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.310 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.285 total time=   0.2s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.292 total time=   0.2s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.310 total time=   0.4s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.284 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.292 total time=   0.6s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.604 total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.511 total time=  42.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.620 total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.448 total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.434 total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.476 total time= 1.4min\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.293 total time=   0.1s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.304 total time=   0.1s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.296 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=  22.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.283 total time=  18.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.271 total time=  22.5s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.607 total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.471 total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.611 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.477 total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.468 total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.474 total time=  59.1s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.310 total time=   0.1s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.285 total time=   0.1s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.292 total time=   0.1s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.310 total time=   0.3s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.284 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.292 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.604 total time=  20.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.511 total time=  20.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.620 total time=  17.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.448 total time=  45.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.434 total time=  41.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.476 total time=  41.5s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.3s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.509 total time=  20.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.392 total time=  24.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.518 total time=  22.5s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.423 total time=  24.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.331 total time=  35.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.409 total time=  32.2s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.2s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.558 total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.441 total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.523 total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.349 total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.309 total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.380 total time=  51.7s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.509 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.392 total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.518 total time= 3.6min\n",
      "[CV 1/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.423 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.331 total time=  52.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.409 total time=  59.3s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.283 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.232 total time= 1.6min\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.308 total time=   0.2s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.312 total time=   0.1s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.307 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.303 total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.251 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.277 total time= 1.1min\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.604 total time=  18.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.511 total time=  17.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.620 total time=  18.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.448 total time=  48.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.434 total time=  40.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.476 total time=  40.3s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=  43.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=  52.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=  45.2s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.296 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.310 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.348 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.269 total time=  34.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.228 total time=  33.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.279 total time=  33.5s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.607 total time=  30.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.471 total time=  29.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.611 total time=  33.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.477 total time=  58.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.468 total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.474 total time=  57.9s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=  53.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.283 total time=  52.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.232 total time=  53.2s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.308 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.312 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.307 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.303 total time=  40.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.251 total time=  40.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.277 total time=  41.6s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.604 total time=  13.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.511 total time=  14.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.620 total time=  14.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.448 total time=  41.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.434 total time=  40.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.476 total time=  41.1s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   1.2s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.5s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   2.4s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.509 total time=  14.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.392 total time=  13.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.518 total time=  15.1s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.423 total time=  18.6s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.331 total time=  20.3s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.409 total time=  26.1s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.7s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.3s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   1.2s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.558 total time=  29.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.441 total time=  25.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.523 total time=  31.4s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.349 total time=  37.5s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.309 total time=  33.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.380 total time=  37.5s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   1.2s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   0.4s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   2.4s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.509 total time=  15.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.392 total time=  14.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.518 total time=  15.4s\n",
      "[CV 1/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.423 total time=  18.6s\n",
      "[CV 2/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.331 total time=  20.9s\n",
      "[CV 3/3] END C=1, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.409 total time=  26.3s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.249 total time=   0.1s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.320 total time=  52.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.266 total time=  54.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=  54.3s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.373 total time=   0.1s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.332 total time=   0.2s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.349 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.321 total time=  39.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.292 total time=  40.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.258 total time=  41.3s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.604 total time=  13.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.511 total time=  15.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.620 total time=  14.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.448 total time=  40.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.434 total time=  40.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.476 total time=  40.6s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.249 total time=   0.1s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.226 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.273 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.285 total time= 1.1min\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.397 total time=   0.1s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.332 total time=   0.1s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.374 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.287 total time=  32.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=  33.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=  32.1s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.607 total time=  30.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.471 total time=  28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.611 total time=  32.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.477 total time=  56.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.468 total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.474 total time=  57.1s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.320 total time=  54.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.266 total time=  52.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=  39.2s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.373 total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.332 total time=   0.1s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.349 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.321 total time=  30.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.292 total time=  29.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.258 total time=  30.3s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.604 total time=  12.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.511 total time=  13.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.620 total time=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.448 total time=  29.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.434 total time=  28.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.476 total time=  29.2s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   7.3s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   7.3s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   7.5s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.3s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.509 total time=  13.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.392 total time=  12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.518 total time=  13.3s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.423 total time=  13.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.331 total time=  15.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.409 total time=  18.1s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=  10.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   9.5s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=  13.6s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.4s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.3s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.3s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.558 total time=  25.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.441 total time=  22.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.523 total time=  24.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.349 total time=  25.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.309 total time=  22.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.380 total time=  24.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   7.9s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   6.4s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.250 total time=   8.4s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.1s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.2s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.3s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   0.2s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.509 total time=  12.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.392 total time=  12.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.518 total time=  12.5s\n",
      "[CV 1/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.423 total time=  13.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.331 total time=  14.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.409 total time=  19.2s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.352 total time=   0.2s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.304 total time=   0.3s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.382 total time=   0.2s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.374 total time=  40.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.436 total time=  40.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.378 total time=  40.7s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.295 total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.253 total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.289 total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.425 total time=   0.2s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.404 total time=   0.2s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.387 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.390 total time=  29.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.294 total time=  28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.287 total time=  31.4s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.604 total time=  12.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.511 total time=  13.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.620 total time=  12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.448 total time=  29.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.434 total time=  29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.476 total time=  30.4s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.352 total time=   0.3s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.304 total time=   0.3s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.382 total time=   0.2s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.386 total time=  50.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.350 total time=  50.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.390 total time=  50.6s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.295 total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.253 total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.289 total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.451 total time=   0.1s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.378 total time=   0.1s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.410 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.270 total time=  33.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.239 total time=  32.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.312 total time=  33.2s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.607 total time=  26.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.471 total time=  25.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.611 total time=  28.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.477 total time=  38.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.468 total time=  41.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.474 total time=  41.5s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.374 total time=  40.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.436 total time=  39.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.378 total time=  40.7s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.425 total time=   0.2s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.404 total time=   0.2s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.387 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.390 total time=  29.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.294 total time=  29.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.287 total time=  29.7s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.604 total time=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.511 total time=  12.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.620 total time=  12.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.448 total time=  28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.434 total time=  30.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.476 total time=  29.6s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.342 total time=   0.4s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.298 total time=   0.4s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.362 total time=   0.6s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.351 total time=  19.3s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.293 total time=  19.4s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.354 total time=  26.1s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.4s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.4s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.4s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   1.1s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   1.1s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   1.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.509 total time=  12.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.392 total time=  13.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.518 total time=  13.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.423 total time=  13.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.331 total time=  14.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.409 total time=  18.5s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.342 total time=   0.4s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.298 total time=   0.5s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.362 total time=   0.6s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.311 total time=  34.3s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.266 total time=  26.5s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.340 total time=  31.7s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.250 total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.2s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.2s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.2s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   1.7s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   1.8s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   1.6s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.558 total time=  26.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.441 total time=  22.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.523 total time=  24.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.349 total time=  25.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.309 total time=  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.380 total time=  24.1s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.351 total time=  18.9s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.293 total time=  18.8s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.354 total time=  28.2s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.4s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.4s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.250 total time=   0.4s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   1.1s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   1.1s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.250 total time=   1.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.509 total time=  13.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.392 total time=  12.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.518 total time=  13.0s\n",
      "[CV 1/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.423 total time=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.331 total time=  15.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.409 total time=  18.7s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.461 total time=   3.1s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.401 total time=   1.7s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.466 total time=   2.8s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.329 total time=  45.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.435 total time=  44.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.430 total time=  43.7s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.378 total time=   0.1s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.293 total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.347 total time=   0.1s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.500 total time=   0.5s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.442 total time=   0.5s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.495 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.317 total time=  30.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.295 total time=  28.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.307 total time=  30.2s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.604 total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.511 total time=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.620 total time=  12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.448 total time=  31.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.434 total time=  29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.476 total time=  30.1s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.461 total time=   2.4s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.401 total time=   1.5s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.466 total time=   3.7s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.486 total time=  59.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.416 total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.527 total time= 1.0min\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.378 total time=   0.1s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.293 total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.347 total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.485 total time=   0.4s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.460 total time=   0.4s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.475 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.323 total time=  33.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.435 total time=  32.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.408 total time=  34.6s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.607 total time=  25.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.471 total time=  25.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.611 total time=  29.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.477 total time=  40.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.468 total time=  42.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.474 total time=  40.5s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.329 total time=  44.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.435 total time=  44.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.430 total time=  44.6s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.500 total time=   0.6s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.442 total time=   0.5s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.495 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.317 total time=  29.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.295 total time=  30.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.307 total time=  30.5s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.604 total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.511 total time=  13.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.620 total time=  12.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.448 total time=  29.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.434 total time=  29.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.476 total time=  30.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.471 total time=   3.2s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.376 total time=   3.1s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.439 total time=   2.4s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.406 total time=  20.6s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.333 total time=  21.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.410 total time=  25.8s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.283 total time=   0.1s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.256 total time=   0.1s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.302 total time=   0.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.345 total time=   1.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.274 total time=   1.2s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.339 total time=   1.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.345 total time=   7.3s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.266 total time=   4.5s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.340 total time=   5.9s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.509 total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.392 total time=  13.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.518 total time=  13.5s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.423 total time=  13.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.331 total time=  15.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.409 total time=  18.7s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.471 total time=   3.6s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.376 total time=   2.3s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.439 total time=   3.3s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.360 total time=  39.7s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.293 total time=  33.2s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.369 total time=  36.8s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.283 total time=   0.1s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.256 total time=   0.1s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.302 total time=   0.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.283 total time=   0.7s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.256 total time=   0.7s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.302 total time=   0.7s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.283 total time=   8.3s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.257 total time=   6.9s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.302 total time=   8.2s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.558 total time=  24.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.441 total time=  22.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.523 total time=  24.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.349 total time=  25.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.309 total time=  22.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.380 total time=  23.5s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.406 total time=  20.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.333 total time=  20.4s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.410 total time=  27.8s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.345 total time=   1.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.274 total time=   1.1s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.339 total time=   1.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.345 total time=   6.6s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.266 total time=   5.6s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.340 total time=   5.3s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.509 total time=  14.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.392 total time=  12.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.518 total time=  12.6s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.423 total time=  14.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.331 total time=  14.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.409 total time=  19.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.506 total time=   9.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.442 total time=   8.6s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.524 total time=   6.1s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.471 total time=  46.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.436 total time=  37.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.470 total time=  38.8s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.433 total time=   0.1s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.402 total time=   0.1s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.448 total time=   0.1s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.473 total time=   0.8s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.445 total time=   0.8s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.555 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.386 total time=  25.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.347 total time=  24.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.271 total time=  29.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.604 total time=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.511 total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=lbfgs;, score=0.620 total time=  15.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.448 total time=  31.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.434 total time=  29.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=None, random_state=0, solver=saga;, score=0.476 total time=  26.9s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.506 total time=   8.8s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.442 total time=   7.4s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.524 total time=   6.4s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.502 total time=  50.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.410 total time=  54.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.535 total time=  53.7s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.433 total time=   0.1s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.402 total time=   0.1s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.448 total time=   0.1s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.486 total time=   0.7s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.463 total time=   0.7s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.517 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.366 total time=  28.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.445 total time=  28.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.449 total time=  29.4s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.607 total time=  14.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.471 total time=  14.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=lbfgs;, score=0.611 total time=  16.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.477 total time=  32.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.468 total time=  34.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=None, random_state=0, solver=saga;, score=0.474 total time=  34.1s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.471 total time=  37.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.436 total time=  41.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.470 total time=  41.1s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.473 total time=   0.8s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.445 total time=   1.5s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.555 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.386 total time=  27.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.347 total time=  28.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.271 total time=  27.6s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.604 total time=  10.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.511 total time=  10.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=lbfgs;, score=0.620 total time=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.448 total time=  29.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.434 total time=  28.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "714 fits failed out of a total of 1512.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "126 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "126 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "126 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "126 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1179, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "84 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1228, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1229, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "126 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1219, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 92, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.25              nan 0.25       0.25       0.25       0.25\n",
      "        nan        nan        nan        nan 0.47330497 0.38776907\n",
      " 0.25              nan 0.25       0.25       0.25       0.25\n",
      "        nan        nan        nan        nan 0.50705597 0.34598943\n",
      "        nan        nan 0.25              nan 0.25       0.25\n",
      "        nan        nan        nan        nan 0.47330497 0.38776907\n",
      " 0.25              nan 0.25       0.25       0.29026911 0.29093049\n",
      "        nan        nan        nan        nan 0.5783281  0.45253839\n",
      " 0.25              nan 0.25       0.25       0.30282821 0.30249489\n",
      "        nan        nan        nan        nan 0.56296029 0.47320143\n",
      "        nan        nan 0.25              nan 0.29026911 0.29093049\n",
      "        nan        nan        nan        nan 0.5783281  0.45253839\n",
      " 0.25              nan 0.25       0.25       0.25       0.25\n",
      "        nan        nan        nan        nan 0.47330497 0.38776907\n",
      " 0.25              nan 0.25       0.25       0.25       0.25\n",
      "        nan        nan        nan        nan 0.50705597 0.34598943\n",
      "        nan        nan 0.25              nan 0.25       0.25\n",
      "        nan        nan        nan        nan 0.47330497 0.38776907\n",
      " 0.25              nan 0.25       0.25       0.29552912 0.29519844\n",
      "        nan        nan        nan        nan 0.5783281  0.45253839\n",
      " 0.25              nan 0.25       0.25       0.29783466 0.26797362\n",
      "        nan        nan        nan        nan 0.56296029 0.47320143\n",
      "        nan        nan 0.25              nan 0.29552912 0.29519844\n",
      "        nan        nan        nan        nan 0.5783281  0.45253839\n",
      " 0.25              nan 0.25       0.25       0.25       0.25\n",
      "        nan        nan        nan        nan 0.47330497 0.38776907\n",
      " 0.25              nan 0.25       0.25       0.25       0.25\n",
      "        nan        nan        nan        nan 0.50705597 0.34598943\n",
      "        nan        nan 0.25              nan 0.25       0.25\n",
      "        nan        nan        nan        nan 0.47330497 0.38776907\n",
      " 0.25              nan 0.25524135 0.25       0.3088067  0.27713368\n",
      "        nan        nan        nan        nan 0.5783281  0.45253839\n",
      " 0.25              nan 0.25       0.25       0.31793209 0.2587064\n",
      "        nan        nan        nan        nan 0.56296029 0.47320143\n",
      "        nan        nan 0.25524135        nan 0.3088067  0.27713368\n",
      "        nan        nan        nan        nan 0.5783281  0.45253839\n",
      " 0.25              nan 0.25       0.25       0.25       0.25\n",
      "        nan        nan        nan        nan 0.47330497 0.38776907\n",
      " 0.25              nan 0.25       0.25       0.25       0.25\n",
      "        nan        nan        nan        nan 0.50705597 0.34598943\n",
      "        nan        nan 0.25              nan 0.25       0.25\n",
      "        nan        nan        nan        nan 0.47330497 0.38776907\n",
      " 0.24966931        nan 0.27840158 0.25       0.35151363 0.29015194\n",
      "        nan        nan        nan        nan 0.5783281  0.45253839\n",
      " 0.24966931        nan 0.26114937 0.25       0.36768455 0.26235227\n",
      "        nan        nan        nan        nan 0.56296029 0.47320143\n",
      "        nan        nan 0.27840158        nan 0.35151363 0.29015194\n",
      "        nan        nan        nan        nan 0.5783281  0.45253839\n",
      " 0.25              nan 0.25       0.25       0.25       0.25\n",
      "        nan        nan        nan        nan 0.47330497 0.38776907\n",
      " 0.25              nan 0.25       0.25       0.25       0.25\n",
      "        nan        nan        nan        nan 0.50705597 0.34598943\n",
      "        nan        nan 0.25              nan 0.25       0.25\n",
      "        nan        nan        nan        nan 0.47330497 0.38776907\n",
      " 0.34586107        nan 0.39581256 0.27912644 0.40499777 0.32393185\n",
      "        nan        nan        nan        nan 0.5783281  0.45253839\n",
      " 0.34586107        nan 0.37534246 0.27912644 0.41299644 0.2735843\n",
      "        nan        nan        nan        nan 0.56296029 0.47320143\n",
      "        nan        nan 0.39581256        nan 0.40499777 0.32393185\n",
      "        nan        nan        nan        nan 0.5783281  0.45253839\n",
      " 0.33418124        nan 0.33260409 0.25       0.25       0.25\n",
      "        nan        nan        nan        nan 0.47330497 0.38776907\n",
      " 0.33418124        nan 0.30555469 0.25       0.25       0.25\n",
      "        nan        nan        nan        nan 0.50705597 0.34598943\n",
      "        nan        nan 0.33260409        nan 0.25       0.25\n",
      "        nan        nan        nan        nan 0.47330497 0.38776907\n",
      " 0.44280278        nan 0.39816987 0.33947919 0.47909019 0.30627019\n",
      "        nan        nan        nan        nan 0.5783281  0.45253839\n",
      " 0.44280278        nan 0.47611246 0.33947919 0.47335722 0.38866946\n",
      "        nan        nan        nan        nan 0.56296029 0.47320143\n",
      "        nan        nan 0.39816987        nan 0.47909019 0.30627019\n",
      "        nan        nan        nan        nan 0.5783281  0.45253839\n",
      " 0.42843521        nan 0.38286578 0.28018277 0.31909119 0.31681903\n",
      "        nan        nan        nan        nan 0.47330497 0.38776907\n",
      " 0.42843521        nan 0.3409471  0.28018277 0.28018277 0.28051346\n",
      "        nan        nan        nan        nan 0.50705597 0.34598943\n",
      "        nan        nan 0.38286578        nan 0.31909119 0.31681903\n",
      "        nan        nan        nan        nan 0.47330497 0.38776907\n",
      " 0.49051603        nan 0.45896988 0.42768399 0.4912232  0.3347467\n",
      "        nan        nan        nan        nan 0.5783281  0.45253839\n",
      " 0.49051603        nan 0.48213028 0.42768399 0.48871244 0.4199866\n",
      "        nan        nan        nan        nan 0.56296029 0.47320143\n",
      "        nan        nan 0.45896988        nan 0.4912232  0.3347467\n",
      "        nan        nan        nan        nan 0.5783281  0.45253839]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=None, random_state=0, solver=saga;, score=0.476 total time=  25.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.001,\n",
       " 'class_weight': 'balanced',\n",
       " 'max_iter': 10000,\n",
       " 'multi_class': 'auto',\n",
       " 'penalty': None,\n",
       " 'random_state': 0,\n",
       " 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'solver': ['liblinear', 'lbfgs', 'saga',],# 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    'class_weight':[None, 'balanced'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'multi_class': ['auto', 'ovr', 'multinomial'],\n",
    "    'max_iter': [10000],\n",
    "    'random_state':[0]\n",
    "}\n",
    "\n",
    "random_state=0\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, descnm = data_preprocessing(data_db)\n",
    "X_train, y_train  = SMOTE(random_state=random_state).fit_resample(X_train, y_train)\n",
    "scaler = preprocessing.Normalizer()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "cv_res, cv_params = grid_search(X_val, y_val, param_grid, \n",
    "                                algorithm='LogisticRegression',)\n",
    "\n",
    "cv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>14.427718</td>\n",
       "      <td>0.405074</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'max_it...</td>\n",
       "      <td>0.604209</td>\n",
       "      <td>0.511072</td>\n",
       "      <td>0.619703</td>\n",
       "      <td>0.578328</td>\n",
       "      <td>0.047976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>12.783788</td>\n",
       "      <td>0.514693</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'max_ite...</td>\n",
       "      <td>0.604209</td>\n",
       "      <td>0.511072</td>\n",
       "      <td>0.619703</td>\n",
       "      <td>0.578328</td>\n",
       "      <td>0.047976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>12.530428</td>\n",
       "      <td>0.382646</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'max_iter...</td>\n",
       "      <td>0.604209</td>\n",
       "      <td>0.511072</td>\n",
       "      <td>0.619703</td>\n",
       "      <td>0.578328</td>\n",
       "      <td>0.047976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>86.084208</td>\n",
       "      <td>26.223098</td>\n",
       "      <td>0.011181</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>0.001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.001, 'class_weight': 'balanced', 'max_...</td>\n",
       "      <td>0.604209</td>\n",
       "      <td>0.511072</td>\n",
       "      <td>0.619703</td>\n",
       "      <td>0.578328</td>\n",
       "      <td>0.047976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>12.626360</td>\n",
       "      <td>0.585792</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>100</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>auto</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 100, 'class_weight': 'balanced', 'max_it...</td>\n",
       "      <td>0.604209</td>\n",
       "      <td>0.511072</td>\n",
       "      <td>0.619703</td>\n",
       "      <td>0.578328</td>\n",
       "      <td>0.047976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1000, 'class_weight': 'balanced', 'max_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1000, 'class_weight': 'balanced', 'max_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 1000, 'class_weight': 'balanced', 'max_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 1000, 'class_weight': 'balanced', 'max_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 1000, 'class_weight': 'balanced', 'max_i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "214      14.427718      0.405074         0.002739        0.000225     0.1   \n",
       "358      12.783788      0.514693         0.002513        0.000036      10   \n",
       "286      12.530428      0.382646         0.003328        0.001142       1   \n",
       "46       86.084208     26.223098         0.011181        0.008977   0.001   \n",
       "406      12.626360      0.585792         0.002982        0.000097     100   \n",
       "..             ...           ...              ...             ...     ...   \n",
       "495       0.001298      0.000144         0.000000        0.000000    1000   \n",
       "498       0.000821      0.000071         0.000000        0.000000    1000   \n",
       "499       0.000716      0.000031         0.000000        0.000000    1000   \n",
       "500       0.000704      0.000019         0.000000        0.000000    1000   \n",
       "501       0.001229      0.000011         0.000000        0.000000    1000   \n",
       "\n",
       "    param_class_weight param_max_iter param_multi_class param_penalty  \\\n",
       "214           balanced          10000       multinomial          None   \n",
       "358           balanced          10000       multinomial          None   \n",
       "286           balanced          10000       multinomial          None   \n",
       "46            balanced          10000              auto          None   \n",
       "406           balanced          10000              auto          None   \n",
       "..                 ...            ...               ...           ...   \n",
       "495           balanced          10000       multinomial            l2   \n",
       "498           balanced          10000       multinomial    elasticnet   \n",
       "499           balanced          10000       multinomial    elasticnet   \n",
       "500           balanced          10000       multinomial    elasticnet   \n",
       "501           balanced          10000       multinomial          None   \n",
       "\n",
       "    param_random_state param_solver  \\\n",
       "214                  0        lbfgs   \n",
       "358                  0        lbfgs   \n",
       "286                  0        lbfgs   \n",
       "46                   0        lbfgs   \n",
       "406                  0        lbfgs   \n",
       "..                 ...          ...   \n",
       "495                  0    liblinear   \n",
       "498                  0    liblinear   \n",
       "499                  0        lbfgs   \n",
       "500                  0         saga   \n",
       "501                  0    liblinear   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "214  {'C': 0.1, 'class_weight': 'balanced', 'max_it...           0.604209   \n",
       "358  {'C': 10, 'class_weight': 'balanced', 'max_ite...           0.604209   \n",
       "286  {'C': 1, 'class_weight': 'balanced', 'max_iter...           0.604209   \n",
       "46   {'C': 0.001, 'class_weight': 'balanced', 'max_...           0.604209   \n",
       "406  {'C': 100, 'class_weight': 'balanced', 'max_it...           0.604209   \n",
       "..                                                 ...                ...   \n",
       "495  {'C': 1000, 'class_weight': 'balanced', 'max_i...                NaN   \n",
       "498  {'C': 1000, 'class_weight': 'balanced', 'max_i...                NaN   \n",
       "499  {'C': 1000, 'class_weight': 'balanced', 'max_i...                NaN   \n",
       "500  {'C': 1000, 'class_weight': 'balanced', 'max_i...                NaN   \n",
       "501  {'C': 1000, 'class_weight': 'balanced', 'max_i...                NaN   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "214           0.511072           0.619703         0.578328        0.047976   \n",
       "358           0.511072           0.619703         0.578328        0.047976   \n",
       "286           0.511072           0.619703         0.578328        0.047976   \n",
       "46            0.511072           0.619703         0.578328        0.047976   \n",
       "406           0.511072           0.619703         0.578328        0.047976   \n",
       "..                 ...                ...              ...             ...   \n",
       "495                NaN                NaN              NaN             NaN   \n",
       "498                NaN                NaN              NaN             NaN   \n",
       "499                NaN                NaN              NaN             NaN   \n",
       "500                NaN                NaN              NaN             NaN   \n",
       "501                NaN                NaN              NaN             NaN   \n",
       "\n",
       "     rank_test_score  \n",
       "214                1  \n",
       "358                1  \n",
       "286                1  \n",
       "46                 1  \n",
       "406                1  \n",
       "..               ...  \n",
       "495              267  \n",
       "498              267  \n",
       "499              267  \n",
       "500              267  \n",
       "501              267  \n",
       "\n",
       "[504 rows x 18 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_lr_cv_iter_1 = pd.DataFrame(cv_res).sort_values(by='mean_test_score', ascending=False)\n",
    "db_lr_cv_iter_1.to_csv('db_lr_cv_iter_1.csv', index=False)\n",
    "db_lr_cv_iter_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.471 total time=   8.1s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.376 total time=  12.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.439 total time=   8.7s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.406 total time=  43.8s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.333 total time=  34.3s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.410 total time=  46.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.283 total time=   0.1s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.256 total time=   0.1s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.302 total time=   0.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.345 total time=   3.4s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.274 total time=   3.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.339 total time=   2.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.345 total time=  10.7s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.266 total time=   7.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.340 total time=  13.8s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.471 total time=   9.9s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.376 total time=   4.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.439 total time=   4.7s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.360 total time= 1.2min\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.293 total time= 1.9min\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.369 total time= 1.4min\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.283 total time=   0.1s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.256 total time=   0.1s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.302 total time=   0.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.283 total time=   2.8s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.256 total time=   1.6s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.302 total time=   2.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.283 total time=  16.1s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.257 total time=  23.5s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.302 total time=  22.8s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.406 total time=  36.1s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.333 total time=  44.5s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.410 total time=  54.7s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.345 total time=   1.8s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.274 total time=   3.7s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.339 total time=   2.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.345 total time=  11.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.266 total time=   9.4s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.340 total time=  13.9s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.506 total time=  19.9s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.442 total time=  21.2s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.524 total time=  11.4s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.471 total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.436 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.470 total time= 1.6min\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.433 total time=   0.4s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.402 total time=   0.3s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.448 total time=   0.4s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.473 total time=   6.6s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.445 total time=   2.1s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.555 total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.386 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.347 total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.271 total time=  50.6s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.506 total time=  19.5s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.442 total time=  19.9s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.524 total time=  26.7s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.502 total time= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.410 total time= 3.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.535 total time= 3.4min\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.433 total time=   0.5s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.402 total time=   0.2s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.448 total time=   0.2s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.486 total time=   5.7s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.463 total time=   3.5s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.517 total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.366 total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.445 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.449 total time= 1.5min\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.471 total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.436 total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.470 total time= 1.8min\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.473 total time=   4.7s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.445 total time=   4.3s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.555 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.386 total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.347 total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.271 total time= 1.2min\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.478 total time=  10.5s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.381 total time=   9.8s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.487 total time=   8.9s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.417 total time=  47.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.333 total time=  49.6s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.409 total time= 1.1min\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.313 total time=   0.1s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.266 total time=   0.2s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.344 total time=   0.1s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.342 total time=   5.3s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.271 total time=   3.6s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.375 total time=   4.6s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.343 total time=  18.5s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.272 total time=  14.3s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.375 total time=  18.3s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.478 total time=  15.1s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.381 total time=  10.3s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.487 total time=  20.1s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.359 total time= 2.4min\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.301 total time= 1.1min\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.380 total time= 1.2min\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.313 total time=   0.1s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.266 total time=   0.2s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.344 total time=   0.1s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.313 total time=   3.8s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.266 total time=   1.8s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.344 total time=   3.2s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.313 total time=  23.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.266 total time=  31.2s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.332 total time=  20.4s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.417 total time=  35.2s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.333 total time=  36.9s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.409 total time=  48.0s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.342 total time=   2.4s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.271 total time=   3.4s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.375 total time=   2.3s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.343 total time=  13.6s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.272 total time=  11.2s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.375 total time=  12.3s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.549 total time=  21.6s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.495 total time=  45.9s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.539 total time=  13.9s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.329 total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.425 total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.356 total time= 1.3min\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.449 total time=   0.1s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.407 total time=   0.1s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.466 total time=   0.2s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.509 total time=   4.3s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.440 total time=   3.7s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.549 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.388 total time=  49.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.362 total time=  50.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.537 total time=  43.1s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.549 total time=  19.7s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.495 total time=  39.0s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.539 total time=  11.5s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.529 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.444 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.542 total time= 1.5min\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.449 total time=   0.1s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.407 total time=   0.1s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.466 total time=   0.1s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.499 total time=   2.9s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.462 total time=   2.1s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.543 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.466 total time=  53.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.350 total time=  51.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.424 total time=  52.8s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.329 total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.425 total time=  53.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.356 total time=  42.8s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.509 total time=   2.5s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.440 total time=   1.9s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.549 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.388 total time=  27.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.362 total time=  27.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.537 total time=  33.8s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=2000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.491 total time=   6.0s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.383 total time=   7.4s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.478 total time=   5.5s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.423 total time=  20.1s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.331 total time=  23.1s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.409 total time=  28.3s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.311 total time=   0.1s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.273 total time=   0.1s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.364 total time=   0.1s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.398 total time=   2.1s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.328 total time=   2.7s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.382 total time=   2.1s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.376 total time=  10.2s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.311 total time=   8.9s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.384 total time=  11.1s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.491 total time=   6.8s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.383 total time=   6.6s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.478 total time=   5.5s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.349 total time=  38.5s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.309 total time=  33.6s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.380 total time=  36.3s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.311 total time=   0.1s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.273 total time=   0.1s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.364 total time=   0.1s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.311 total time=   1.2s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.273 total time=   1.2s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.364 total time=   1.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.311 total time=  15.7s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.274 total time=  12.0s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.342 total time=  15.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.423 total time=  19.9s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.331 total time=  20.7s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.409 total time=  28.3s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.398 total time=   1.7s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.328 total time=   2.9s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.382 total time=   3.2s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.376 total time=   9.7s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.311 total time=   9.7s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.384 total time=  11.5s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.603 total time=  16.6s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.527 total time=  43.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.578 total time=  18.8s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.449 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.335 total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.489 total time= 1.9min\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.470 total time=   0.2s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.392 total time=   0.2s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.465 total time=   0.1s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.528 total time=   4.0s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.444 total time=   5.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.531 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.369 total time=  42.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.433 total time=  46.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.439 total time=  34.7s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.603 total time=  28.4s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.527 total time= 1.5min\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.578 total time=  36.7s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.454 total time= 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.370 total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.567 total time= 3.5min\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.470 total time=   0.6s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.392 total time=   0.3s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.465 total time=   0.3s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.497 total time=   8.9s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.457 total time=   9.5s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.535 total time=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.496 total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.430 total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.540 total time= 2.2min\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.449 total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.335 total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.489 total time= 2.3min\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.528 total time=  14.2s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.444 total time=  16.7s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.531 total time=  12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.369 total time= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.433 total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.439 total time= 1.3min\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=5000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.507 total time=  24.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.413 total time=  28.9s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.479 total time=  20.9s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.423 total time=  56.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.331 total time= 1.1min\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.409 total time= 1.3min\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.335 total time=   0.3s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.309 total time=   0.3s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.380 total time=   0.3s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.421 total time=  10.2s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.341 total time=  10.4s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.411 total time=   9.8s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.398 total time=  30.7s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.329 total time=  32.8s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.380 total time=  49.1s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.507 total time=  29.3s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.413 total time=  31.7s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.479 total time=  22.8s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.349 total time= 1.9min\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.309 total time= 2.2min\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.380 total time= 2.0min\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.335 total time=   1.9s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.309 total time=   2.1s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.380 total time=   2.4s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.335 total time=  15.5s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.309 total time=  10.4s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.380 total time=   9.4s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.317 total time= 1.2min\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.273 total time=  56.0s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.372 total time= 2.0min\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.423 total time= 2.2min\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.331 total time= 1.2min\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.409 total time= 2.0min\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.421 total time=  13.2s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.341 total time=  10.5s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.411 total time=  10.4s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.398 total time=  33.1s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.329 total time=  30.2s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.380 total time=  46.0s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=None, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.633 total time= 1.1min\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.511 total time= 2.8min\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=liblinear;, score=0.557 total time= 1.5min\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.421 total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.460 total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l1, random_state=0, solver=saga;, score=0.511 total time= 2.6min\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.499 total time=   0.7s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.411 total time=   0.6s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=liblinear;, score=0.464 total time=   0.5s\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.517 total time=  14.2s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.450 total time=  20.0s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=lbfgs;, score=0.540 total time=  22.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.447 total time= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.431 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=l2, random_state=0, solver=saga;, score=0.397 total time= 1.8min\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=auto, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.633 total time=  53.7s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.511 total time= 5.0min\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=liblinear;, score=0.557 total time= 2.5min\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.497 total time= 3.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.458 total time= 5.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l1, random_state=0, solver=saga;, score=0.455 total time= 3.8min\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.499 total time=   0.7s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.411 total time=   0.8s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=liblinear;, score=0.464 total time=   0.7s\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.508 total time=  18.7s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.472 total time=  14.7s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=lbfgs;, score=0.538 total time=  13.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.523 total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.432 total time= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=l2, random_state=0, solver=saga;, score=0.403 total time= 2.1min\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=ovr, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.421 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.460 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l1, random_state=0, solver=saga;, score=0.511 total time= 2.1min\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.517 total time=  32.0s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.450 total time=  59.6s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=lbfgs;, score=0.540 total time=  18.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.447 total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.431 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "336 fits failed out of a total of 648.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "72 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "72 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "72 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "72 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1179, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1219, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "  File \"/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 92, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=l2, random_state=0, solver=saga;, score=0.397 total time= 1.6min\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10000, class_weight=balanced, max_iter=10000, multi_class=multinomial, penalty=elasticnet, random_state=0, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.42843521        nan 0.38286578 0.28018277 0.31909119 0.31681903\n",
      "        nan        nan        nan 0.42843521        nan 0.3409471\n",
      " 0.28018277 0.28018277 0.28051346        nan        nan        nan\n",
      "        nan        nan 0.38286578        nan 0.31909119 0.31681903\n",
      "        nan        nan        nan 0.49051603        nan 0.45896988\n",
      " 0.42768399 0.4912232  0.3347467         nan        nan        nan\n",
      " 0.49051603        nan 0.48213028 0.42768399 0.48871244 0.4199866\n",
      "        nan        nan        nan        nan        nan 0.45896988\n",
      "        nan 0.4912232  0.3347467         nan        nan        nan\n",
      " 0.44836449        nan 0.38615696 0.30754408 0.32906931 0.32973069\n",
      "        nan        nan        nan 0.44836449        nan 0.34700845\n",
      " 0.30754408 0.30754408 0.3037562         nan        nan        nan\n",
      "        nan        nan 0.38615696        nan 0.32906931 0.32973069\n",
      "        nan        nan        nan 0.52738045        nan 0.37001291\n",
      " 0.44077912 0.49922556 0.42919953        nan        nan        nan\n",
      " 0.52738045        nan 0.50496938 0.44077912 0.50123809 0.41322096\n",
      "        nan        nan        nan        nan        nan 0.37001291\n",
      "        nan 0.49922556 0.42919953        nan        nan        nan\n",
      " 0.45063869        nan 0.38776907 0.31606793 0.36925095 0.3571026\n",
      "        nan        nan        nan 0.45063869        nan 0.34598943\n",
      " 0.31606793 0.31606793 0.30882286        nan        nan        nan\n",
      "        nan        nan 0.38776907        nan 0.36925095 0.3571026\n",
      "        nan        nan        nan 0.56916387        nan 0.42412451\n",
      " 0.4423899  0.50092823 0.41353906        nan        nan        nan\n",
      " 0.56916387        nan 0.46372529 0.4423899  0.49645083 0.48878141\n",
      "        nan        nan        nan        nan        nan 0.42412451\n",
      "        nan 0.50092823 0.41353906        nan        nan        nan\n",
      " 0.46661408        nan 0.38776907 0.34134853 0.39136793 0.36891763\n",
      "        nan        nan        nan 0.46661408        nan 0.34598943\n",
      " 0.34134853 0.34134853 0.32053598        nan        nan        nan\n",
      "        nan        nan 0.38776907        nan 0.39136793 0.36891763\n",
      "        nan        nan        nan 0.56706438        nan 0.46384821\n",
      " 0.45816275 0.50211947 0.42509294        nan        nan        nan\n",
      " 0.56706438        nan 0.46996215 0.45816275 0.50598902 0.45280067\n",
      "        nan        nan        nan        nan        nan 0.46384821\n",
      "        nan 0.50211947 0.42509294        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 5000,\n",
       " 'class_weight': 'balanced',\n",
       " 'max_iter': 10000,\n",
       " 'multi_class': 'auto',\n",
       " 'penalty': 'l1',\n",
       " 'random_state': 0,\n",
       " 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'solver': ['liblinear', 'lbfgs', 'saga',],# 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', ],\n",
    "    'class_weight':[None, 'balanced'],\n",
    "    'C': [1000, 2000, 5000, 10000],\n",
    "    'multi_class': ['auto', 'ovr', 'multinomial'],\n",
    "    'max_iter': [10000],\n",
    "    'random_state':[0]\n",
    "}\n",
    "\n",
    "random_state=0\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, descnm = data_preprocessing(data_db)\n",
    "X_train, y_train  = SMOTE(random_state=random_state).fit_resample(X_train, y_train)\n",
    "scaler = preprocessing.Normalizer()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "cv_res, cv_params = grid_search(X_val, y_val, param_grid, \n",
    "                                algorithm='LogisticRegression',)\n",
    "\n",
    "cv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>26.118846</td>\n",
       "      <td>11.990682</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>5000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 5000, 'class_weight': 'balanced', 'max_i...</td>\n",
       "      <td>0.602888</td>\n",
       "      <td>0.526612</td>\n",
       "      <td>0.577991</td>\n",
       "      <td>0.569164</td>\n",
       "      <td>0.031759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>52.003511</td>\n",
       "      <td>27.733853</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>5000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l1</td>\n",
       "      <td>0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 5000, 'class_weight': 'balanced', 'max_i...</td>\n",
       "      <td>0.602888</td>\n",
       "      <td>0.526612</td>\n",
       "      <td>0.577991</td>\n",
       "      <td>0.569164</td>\n",
       "      <td>0.031759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>108.861038</td>\n",
       "      <td>43.256944</td>\n",
       "      <td>0.021987</td>\n",
       "      <td>0.025546</td>\n",
       "      <td>10000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10000, 'class_weight': 'balanced', 'max_...</td>\n",
       "      <td>0.633428</td>\n",
       "      <td>0.510705</td>\n",
       "      <td>0.557060</td>\n",
       "      <td>0.567064</td>\n",
       "      <td>0.050598</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>167.948084</td>\n",
       "      <td>100.605282</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.020604</td>\n",
       "      <td>10000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l1</td>\n",
       "      <td>0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10000, 'class_weight': 'balanced', 'max_...</td>\n",
       "      <td>0.633428</td>\n",
       "      <td>0.510705</td>\n",
       "      <td>0.557060</td>\n",
       "      <td>0.567064</td>\n",
       "      <td>0.050598</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>23.412665</td>\n",
       "      <td>11.527736</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>2000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>l1</td>\n",
       "      <td>0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 2000, 'class_weight': 'balanced', 'max_i...</td>\n",
       "      <td>0.548629</td>\n",
       "      <td>0.494999</td>\n",
       "      <td>0.538513</td>\n",
       "      <td>0.527380</td>\n",
       "      <td>0.023266</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l1</td>\n",
       "      <td>0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10000, 'class_weight': 'balanced', 'max_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.005363</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>l2</td>\n",
       "      <td>0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10000, 'class_weight': 'balanced', 'max_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10000, 'class_weight': 'balanced', 'max_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>0.001188</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10000, 'class_weight': 'balanced', 'max_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>0.001275</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>0</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 10000, 'class_weight': 'balanced', 'max_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "135      26.118846     11.990682         0.001653        0.000080    5000   \n",
       "144      52.003511     27.733853         0.005583        0.003937    5000   \n",
       "189     108.861038     43.256944         0.021987        0.025546   10000   \n",
       "198     167.948084    100.605282         0.028868        0.020604   10000   \n",
       "90       23.412665     11.527736         0.002265        0.000331    2000   \n",
       "..             ...           ...              ...             ...     ...   \n",
       "208       0.003101      0.000367         0.000000        0.000000   10000   \n",
       "210       0.005363      0.002451         0.000000        0.000000   10000   \n",
       "213       0.002067      0.000729         0.000000        0.000000   10000   \n",
       "214       0.001188      0.000372         0.000000        0.000000   10000   \n",
       "215       0.001275      0.000291         0.000000        0.000000   10000   \n",
       "\n",
       "    param_class_weight param_max_iter param_multi_class param_penalty  \\\n",
       "135           balanced          10000              auto            l1   \n",
       "144           balanced          10000               ovr            l1   \n",
       "189           balanced          10000              auto            l1   \n",
       "198           balanced          10000               ovr            l1   \n",
       "90            balanced          10000               ovr            l1   \n",
       "..                 ...            ...               ...           ...   \n",
       "208           balanced          10000       multinomial            l1   \n",
       "210           balanced          10000       multinomial            l2   \n",
       "213           balanced          10000       multinomial    elasticnet   \n",
       "214           balanced          10000       multinomial    elasticnet   \n",
       "215           balanced          10000       multinomial    elasticnet   \n",
       "\n",
       "    param_random_state param_solver  \\\n",
       "135                  0    liblinear   \n",
       "144                  0    liblinear   \n",
       "189                  0    liblinear   \n",
       "198                  0    liblinear   \n",
       "90                   0    liblinear   \n",
       "..                 ...          ...   \n",
       "208                  0        lbfgs   \n",
       "210                  0    liblinear   \n",
       "213                  0    liblinear   \n",
       "214                  0        lbfgs   \n",
       "215                  0         saga   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "135  {'C': 5000, 'class_weight': 'balanced', 'max_i...           0.602888   \n",
       "144  {'C': 5000, 'class_weight': 'balanced', 'max_i...           0.602888   \n",
       "189  {'C': 10000, 'class_weight': 'balanced', 'max_...           0.633428   \n",
       "198  {'C': 10000, 'class_weight': 'balanced', 'max_...           0.633428   \n",
       "90   {'C': 2000, 'class_weight': 'balanced', 'max_i...           0.548629   \n",
       "..                                                 ...                ...   \n",
       "208  {'C': 10000, 'class_weight': 'balanced', 'max_...                NaN   \n",
       "210  {'C': 10000, 'class_weight': 'balanced', 'max_...                NaN   \n",
       "213  {'C': 10000, 'class_weight': 'balanced', 'max_...                NaN   \n",
       "214  {'C': 10000, 'class_weight': 'balanced', 'max_...                NaN   \n",
       "215  {'C': 10000, 'class_weight': 'balanced', 'max_...                NaN   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "135           0.526612           0.577991         0.569164        0.031759   \n",
       "144           0.526612           0.577991         0.569164        0.031759   \n",
       "189           0.510705           0.557060         0.567064        0.050598   \n",
       "198           0.510705           0.557060         0.567064        0.050598   \n",
       "90            0.494999           0.538513         0.527380        0.023266   \n",
       "..                 ...                ...              ...             ...   \n",
       "208                NaN                NaN              NaN             NaN   \n",
       "210                NaN                NaN              NaN             NaN   \n",
       "213                NaN                NaN              NaN             NaN   \n",
       "214                NaN                NaN              NaN             NaN   \n",
       "215                NaN                NaN              NaN             NaN   \n",
       "\n",
       "     rank_test_score  \n",
       "135                1  \n",
       "144                1  \n",
       "189                3  \n",
       "198                3  \n",
       "90                 5  \n",
       "..               ...  \n",
       "208              105  \n",
       "210              105  \n",
       "213              105  \n",
       "214              105  \n",
       "215              105  \n",
       "\n",
       "[216 rows x 18 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_lr_cv_iter_2 = pd.DataFrame(cv_res).sort_values(by='mean_test_score', ascending=False)\n",
    "db_lr_cv_iter_2.to_csv('db_lr_cv_iter_2.csv', index=False)\n",
    "db_lr_cv_iter_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 5000,\n",
       " 'class_weight': 'balanced',\n",
       " 'max_iter': 10000,\n",
       " 'multi_class': 'auto',\n",
       " 'penalty': 'l1',\n",
       " 'random_state': 0,\n",
       " 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_lr_cv_iter_2.params[135]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN scores \n",
      "\n",
      "f1: 0.817\n",
      "balanced accuracy: 0.823\n",
      "matthews corrcoeff: 0.769\n",
      "cf:\n",
      "[[1643  238  367   18]\n",
      " [ 488 1398  272  108]\n",
      " [  16    7 2240    3]\n",
      " [  15   17   57 2177]]\n",
      "-----------\n",
      "VAL scores \n",
      "\n",
      "f1: 0.670\n",
      "balanced accuracy: 0.659\n",
      "matthews corrcoeff: 0.361\n",
      "cf:\n",
      "[[ 53  25  19   0]\n",
      " [171 463  78  43]\n",
      " [  6   3  57   2]\n",
      " [  3   5   4  21]]\n",
      "-----------\n",
      "TEST scores \n",
      "\n",
      "f1: 0.638\n",
      "balanced accuracy: 0.615\n",
      "matthews corrcoeff: 0.321\n",
      "cf:\n",
      "[[ 47  21  27   2]\n",
      " [164 436  98  57]\n",
      " [  7   4  56   1]\n",
      " [  2   8   4  19]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solver='liblinear'\n",
    "max_iter=10000\n",
    "random_state=0\n",
    "C=5000\n",
    "penalty='l1'\n",
    "multi_class = 'auto'\n",
    "class_weight = 'balanced'\n",
    "\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, descnm = data_preprocessing(data_db)\n",
    "X_train, y_train  = SMOTE(random_state=random_state).fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = preprocessing.Normalizer()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# create final model in linreg\n",
    "lr = LogisticRegression(solver=solver,max_iter=max_iter, random_state=random_state, C=C, penalty=penalty, multi_class=multi_class, class_weight=class_weight)\n",
    "fit = lr.fit(X_train, y_train)\n",
    "y_pred = fit.predict(X_train)\n",
    "y_val_pred = fit.predict(X_val)\n",
    "y_test_pred = fit.predict(X_test)\n",
    "\n",
    "# calculate statistical metrics for training set\n",
    "train_f1 = metrics.f1_score(y_train, y_pred, average = 'weighted')\n",
    "train_ba = metrics.balanced_accuracy_score(y_train, y_pred)\n",
    "train_mcc = metrics.matthews_corrcoef(y_train, y_pred)\n",
    "train_cf = metrics.confusion_matrix(y_train, y_pred)\n",
    "\n",
    "# calculate statistical metrics for val set\n",
    "val_f1 = metrics.f1_score(y_val, y_val_pred, average = 'weighted')\n",
    "val_ba = metrics.balanced_accuracy_score(y_val, y_val_pred)\n",
    "val_mcc = metrics.matthews_corrcoef(y_val, y_val_pred)\n",
    "val_cf = metrics.confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# calculate statistical metrics for testing set\n",
    "test_f1 = metrics.f1_score(y_test, y_test_pred, average = 'weighted')\n",
    "test_ba = metrics.balanced_accuracy_score(y_test, y_test_pred)\n",
    "test_mcc = metrics.matthews_corrcoef(y_test, y_test_pred)\n",
    "test_cf = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(f'TRAIN scores \\n')\n",
    "print(f'f1: {train_f1:.3f}')\n",
    "print(f'balanced accuracy: {train_ba:.3f}')\n",
    "print(f'matthews corrcoeff: {train_mcc:.3f}')\n",
    "print(f'cf:\\n{train_cf}')\n",
    "print('-----------')\n",
    "print(f'VAL scores \\n')\n",
    "print(f'f1: {val_f1:.3f}')\n",
    "print(f'balanced accuracy: {val_ba:.3f}')\n",
    "print(f'matthews corrcoeff: {val_mcc:.3f}')\n",
    "print(f'cf:\\n{val_cf}')\n",
    "print('-----------')\n",
    "print(f'TEST scores \\n')\n",
    "print(f'f1: {test_f1:.3f}')\n",
    "print(f'balanced accuracy: {test_ba:.3f}')\n",
    "print(f'matthews corrcoeff: {test_mcc:.3f}')\n",
    "print(f'cf:\\n{test_cf}')\n",
    "print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m fit\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Calculate ROC curve and AUC\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_proba\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mauc(fpr, tpr)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Plot ROC curve\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1095\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    994\u001b[0m     {\n\u001b[1;32m    995\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m ):\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \n\u001b[1;32m   1008\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1095\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/kinase/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:804\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    802\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[0;32m--> 804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m    806\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m    807\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_proba = fit.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, descnm = data_preprocessing(data_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation took 1777.8071229457855 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_rbf = pd.DataFrame(find_model(X_train, y_train, X_val, y_val, algorithm='SVC', kernel='rbf', multiclass=True))\n",
    "model_rbf.to_csv('db_svm_rbf.csv')\n",
    "end_time = time.time()\n",
    "duration_rbf = end_time-start_time\n",
    "print(f\"Operation took {duration_rbf} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>scaling</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_ba</th>\n",
       "      <th>train_mcc</th>\n",
       "      <th>train_cf</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_ba</th>\n",
       "      <th>val_mcc</th>\n",
       "      <th>val_cf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>none</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.077</td>\n",
       "      <td>[[1679, 8, 485, 0, 94], [1477, 18, 580, 0, 191...</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.025</td>\n",
       "      <td>[[49, 0, 20, 0, 3], [453, 3, 223, 0, 76], [16,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.091</td>\n",
       "      <td>[[432, 26, 504, 0, 1304], [230, 35, 578, 2, 14...</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.015</td>\n",
       "      <td>[[12, 1, 19, 1, 39], [73, 4, 221, 2, 455], [9,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.072</td>\n",
       "      <td>[[63, 0, 17, 0, 0], [57, 0, 23, 0, 0], [46, 0,...</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.011</td>\n",
       "      <td>[[52, 0, 20, 0, 0], [532, 0, 223, 0, 0], [16, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.982</td>\n",
       "      <td>[[2239, 9, 18, 0, 0], [73, 2149, 19, 13, 12], ...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.981</td>\n",
       "      <td>[[2240, 0, 26, 0, 0], [78, 2139, 20, 17, 12], ...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.981</td>\n",
       "      <td>[[2234, 19, 13, 0, 0], [85, 2140, 16, 12, 13],...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.979</td>\n",
       "      <td>[[2220, 20, 26, 0, 0], [83, 2142, 16, 11, 14],...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.951</td>\n",
       "      <td>[[2160, 80, 23, 0, 3], [137, 2010, 39, 47, 33]...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.947</td>\n",
       "      <td>[[2143, 96, 22, 0, 5], [139, 1995, 43, 53, 36]...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.945</td>\n",
       "      <td>[[2124, 112, 21, 0, 9], [141, 1994, 39, 45, 47...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.943</td>\n",
       "      <td>[[2124, 112, 21, 0, 9], [143, 1982, 43, 51, 47...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.935</td>\n",
       "      <td>[[2081, 147, 38, 0, 0], [189, 1927, 52, 63, 35...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.932</td>\n",
       "      <td>[[2071, 157, 38, 0, 0], [192, 1912, 57, 65, 40...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.929</td>\n",
       "      <td>[[2073, 160, 33, 0, 0], [189, 1909, 49, 54, 65...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.929</td>\n",
       "      <td>[[2085, 148, 33, 0, 0], [201, 1895, 51, 61, 58...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.879</td>\n",
       "      <td>[[71, 4, 5, 0, 0], [2, 72, 2, 1, 3], [2, 0, 74...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.857</td>\n",
       "      <td>[[69, 5, 4, 1, 1], [5, 69, 3, 1, 2], [3, 0, 73...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.739</td>\n",
       "      <td>[[62, 8, 7, 2, 1], [12, 55, 6, 2, 5], [1, 1, 6...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.723</td>\n",
       "      <td>[[59, 12, 5, 2, 2], [11, 55, 7, 2, 5], [1, 1, ...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.746</td>\n",
       "      <td>[[1749, 10, 507, 0, 0], [51, 1578, 603, 23, 11...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.742</td>\n",
       "      <td>[[1713, 8, 545, 0, 0], [58, 1568, 606, 26, 8],...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.714</td>\n",
       "      <td>[[62, 7, 7, 3, 1], [13, 53, 7, 2, 5], [2, 1, 6...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.704</td>\n",
       "      <td>[[56, 14, 6, 2, 2], [11, 54, 7, 2, 6], [1, 1, ...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.713</td>\n",
       "      <td>[[1662, 75, 519, 2, 8], [139, 1432, 624, 41, 3...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.710</td>\n",
       "      <td>[[1655, 80, 521, 2, 8], [146, 1420, 624, 44, 3...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.697</td>\n",
       "      <td>[[1622, 83, 550, 0, 11], [183, 1368, 632, 49, ...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.691</td>\n",
       "      <td>[[1595, 110, 550, 0, 11], [194, 1344, 637, 51,...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.636</td>\n",
       "      <td>[[56, 3, 20, 1, 0], [3, 47, 25, 1, 4], [4, 0, ...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.710</td>\n",
       "      <td>[[91, 119, 2, 2, 0], [3, 2250, 1, 10, 2], [2, ...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.528</td>\n",
       "      <td>[[51, 4, 20, 2, 3], [6, 39, 27, 1, 7], [9, 0, ...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.524</td>\n",
       "      <td>[[51, 4, 20, 2, 3], [6, 39, 27, 1, 7], [10, 0,...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.690</td>\n",
       "      <td>[[82, 127, 2, 3, 0], [2, 2251, 1, 10, 2], [1, ...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.363</td>\n",
       "      <td>[[869, 186, 988, 78, 145], [349, 514, 998, 90,...</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[72, 0, 0, 0, 0], [755, 0, 0, 0, 0], [26, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.327</td>\n",
       "      <td>[[778, 226, 955, 114, 193], [364, 542, 961, 80...</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[72, 0, 0, 0, 0], [755, 0, 0, 0, 0], [26, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[[41, 172, 0, 1, 0], [3, 2259, 0, 2, 2], [1, 7...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.498</td>\n",
       "      <td>[[19, 190, 0, 5, 0], [1, 2253, 0, 12, 0], [0, ...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.480</td>\n",
       "      <td>[[14, 197, 0, 3, 0], [0, 2254, 0, 12, 0], [0, ...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.438</td>\n",
       "      <td>[[3, 206, 0, 5, 0], [0, 2253, 0, 13, 0], [0, 7...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.433</td>\n",
       "      <td>[[3, 208, 0, 3, 0], [0, 2252, 0, 14, 0], [0, 7...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.124</td>\n",
       "      <td>[[49, 2, 26, 2, 1], [40, 8, 27, 0, 5], [37, 0,...</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 72, 0, 0], [0, 0, 755, 0, 0], [0, 0, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.265</td>\n",
       "      <td>[[2, 212, 0, 0, 0], [0, 2264, 0, 2, 0], [0, 77...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.233</td>\n",
       "      <td>[[0, 214, 0, 0, 0], [0, 2265, 0, 1, 0], [0, 77...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>none</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 214, 0, 0, 0], [0, 2266, 0, 0, 0], [0, 80...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 214, 0, 0, 0], [0, 2266, 0, 0, 0], [0, 80...</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sampling                      scaling  train_accuracy  train_f1  \\\n",
       "0                SMOTE                         none           0.247     0.160   \n",
       "22   RandomOverSampler                         none           0.263     0.191   \n",
       "11  RandomUnderSampler                         none           0.242     0.137   \n",
       "3                SMOTE               StandardScaler           0.985     0.985   \n",
       "25   RandomOverSampler               StandardScaler           0.985     0.985   \n",
       "10               SMOTE  StandardScaler + Normalizer           0.984     0.984   \n",
       "32   RandomOverSampler  StandardScaler + Normalizer           0.983     0.983   \n",
       "8                SMOTE    MaxAbsScaler + Normalizer           0.961     0.960   \n",
       "9                SMOTE    MinMaxScaler + Normalizer           0.957     0.957   \n",
       "1                SMOTE                 MaxAbsScaler           0.956     0.955   \n",
       "2                SMOTE                 MinMaxScaler           0.954     0.954   \n",
       "30   RandomOverSampler    MaxAbsScaler + Normalizer           0.948     0.947   \n",
       "31   RandomOverSampler    MinMaxScaler + Normalizer           0.945     0.944   \n",
       "23   RandomOverSampler                 MaxAbsScaler           0.943     0.942   \n",
       "24   RandomOverSampler                 MinMaxScaler           0.943     0.942   \n",
       "21  RandomUnderSampler  StandardScaler + Normalizer           0.902     0.903   \n",
       "14  RandomUnderSampler               StandardScaler           0.885     0.885   \n",
       "20  RandomUnderSampler    MinMaxScaler + Normalizer           0.790     0.789   \n",
       "13  RandomUnderSampler                 MinMaxScaler           0.778     0.777   \n",
       "7                SMOTE  Normalizer + StandardScaler           0.774     0.793   \n",
       "29   RandomOverSampler  Normalizer + StandardScaler           0.770     0.789   \n",
       "19  RandomUnderSampler    MaxAbsScaler + Normalizer           0.770     0.770   \n",
       "12  RandomUnderSampler                 MaxAbsScaler           0.762     0.762   \n",
       "5                SMOTE    Normalizer + MaxAbsScaler           0.749     0.764   \n",
       "6                SMOTE    Normalizer + MinMaxScaler           0.747     0.762   \n",
       "27   RandomOverSampler    Normalizer + MaxAbsScaler           0.735     0.749   \n",
       "28   RandomOverSampler    Normalizer + MinMaxScaler           0.731     0.744   \n",
       "18  RandomUnderSampler  Normalizer + StandardScaler           0.688     0.704   \n",
       "43         no_sampling  StandardScaler + Normalizer           0.905     0.890   \n",
       "16  RandomUnderSampler    Normalizer + MaxAbsScaler           0.605     0.615   \n",
       "17  RandomUnderSampler    Normalizer + MinMaxScaler           0.602     0.613   \n",
       "36         no_sampling               StandardScaler           0.899     0.883   \n",
       "4                SMOTE                   Normalizer           0.468     0.454   \n",
       "26   RandomOverSampler                   Normalizer           0.443     0.429   \n",
       "40         no_sampling  Normalizer + StandardScaler           0.846     0.806   \n",
       "34         no_sampling                 MaxAbsScaler           0.850     0.804   \n",
       "35         no_sampling                 MinMaxScaler           0.846     0.795   \n",
       "41         no_sampling    MaxAbsScaler + Normalizer           0.837     0.780   \n",
       "42         no_sampling    MinMaxScaler + Normalizer           0.836     0.778   \n",
       "15  RandomUnderSampler                   Normalizer           0.285     0.232   \n",
       "38         no_sampling    Normalizer + MaxAbsScaler           0.809     0.736   \n",
       "39         no_sampling    Normalizer + MinMaxScaler           0.805     0.728   \n",
       "33         no_sampling                         none           0.792     0.700   \n",
       "37         no_sampling                   Normalizer           0.792     0.700   \n",
       "\n",
       "    train_ba  train_mcc                                           train_cf  \\\n",
       "0      0.247      0.077  [[1679, 8, 485, 0, 94], [1477, 18, 580, 0, 191...   \n",
       "22     0.263      0.091  [[432, 26, 504, 0, 1304], [230, 35, 578, 2, 14...   \n",
       "11     0.242      0.072  [[63, 0, 17, 0, 0], [57, 0, 23, 0, 0], [46, 0,...   \n",
       "3      0.985      0.982  [[2239, 9, 18, 0, 0], [73, 2149, 19, 13, 12], ...   \n",
       "25     0.985      0.981  [[2240, 0, 26, 0, 0], [78, 2139, 20, 17, 12], ...   \n",
       "10     0.984      0.981  [[2234, 19, 13, 0, 0], [85, 2140, 16, 12, 13],...   \n",
       "32     0.983      0.979  [[2220, 20, 26, 0, 0], [83, 2142, 16, 11, 14],...   \n",
       "8      0.961      0.951  [[2160, 80, 23, 0, 3], [137, 2010, 39, 47, 33]...   \n",
       "9      0.957      0.947  [[2143, 96, 22, 0, 5], [139, 1995, 43, 53, 36]...   \n",
       "1      0.956      0.945  [[2124, 112, 21, 0, 9], [141, 1994, 39, 45, 47...   \n",
       "2      0.954      0.943  [[2124, 112, 21, 0, 9], [143, 1982, 43, 51, 47...   \n",
       "30     0.948      0.935  [[2081, 147, 38, 0, 0], [189, 1927, 52, 63, 35...   \n",
       "31     0.945      0.932  [[2071, 157, 38, 0, 0], [192, 1912, 57, 65, 40...   \n",
       "23     0.943      0.929  [[2073, 160, 33, 0, 0], [189, 1909, 49, 54, 65...   \n",
       "24     0.943      0.929  [[2085, 148, 33, 0, 0], [201, 1895, 51, 61, 58...   \n",
       "21     0.903      0.879  [[71, 4, 5, 0, 0], [2, 72, 2, 1, 3], [2, 0, 74...   \n",
       "14     0.885      0.857  [[69, 5, 4, 1, 1], [5, 69, 3, 1, 2], [3, 0, 73...   \n",
       "20     0.790      0.739  [[62, 8, 7, 2, 1], [12, 55, 6, 2, 5], [1, 1, 6...   \n",
       "13     0.778      0.723  [[59, 12, 5, 2, 2], [11, 55, 7, 2, 5], [1, 1, ...   \n",
       "7      0.774      0.746  [[1749, 10, 507, 0, 0], [51, 1578, 603, 23, 11...   \n",
       "29     0.770      0.742  [[1713, 8, 545, 0, 0], [58, 1568, 606, 26, 8],...   \n",
       "19     0.770      0.714  [[62, 7, 7, 3, 1], [13, 53, 7, 2, 5], [2, 1, 6...   \n",
       "12     0.763      0.704  [[56, 14, 6, 2, 2], [11, 54, 7, 2, 6], [1, 1, ...   \n",
       "5      0.749      0.713  [[1662, 75, 519, 2, 8], [139, 1432, 624, 41, 3...   \n",
       "6      0.747      0.710  [[1655, 80, 521, 2, 8], [146, 1420, 624, 44, 3...   \n",
       "27     0.735      0.697  [[1622, 83, 550, 0, 11], [183, 1368, 632, 49, ...   \n",
       "28     0.731      0.691  [[1595, 110, 550, 0, 11], [194, 1344, 637, 51,...   \n",
       "18     0.688      0.636  [[56, 3, 20, 1, 0], [3, 47, 25, 1, 4], [4, 0, ...   \n",
       "43     0.617      0.710  [[91, 119, 2, 2, 0], [3, 2250, 1, 10, 2], [2, ...   \n",
       "16     0.605      0.528  [[51, 4, 20, 2, 3], [6, 39, 27, 1, 7], [9, 0, ...   \n",
       "17     0.602      0.524  [[51, 4, 20, 2, 3], [6, 39, 27, 1, 7], [10, 0,...   \n",
       "36     0.600      0.690  [[82, 127, 2, 3, 0], [2, 2251, 1, 10, 2], [1, ...   \n",
       "4      0.468      0.363  [[869, 186, 988, 78, 145], [349, 514, 998, 90,...   \n",
       "26     0.443      0.327  [[778, 226, 955, 114, 193], [364, 542, 961, 80...   \n",
       "40     0.404      0.479  [[41, 172, 0, 1, 0], [3, 2259, 0, 2, 2], [1, 7...   \n",
       "34     0.398      0.498  [[19, 190, 0, 5, 0], [1, 2253, 0, 12, 0], [0, ...   \n",
       "35     0.378      0.480  [[14, 197, 0, 3, 0], [0, 2254, 0, 12, 0], [0, ...   \n",
       "41     0.350      0.438  [[3, 206, 0, 5, 0], [0, 2253, 0, 13, 0], [0, 7...   \n",
       "42     0.347      0.433  [[3, 208, 0, 3, 0], [0, 2252, 0, 14, 0], [0, 7...   \n",
       "15     0.285      0.124  [[49, 2, 26, 2, 1], [40, 8, 27, 0, 5], [37, 0,...   \n",
       "38     0.250      0.265  [[2, 212, 0, 0, 0], [0, 2264, 0, 2, 0], [0, 77...   \n",
       "39     0.238      0.233  [[0, 214, 0, 0, 0], [0, 2265, 0, 1, 0], [0, 77...   \n",
       "33     0.200      0.000  [[0, 214, 0, 0, 0], [0, 2266, 0, 0, 0], [0, 80...   \n",
       "37     0.200      0.000  [[0, 214, 0, 0, 0], [0, 2266, 0, 0, 0], [0, 80...   \n",
       "\n",
       "    val_accuracy  val_f1  val_ba  val_mcc  \\\n",
       "0          0.070   0.022   0.244    0.025   \n",
       "22         0.048   0.022   0.233    0.015   \n",
       "11         0.065   0.012   0.221    0.011   \n",
       "3          0.791   0.699   0.200    0.000   \n",
       "25         0.791   0.699   0.200    0.000   \n",
       "10         0.791   0.699   0.200    0.000   \n",
       "32         0.791   0.699   0.200    0.000   \n",
       "8          0.791   0.699   0.200    0.000   \n",
       "9          0.791   0.699   0.200    0.000   \n",
       "1          0.791   0.699   0.200    0.000   \n",
       "2          0.791   0.699   0.200    0.000   \n",
       "30         0.791   0.699   0.200    0.000   \n",
       "31         0.791   0.699   0.200    0.000   \n",
       "23         0.791   0.699   0.200    0.000   \n",
       "24         0.791   0.699   0.200    0.000   \n",
       "21         0.791   0.699   0.200    0.000   \n",
       "14         0.791   0.699   0.200    0.000   \n",
       "20         0.791   0.699   0.200    0.000   \n",
       "13         0.791   0.699   0.200    0.000   \n",
       "7          0.791   0.699   0.200    0.000   \n",
       "29         0.791   0.699   0.200    0.000   \n",
       "19         0.791   0.699   0.200    0.000   \n",
       "12         0.791   0.699   0.200    0.000   \n",
       "5          0.791   0.699   0.200    0.000   \n",
       "6          0.791   0.699   0.200    0.000   \n",
       "27         0.791   0.699   0.200    0.000   \n",
       "28         0.791   0.699   0.200    0.000   \n",
       "18         0.791   0.699   0.200    0.000   \n",
       "43         0.791   0.699   0.200    0.000   \n",
       "16         0.791   0.699   0.200    0.000   \n",
       "17         0.791   0.699   0.200    0.000   \n",
       "36         0.791   0.699   0.200    0.000   \n",
       "4          0.075   0.011   0.200    0.000   \n",
       "26         0.075   0.011   0.200    0.000   \n",
       "40         0.791   0.699   0.200    0.000   \n",
       "34         0.791   0.699   0.200    0.000   \n",
       "35         0.791   0.699   0.200    0.000   \n",
       "41         0.791   0.699   0.200    0.000   \n",
       "42         0.791   0.699   0.200    0.000   \n",
       "15         0.027   0.001   0.200    0.000   \n",
       "38         0.791   0.699   0.200    0.000   \n",
       "39         0.791   0.699   0.200    0.000   \n",
       "33         0.791   0.699   0.200    0.000   \n",
       "37         0.791   0.699   0.200    0.000   \n",
       "\n",
       "                                               val_cf  \n",
       "0   [[49, 0, 20, 0, 3], [453, 3, 223, 0, 76], [16,...  \n",
       "22  [[12, 1, 19, 1, 39], [73, 4, 221, 2, 455], [9,...  \n",
       "11  [[52, 0, 20, 0, 0], [532, 0, 223, 0, 0], [16, ...  \n",
       "3   [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "25  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "10  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "32  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "8   [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "9   [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "1   [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "2   [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "30  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "31  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "23  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "24  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "21  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "14  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "20  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "13  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "7   [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "29  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "19  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "12  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "5   [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "6   [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "27  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "28  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "18  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "43  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "16  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "17  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "36  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "4   [[72, 0, 0, 0, 0], [755, 0, 0, 0, 0], [26, 0, ...  \n",
       "26  [[72, 0, 0, 0, 0], [755, 0, 0, 0, 0], [26, 0, ...  \n",
       "40  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "34  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "35  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "41  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "42  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "15  [[0, 0, 72, 0, 0], [0, 0, 755, 0, 0], [0, 0, 2...  \n",
       "38  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "39  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "33  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  \n",
       "37  [[0, 72, 0, 0, 0], [0, 755, 0, 0, 0], [0, 26, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>scaling</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_ba</th>\n",
       "      <th>train_mcc</th>\n",
       "      <th>train_cf</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_ba</th>\n",
       "      <th>val_mcc</th>\n",
       "      <th>val_cf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>none</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.362</td>\n",
       "      <td>[[1027, 181, 852, 206], [625, 583, 783, 275], ...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.176</td>\n",
       "      <td>[[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.362</td>\n",
       "      <td>[[1027, 181, 852, 206], [625, 583, 783, 275], ...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.176</td>\n",
       "      <td>[[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.362</td>\n",
       "      <td>[[1027, 181, 852, 206], [625, 583, 783, 275], ...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.176</td>\n",
       "      <td>[[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.362</td>\n",
       "      <td>[[1027, 181, 852, 206], [625, 583, 783, 275], ...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.176</td>\n",
       "      <td>[[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.362</td>\n",
       "      <td>[[1027, 181, 852, 206], [625, 583, 783, 275], ...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.176</td>\n",
       "      <td>[[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.362</td>\n",
       "      <td>[[1027, 181, 852, 206], [625, 583, 783, 275], ...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.176</td>\n",
       "      <td>[[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>none</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.362</td>\n",
       "      <td>[[1027, 181, 852, 206], [625, 583, 783, 275], ...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.176</td>\n",
       "      <td>[[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.362</td>\n",
       "      <td>[[1027, 181, 852, 206], [625, 583, 783, 275], ...</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.176</td>\n",
       "      <td>[[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.676</td>\n",
       "      <td>[[1447, 104, 711, 4], [172, 1365, 692, 37], [1...</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.065</td>\n",
       "      <td>[[0, 66, 31, 0], [0, 545, 210, 0], [0, 38, 30,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.676</td>\n",
       "      <td>[[1447, 104, 711, 4], [172, 1365, 692, 37], [1...</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.065</td>\n",
       "      <td>[[0, 66, 31, 0], [0, 545, 210, 0], [0, 38, 30,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.676</td>\n",
       "      <td>[[1447, 104, 711, 4], [172, 1365, 692, 37], [1...</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.055</td>\n",
       "      <td>[[0, 66, 31, 0], [0, 532, 223, 0], [0, 38, 30,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.676</td>\n",
       "      <td>[[1447, 104, 711, 4], [172, 1365, 692, 37], [1...</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.055</td>\n",
       "      <td>[[0, 66, 31, 0], [0, 532, 223, 0], [0, 38, 30,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.676</td>\n",
       "      <td>[[1447, 104, 711, 4], [172, 1365, 692, 37], [1...</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.055</td>\n",
       "      <td>[[0, 66, 31, 0], [0, 532, 223, 0], [0, 38, 30,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.676</td>\n",
       "      <td>[[1447, 104, 711, 4], [172, 1365, 692, 37], [1...</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.055</td>\n",
       "      <td>[[0, 66, 31, 0], [0, 532, 223, 0], [0, 38, 30,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.676</td>\n",
       "      <td>[[1447, 104, 711, 4], [172, 1365, 692, 37], [1...</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.055</td>\n",
       "      <td>[[0, 66, 31, 0], [0, 532, 223, 0], [0, 38, 30,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MinMaxScaler</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.676</td>\n",
       "      <td>[[1447, 104, 711, 4], [172, 1365, 692, 37], [1...</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.055</td>\n",
       "      <td>[[0, 66, 31, 0], [0, 532, 223, 0], [0, 38, 30,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.722</td>\n",
       "      <td>[[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.722</td>\n",
       "      <td>[[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.722</td>\n",
       "      <td>[[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.722</td>\n",
       "      <td>[[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.722</td>\n",
       "      <td>[[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.722</td>\n",
       "      <td>[[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.722</td>\n",
       "      <td>[[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + StandardScaler</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.722</td>\n",
       "      <td>[[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.679</td>\n",
       "      <td>[[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.679</td>\n",
       "      <td>[[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.679</td>\n",
       "      <td>[[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.679</td>\n",
       "      <td>[[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.679</td>\n",
       "      <td>[[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.679</td>\n",
       "      <td>[[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.679</td>\n",
       "      <td>[[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>Normalizer + MaxAbsScaler</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.679</td>\n",
       "      <td>[[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.657</td>\n",
       "      <td>[[1428, 116, 712, 10], [214, 1300, 690, 62], [...</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 97, 0, 0], [0, 755, 0, 0], [0, 68, 0, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.657</td>\n",
       "      <td>[[1428, 116, 712, 10], [214, 1300, 690, 62], [...</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 97, 0, 0], [0, 755, 0, 0], [0, 68, 0, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.657</td>\n",
       "      <td>[[1428, 116, 712, 10], [214, 1300, 690, 62], [...</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 97, 0, 0], [0, 755, 0, 0], [0, 68, 0, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MinMaxScaler + Normalizer</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.657</td>\n",
       "      <td>[[1428, 116, 712, 10], [214, 1300, 690, 62], [...</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[[0, 97, 0, 0], [0, 755, 0, 0], [0, 68, 0, 0],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.786</td>\n",
       "      <td>[[1584, 237, 427, 18], [243, 1670, 252, 101], ...</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.009</td>\n",
       "      <td>[[1, 66, 2, 28], [17, 538, 23, 177], [0, 45, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.786</td>\n",
       "      <td>[[1584, 237, 427, 18], [243, 1670, 252, 101], ...</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.009</td>\n",
       "      <td>[[1, 66, 2, 28], [17, 538, 23, 177], [0, 45, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.786</td>\n",
       "      <td>[[1584, 237, 427, 18], [243, 1670, 252, 101], ...</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.009</td>\n",
       "      <td>[[1, 66, 2, 28], [17, 538, 23, 177], [0, 45, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>MaxAbsScaler + Normalizer</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.786</td>\n",
       "      <td>[[1584, 237, 427, 18], [243, 1670, 252, 101], ...</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.009</td>\n",
       "      <td>[[1, 66, 2, 28], [17, 538, 23, 177], [0, 45, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.727</td>\n",
       "      <td>[[1584, 12, 670, 0], [85, 1517, 653, 11], [0, ...</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>[[7, 90, 0, 0], [123, 632, 0, 0], [8, 60, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.727</td>\n",
       "      <td>[[1584, 12, 670, 0], [85, 1517, 653, 11], [0, ...</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>[[7, 90, 0, 0], [123, 632, 0, 0], [8, 60, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.727</td>\n",
       "      <td>[[1584, 12, 670, 0], [85, 1517, 653, 11], [0, ...</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>[[7, 90, 0, 0], [123, 632, 0, 0], [8, 60, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>StandardScaler + Normalizer</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.727</td>\n",
       "      <td>[[1584, 12, 670, 0], [85, 1517, 653, 11], [0, ...</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.227</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>[[7, 90, 0, 0], [123, 632, 0, 0], [8, 60, 0, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sampling                      scaling  train_accuracy  train_f1  \\\n",
       "0                SMOTE                         none           0.511     0.499   \n",
       "4                SMOTE                   Normalizer           0.511     0.499   \n",
       "11  RandomUnderSampler                         none           0.511     0.499   \n",
       "15  RandomUnderSampler                   Normalizer           0.511     0.499   \n",
       "22   RandomOverSampler                         none           0.511     0.499   \n",
       "26   RandomOverSampler                   Normalizer           0.511     0.499   \n",
       "33         no_sampling                         none           0.511     0.499   \n",
       "37         no_sampling                   Normalizer           0.511     0.499   \n",
       "13  RandomUnderSampler                 MinMaxScaler           0.733     0.742   \n",
       "17  RandomUnderSampler    Normalizer + MinMaxScaler           0.733     0.742   \n",
       "2                SMOTE                 MinMaxScaler           0.733     0.742   \n",
       "6                SMOTE    Normalizer + MinMaxScaler           0.733     0.742   \n",
       "24   RandomOverSampler                 MinMaxScaler           0.733     0.742   \n",
       "28   RandomOverSampler    Normalizer + MinMaxScaler           0.733     0.742   \n",
       "35         no_sampling                 MinMaxScaler           0.733     0.742   \n",
       "39         no_sampling    Normalizer + MinMaxScaler           0.733     0.742   \n",
       "3                SMOTE               StandardScaler           0.768     0.780   \n",
       "7                SMOTE  Normalizer + StandardScaler           0.768     0.780   \n",
       "14  RandomUnderSampler               StandardScaler           0.768     0.780   \n",
       "18  RandomUnderSampler  Normalizer + StandardScaler           0.768     0.780   \n",
       "25   RandomOverSampler               StandardScaler           0.768     0.780   \n",
       "29   RandomOverSampler  Normalizer + StandardScaler           0.768     0.780   \n",
       "36         no_sampling               StandardScaler           0.768     0.780   \n",
       "40         no_sampling  Normalizer + StandardScaler           0.768     0.780   \n",
       "1                SMOTE                 MaxAbsScaler           0.735     0.744   \n",
       "5                SMOTE    Normalizer + MaxAbsScaler           0.735     0.744   \n",
       "12  RandomUnderSampler                 MaxAbsScaler           0.735     0.744   \n",
       "16  RandomUnderSampler    Normalizer + MaxAbsScaler           0.735     0.744   \n",
       "23   RandomOverSampler                 MaxAbsScaler           0.735     0.744   \n",
       "27   RandomOverSampler    Normalizer + MaxAbsScaler           0.735     0.744   \n",
       "34         no_sampling                 MaxAbsScaler           0.735     0.744   \n",
       "38         no_sampling    Normalizer + MaxAbsScaler           0.735     0.744   \n",
       "9                SMOTE    MinMaxScaler + Normalizer           0.721     0.728   \n",
       "20  RandomUnderSampler    MinMaxScaler + Normalizer           0.721     0.728   \n",
       "31   RandomOverSampler    MinMaxScaler + Normalizer           0.721     0.728   \n",
       "42         no_sampling    MinMaxScaler + Normalizer           0.721     0.728   \n",
       "8                SMOTE    MaxAbsScaler + Normalizer           0.836     0.834   \n",
       "19  RandomUnderSampler    MaxAbsScaler + Normalizer           0.836     0.834   \n",
       "30   RandomOverSampler    MaxAbsScaler + Normalizer           0.836     0.834   \n",
       "41         no_sampling    MaxAbsScaler + Normalizer           0.836     0.834   \n",
       "10               SMOTE  StandardScaler + Normalizer           0.772     0.784   \n",
       "21  RandomUnderSampler  StandardScaler + Normalizer           0.772     0.784   \n",
       "32   RandomOverSampler  StandardScaler + Normalizer           0.772     0.784   \n",
       "43         no_sampling  StandardScaler + Normalizer           0.772     0.784   \n",
       "\n",
       "    train_ba  train_mcc                                           train_cf  \\\n",
       "0      0.511      0.362  [[1027, 181, 852, 206], [625, 583, 783, 275], ...   \n",
       "4      0.511      0.362  [[1027, 181, 852, 206], [625, 583, 783, 275], ...   \n",
       "11     0.511      0.362  [[1027, 181, 852, 206], [625, 583, 783, 275], ...   \n",
       "15     0.511      0.362  [[1027, 181, 852, 206], [625, 583, 783, 275], ...   \n",
       "22     0.511      0.362  [[1027, 181, 852, 206], [625, 583, 783, 275], ...   \n",
       "26     0.511      0.362  [[1027, 181, 852, 206], [625, 583, 783, 275], ...   \n",
       "33     0.511      0.362  [[1027, 181, 852, 206], [625, 583, 783, 275], ...   \n",
       "37     0.511      0.362  [[1027, 181, 852, 206], [625, 583, 783, 275], ...   \n",
       "13     0.733      0.676  [[1447, 104, 711, 4], [172, 1365, 692, 37], [1...   \n",
       "17     0.733      0.676  [[1447, 104, 711, 4], [172, 1365, 692, 37], [1...   \n",
       "2      0.733      0.676  [[1447, 104, 711, 4], [172, 1365, 692, 37], [1...   \n",
       "6      0.733      0.676  [[1447, 104, 711, 4], [172, 1365, 692, 37], [1...   \n",
       "24     0.733      0.676  [[1447, 104, 711, 4], [172, 1365, 692, 37], [1...   \n",
       "28     0.733      0.676  [[1447, 104, 711, 4], [172, 1365, 692, 37], [1...   \n",
       "35     0.733      0.676  [[1447, 104, 711, 4], [172, 1365, 692, 37], [1...   \n",
       "39     0.733      0.676  [[1447, 104, 711, 4], [172, 1365, 692, 37], [1...   \n",
       "3      0.768      0.722  [[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...   \n",
       "7      0.768      0.722  [[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...   \n",
       "14     0.768      0.722  [[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...   \n",
       "18     0.768      0.722  [[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...   \n",
       "25     0.768      0.722  [[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...   \n",
       "29     0.768      0.722  [[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...   \n",
       "36     0.768      0.722  [[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...   \n",
       "40     0.768      0.722  [[1564, 24, 678, 0], [85, 1506, 664, 11], [3, ...   \n",
       "1      0.735      0.679  [[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...   \n",
       "5      0.735      0.679  [[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...   \n",
       "12     0.735      0.679  [[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...   \n",
       "16     0.735      0.679  [[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...   \n",
       "23     0.735      0.679  [[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...   \n",
       "27     0.735      0.679  [[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...   \n",
       "34     0.735      0.679  [[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...   \n",
       "38     0.735      0.679  [[1456, 99, 707, 4], [165, 1374, 691, 36], [8,...   \n",
       "9      0.721      0.657  [[1428, 116, 712, 10], [214, 1300, 690, 62], [...   \n",
       "20     0.721      0.657  [[1428, 116, 712, 10], [214, 1300, 690, 62], [...   \n",
       "31     0.721      0.657  [[1428, 116, 712, 10], [214, 1300, 690, 62], [...   \n",
       "42     0.721      0.657  [[1428, 116, 712, 10], [214, 1300, 690, 62], [...   \n",
       "8      0.836      0.786  [[1584, 237, 427, 18], [243, 1670, 252, 101], ...   \n",
       "19     0.836      0.786  [[1584, 237, 427, 18], [243, 1670, 252, 101], ...   \n",
       "30     0.836      0.786  [[1584, 237, 427, 18], [243, 1670, 252, 101], ...   \n",
       "41     0.836      0.786  [[1584, 237, 427, 18], [243, 1670, 252, 101], ...   \n",
       "10     0.772      0.727  [[1584, 12, 670, 0], [85, 1517, 653, 11], [0, ...   \n",
       "21     0.772      0.727  [[1584, 12, 670, 0], [85, 1517, 653, 11], [0, ...   \n",
       "32     0.772      0.727  [[1584, 12, 670, 0], [85, 1517, 653, 11], [0, ...   \n",
       "43     0.772      0.727  [[1584, 12, 670, 0], [85, 1517, 653, 11], [0, ...   \n",
       "\n",
       "    val_accuracy  val_f1  val_ba  val_mcc  \\\n",
       "0          0.328   0.382   0.464    0.176   \n",
       "4          0.328   0.382   0.464    0.176   \n",
       "11         0.328   0.382   0.464    0.176   \n",
       "15         0.328   0.382   0.464    0.176   \n",
       "22         0.328   0.382   0.464    0.176   \n",
       "26         0.328   0.382   0.464    0.176   \n",
       "33         0.328   0.382   0.464    0.176   \n",
       "37         0.328   0.382   0.464    0.176   \n",
       "13         0.603   0.618   0.291    0.065   \n",
       "17         0.603   0.618   0.291    0.065   \n",
       "2          0.590   0.609   0.286    0.055   \n",
       "6          0.590   0.609   0.286    0.055   \n",
       "24         0.590   0.609   0.286    0.055   \n",
       "28         0.590   0.609   0.286    0.055   \n",
       "35         0.590   0.609   0.286    0.055   \n",
       "39         0.590   0.609   0.286    0.055   \n",
       "3          0.102   0.019   0.250    0.000   \n",
       "7          0.102   0.019   0.250    0.000   \n",
       "14         0.102   0.019   0.250    0.000   \n",
       "18         0.102   0.019   0.250    0.000   \n",
       "25         0.102   0.019   0.250    0.000   \n",
       "29         0.102   0.019   0.250    0.000   \n",
       "36         0.102   0.019   0.250    0.000   \n",
       "40         0.102   0.019   0.250    0.000   \n",
       "1          0.071   0.010   0.250    0.000   \n",
       "5          0.071   0.010   0.250    0.000   \n",
       "12         0.071   0.010   0.250    0.000   \n",
       "16         0.071   0.010   0.250    0.000   \n",
       "23         0.071   0.010   0.250    0.000   \n",
       "27         0.071   0.010   0.250    0.000   \n",
       "34         0.071   0.010   0.250    0.000   \n",
       "38         0.071   0.010   0.250    0.000   \n",
       "9          0.792   0.700   0.250    0.000   \n",
       "20         0.792   0.700   0.250    0.000   \n",
       "31         0.792   0.700   0.250    0.000   \n",
       "42         0.792   0.700   0.250    0.000   \n",
       "8          0.574   0.602   0.241    0.009   \n",
       "19         0.574   0.602   0.241    0.009   \n",
       "30         0.574   0.602   0.241    0.009   \n",
       "41         0.574   0.602   0.241    0.009   \n",
       "10         0.671   0.645   0.227   -0.068   \n",
       "21         0.671   0.645   0.227   -0.068   \n",
       "32         0.671   0.645   0.227   -0.068   \n",
       "43         0.671   0.645   0.227   -0.068   \n",
       "\n",
       "                                               val_cf  \n",
       "0   [[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...  \n",
       "4   [[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...  \n",
       "11  [[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...  \n",
       "15  [[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...  \n",
       "22  [[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...  \n",
       "26  [[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...  \n",
       "33  [[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...  \n",
       "37  [[50, 6, 34, 7], [225, 204, 221, 105], [11, 3,...  \n",
       "13  [[0, 66, 31, 0], [0, 545, 210, 0], [0, 38, 30,...  \n",
       "17  [[0, 66, 31, 0], [0, 545, 210, 0], [0, 38, 30,...  \n",
       "2   [[0, 66, 31, 0], [0, 532, 223, 0], [0, 38, 30,...  \n",
       "6   [[0, 66, 31, 0], [0, 532, 223, 0], [0, 38, 30,...  \n",
       "24  [[0, 66, 31, 0], [0, 532, 223, 0], [0, 38, 30,...  \n",
       "28  [[0, 66, 31, 0], [0, 532, 223, 0], [0, 38, 30,...  \n",
       "35  [[0, 66, 31, 0], [0, 532, 223, 0], [0, 38, 30,...  \n",
       "39  [[0, 66, 31, 0], [0, 532, 223, 0], [0, 38, 30,...  \n",
       "3   [[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...  \n",
       "7   [[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...  \n",
       "14  [[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...  \n",
       "18  [[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...  \n",
       "25  [[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...  \n",
       "29  [[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...  \n",
       "36  [[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...  \n",
       "40  [[97, 0, 0, 0], [755, 0, 0, 0], [68, 0, 0, 0],...  \n",
       "1   [[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...  \n",
       "5   [[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...  \n",
       "12  [[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...  \n",
       "16  [[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...  \n",
       "23  [[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...  \n",
       "27  [[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...  \n",
       "34  [[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...  \n",
       "38  [[0, 0, 97, 0], [0, 0, 755, 0], [0, 0, 68, 0],...  \n",
       "9   [[0, 97, 0, 0], [0, 755, 0, 0], [0, 68, 0, 0],...  \n",
       "20  [[0, 97, 0, 0], [0, 755, 0, 0], [0, 68, 0, 0],...  \n",
       "31  [[0, 97, 0, 0], [0, 755, 0, 0], [0, 68, 0, 0],...  \n",
       "42  [[0, 97, 0, 0], [0, 755, 0, 0], [0, 68, 0, 0],...  \n",
       "8   [[1, 66, 2, 28], [17, 538, 23, 177], [0, 45, 0...  \n",
       "19  [[1, 66, 2, 28], [17, 538, 23, 177], [0, 45, 0...  \n",
       "30  [[1, 66, 2, 28], [17, 538, 23, 177], [0, 45, 0...  \n",
       "41  [[1, 66, 2, 28], [17, 538, 23, 177], [0, 45, 0...  \n",
       "10  [[7, 90, 0, 0], [123, 632, 0, 0], [8, 60, 0, 0...  \n",
       "21  [[7, 90, 0, 0], [123, 632, 0, 0], [8, 60, 0, 0...  \n",
       "32  [[7, 90, 0, 0], [123, 632, 0, 0], [8, 60, 0, 0...  \n",
       "43  [[7, 90, 0, 0], [123, 632, 0, 0], [8, 60, 0, 0...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter tuninr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 448 candidates, totalling 1344 fits\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   1.4s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   1.6s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   1.4s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.457 total time=   0.9s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   0.7s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.503 total time=   0.7s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.8s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.8s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.7s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.4s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.319 total time=   1.9s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   0.8s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   0.7s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   0.8s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.478 total time=   0.6s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.455 total time=   0.5s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.545 total time=   0.6s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.7s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.1s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   6.9s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   4.2s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   7.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   3.3s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   3.7s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   2.7s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.209 total time=   3.6s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.204 total time=   2.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.268 total time=   1.3s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.9s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.3s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   1.9s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   0.8s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   0.6s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.5s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.4s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   1.2s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   2.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   1.1s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.457 total time=   0.8s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   0.8s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.503 total time=   1.4s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.9s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.1s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.8s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.319 total time=   1.1s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   0.7s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   0.7s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   0.8s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.478 total time=   0.6s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.455 total time=   0.5s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.545 total time=   0.6s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   0.7s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   0.7s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   0.7s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.209 total time=   0.9s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.204 total time=   1.1s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.268 total time=   2.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.4s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.1s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   1.7s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   0.8s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   0.6s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.8s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.8s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   0.6s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   0.5s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.481 total time=   0.6s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.397 total time=   0.6s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.410 total time=   0.5s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.469 total time=   0.5s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.1s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   0.6s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   0.6s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.481 total time=   0.6s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.397 total time=   0.5s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.410 total time=   0.7s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.469 total time=   0.6s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.1s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.1s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.1s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.458 total time=   0.6s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.467 total time=   0.6s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.4s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.3s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.4s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.279 total time=   1.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.367 total time=   1.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.447 total time=   2.1s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   0.4s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.457 total time=   0.6s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.440 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.503 total time=   0.6s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.9s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.9s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.267 total time=   1.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.398 total time=   2.4s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.415 total time=   1.1s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.311 total time=   0.9s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.293 total time=   0.9s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.342 total time=   0.9s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.6s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.274 total time=   1.8s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.403 total time=   1.1s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.273 total time=   1.1s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   0.4s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.1s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.5s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   0.6s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   0.5s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.458 total time=   0.6s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.467 total time=   0.6s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.6s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.1s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.279 total time=   1.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.367 total time=   1.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.447 total time=   1.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   0.8s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   1.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.457 total time=   0.6s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.440 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.503 total time=   0.7s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.5s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.267 total time=   1.1s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.398 total time=   2.3s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.415 total time=   1.2s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   0.6s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   1.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   0.7s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.311 total time=   1.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.293 total time=   0.9s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.342 total time=   1.1s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.8s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.274 total time=   1.7s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.403 total time=   1.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.273 total time=   1.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   0.4s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.7s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.4s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.6s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   1.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   1.2s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.7s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   1.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   1.3s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.482 total time=   1.8s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.7s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.5s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   1.3s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   2.1s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.6s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   1.7s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   2.7s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.489 total time=   2.4s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.7s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.6s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   0.3s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.199 total time=   0.4s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   0.3s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.1s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   0.2s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.2s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   0.6s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.482 total time=   0.6s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   0.6s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.489 total time=   0.6s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.6s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   0.3s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   0.3s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.2s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.199 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   0.3s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   0.3s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   0.3s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.449 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   0.7s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.451 total time=   0.6s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.231 total time=   2.5s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.218 total time=   1.6s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.270 total time=   0.7s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.317 total time=   0.7s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.265 total time=   0.7s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   0.3s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   0.5s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.457 total time=   1.1s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   1.4s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.503 total time=   0.7s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.6s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.295 total time=   2.3s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.218 total time=   2.3s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.333 total time=   0.9s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.314 total time=   1.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.265 total time=   0.9s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.473 total time=   0.9s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.492 total time=   0.9s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.577 total time=   1.1s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.468 total time=   2.6s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.384 total time=   1.7s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.458 total time=   1.6s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.421 total time=   2.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.574 total time=   1.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.492 total time=   0.9s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.425 total time=   1.4s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.481 total time=   1.8s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.397 total time=   2.2s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.415 total time=   1.1s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.466 total time=   1.4s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.341 total time=   2.2s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.449 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   0.7s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.451 total time=   0.9s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.6s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.231 total time=   2.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.218 total time=   2.1s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.270 total time=   0.8s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.317 total time=   1.3s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.265 total time=   3.7s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   0.7s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   0.6s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   0.5s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.457 total time=   0.7s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   0.6s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.503 total time=   0.7s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.6s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.295 total time=   2.9s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.218 total time=   1.6s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.333 total time=   1.1s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.314 total time=   3.3s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.265 total time=   1.8s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.473 total time=   1.2s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.492 total time=   2.4s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.577 total time=   1.3s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.468 total time=   1.9s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.384 total time=   2.1s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.458 total time=   1.7s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.421 total time=   1.8s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.574 total time=   1.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.492 total time=   0.9s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.7s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.3s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.9s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.425 total time=   2.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.481 total time=   2.7s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.397 total time=   1.4s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.415 total time=   1.8s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.466 total time=   2.5s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.341 total time=   1.4s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   0.3s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   0.3s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.436 total time=   1.1s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.458 total time=   2.3s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.497 total time=   1.2s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   5.1s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.232 total time=   0.2s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.250 total time=   0.3s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   0.6s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.481 total time=   0.8s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.3s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.8s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.217 total time=   1.2s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.241 total time=   0.8s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   0.6s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   0.8s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.242 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.239 total time=   0.8s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.243 total time=   1.2s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.3s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.5s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.6s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.9s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   0.8s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   0.6s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.6s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   0.6s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   0.6s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.436 total time=   1.1s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.458 total time=   1.4s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.497 total time=   2.6s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.5s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.232 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.250 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   0.7s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   1.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   1.3s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   2.8s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.481 total time=   2.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   7.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.9s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   5.2s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.217 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.241 total time=   0.5s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   0.7s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   0.7s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.242 total time=   0.9s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.239 total time=   0.9s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.243 total time=   1.0s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.7s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.2s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   0.7s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   0.6s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   0.9s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   1.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   0.9s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.422 total time=   2.4s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.517 total time=   2.3s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.478 total time=   1.1s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.301 total time=   6.7s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   4.2s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   6.5s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.207 total time=   1.4s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.285 total time=   1.6s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.305 total time=   1.8s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   1.4s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   2.6s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   1.6s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.457 total time=   1.8s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   1.6s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.503 total time=   1.7s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.308 total time=   3.9s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   3.4s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   5.9s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.254 total time=   1.7s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.263 total time=   3.8s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.250 total time=   2.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   0.8s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   1.3s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   2.9s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.478 total time=   2.7s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.455 total time=   1.2s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.545 total time=   3.1s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.513 total time=   2.1s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.420 total time=   2.5s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.547 total time=   4.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.385 total time=   1.8s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.457 total time=   2.4s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.403 total time=   2.8s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   1.1s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   1.1s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   2.1s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.201 total time=   3.2s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.293 total time=   3.3s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.202 total time=   3.5s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.549 total time=   3.6s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.562 total time=   4.5s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.649 total time=   2.8s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.494 total time=   2.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.591 total time=   1.8s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.648 total time=   1.7s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   0.9s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   1.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   1.1s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.422 total time=   1.7s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.517 total time=   1.2s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.478 total time=   2.6s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.301 total time=   3.6s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   6.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   3.8s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.207 total time=   2.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.285 total time=   2.8s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.305 total time=   1.5s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   0.8s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   1.1s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   2.3s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.457 total time=   2.2s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   1.5s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.503 total time=   1.7s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.308 total time=   4.8s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   3.3s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   6.4s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.254 total time=   1.9s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.263 total time=   4.5s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.250 total time=   1.9s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   0.9s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   1.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   2.2s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.478 total time=   2.1s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.455 total time=   1.2s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.545 total time=   1.9s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.513 total time=   3.2s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.420 total time=   2.1s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.547 total time=   2.8s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.385 total time=   2.5s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.457 total time=   1.4s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.403 total time=   1.1s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   2.6s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   1.8s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   0.8s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.201 total time=   2.1s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.293 total time=   3.5s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.202 total time=   2.7s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.549 total time=   2.8s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.562 total time=   2.7s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.649 total time=   2.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.494 total time=   2.8s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.591 total time=   2.8s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.648 total time=   2.0s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   1.0s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   2.9s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   1.3s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.417 total time=   1.1s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.524 total time=   1.5s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.487 total time=   1.0s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.294 total time=   5.2s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   3.3s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=   4.7s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.226 total time=   0.4s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.286 total time=   0.6s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.285 total time=   0.4s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   0.9s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   1.0s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   1.1s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   3.6s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   1.4s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.481 total time=   2.0s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.296 total time=   4.7s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   3.8s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=   4.9s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.269 total time=   0.5s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.265 total time=   0.5s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.216 total time=   0.5s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   0.9s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   1.0s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   2.3s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.397 total time=   2.0s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.410 total time=   1.0s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.469 total time=   1.3s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.318 total time=   3.7s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.300 total time=   1.6s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.270 total time=   2.3s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.273 total time=   0.9s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.304 total time=   1.2s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.297 total time=   0.7s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   0.9s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   1.0s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   1.1s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   0.8s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   1.0s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   1.7s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   2.4s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.417 total time=   1.4s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.524 total time=   1.1s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.487 total time=   2.0s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.294 total time=   4.0s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   3.2s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=   4.8s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.226 total time=   0.4s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.286 total time=   0.4s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.285 total time=   0.4s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   1.0s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   1.0s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   1.0s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   1.7s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   3.0s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.481 total time=   1.2s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.296 total time=   4.8s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   2.8s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=   5.8s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.269 total time=   0.5s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.265 total time=   0.4s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.216 total time=   0.5s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   0.9s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   1.0s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   1.0s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.397 total time=   1.3s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.410 total time=   3.0s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.469 total time=   1.6s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.318 total time=   3.6s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.300 total time=   2.3s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.270 total time=   1.8s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.273 total time=   0.9s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.304 total time=   1.1s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.297 total time=   0.8s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   1.3s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   1.1s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   2.5s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.8s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   0.7s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.4s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   1.8s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   2.5s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   2.4s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.407 total time=   1.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.495 total time=   0.9s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.475 total time=   0.9s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.301 total time=   3.2s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   6.1s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   3.6s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.195 total time=   1.4s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.264 total time=   3.9s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.303 total time=   1.7s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   2.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   3.3s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   1.5s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.458 total time=   1.3s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   2.9s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.467 total time=   1.5s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.308 total time=   5.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   3.4s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   6.2s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.280 total time=   1.8s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.255 total time=   2.7s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.257 total time=   2.5s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   1.9s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   2.8s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   2.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.457 total time=   1.5s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.440 total time=   1.3s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.503 total time=   3.2s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.472 total time=   1.7s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.399 total time=   2.3s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.484 total time=   3.4s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.367 total time=   0.8s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.446 total time=   1.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.420 total time=   1.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   1.9s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   3.6s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   1.2s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.311 total time=   3.7s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.293 total time=   2.6s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.342 total time=   3.1s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.576 total time=   1.9s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.532 total time=   1.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.580 total time=   1.8s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.558 total time=   2.5s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.558 total time=   2.6s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.611 total time=   1.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   3.5s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   2.1s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   2.9s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.407 total time=   1.9s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.495 total time=   1.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.475 total time=   1.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.301 total time=   5.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   3.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   5.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.195 total time=   1.2s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.264 total time=   2.9s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.303 total time=   2.2s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   1.6s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   2.7s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   2.3s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.458 total time=   1.8s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   1.2s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.467 total time=   3.1s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.308 total time=   3.6s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   5.1s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   3.1s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.280 total time=   3.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.255 total time=   2.5s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.257 total time=   1.6s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   2.6s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   2.9s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   1.4s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.457 total time=   1.2s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.440 total time=   3.7s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.503 total time=   2.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.472 total time=   2.5s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.399 total time=   2.8s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.484 total time=   1.6s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.367 total time=   0.9s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.446 total time=   1.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.420 total time=   2.1s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   2.8s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   2.1s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   1.6s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.311 total time=   3.7s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.293 total time=   2.1s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.342 total time=   4.1s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.576 total time=   1.3s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.532 total time=   1.2s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.580 total time=   2.8s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.558 total time=   1.3s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.558 total time=   1.3s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.611 total time=   2.6s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   2.1s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   4.4s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   1.7s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.407 total time=   1.0s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.500 total time=   0.8s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.475 total time=   0.9s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.294 total time=   4.8s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   3.5s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=   4.8s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.246 total time=   0.4s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.273 total time=   0.4s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.267 total time=   0.4s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   1.7s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   4.0s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   1.8s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   2.4s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   2.6s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.482 total time=   1.2s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.302 total time=   4.8s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   3.2s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=   5.3s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.270 total time=   0.5s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.247 total time=   0.4s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.257 total time=   0.5s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   1.8s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   4.3s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   2.4s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   2.8s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   1.1s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.489 total time=   2.1s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.459 total time=   2.8s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.382 total time=   2.0s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.453 total time=   2.2s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.307 total time=   0.9s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.298 total time=   0.9s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.272 total time=   0.7s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   1.8s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   4.0s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   1.6s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.199 total time=   0.8s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.405 total time=   0.7s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.427 total time=   1.1s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.375 total time=   1.8s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.363 total time=   1.2s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.355 total time=   1.0s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.304 total time=   0.8s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   1.8s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   4.0s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   1.6s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.407 total time=   1.1s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.500 total time=   2.0s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.475 total time=   1.7s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.294 total time=   3.0s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   5.2s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=   2.9s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.246 total time=   0.4s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.273 total time=   0.4s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.267 total time=   0.4s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   2.2s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   3.9s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   1.5s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   1.6s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   2.6s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.482 total time=   1.6s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.302 total time=   5.3s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   3.4s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=   5.2s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.270 total time=   0.5s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.247 total time=   0.4s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.257 total time=   0.6s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   2.0s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   4.6s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   1.7s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   1.7s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   2.6s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.489 total time=   1.5s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.459 total time=   2.6s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.382 total time=   3.1s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.453 total time=   1.7s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.307 total time=   0.4s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.298 total time=   0.4s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.272 total time=   0.4s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   2.9s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   3.1s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   1.6s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.199 total time=   0.8s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.405 total time=   0.7s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.427 total time=   1.2s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.375 total time=   2.0s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.363 total time=   1.5s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.355 total time=   0.9s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.304 total time=   0.7s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   1.9s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   4.8s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   1.6s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.407 total time=   1.1s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.498 total time=   2.4s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.474 total time=   1.6s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.301 total time=   4.9s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   3.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   5.2s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.195 total time=   1.5s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.281 total time=   1.2s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.313 total time=   3.1s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   2.1s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   4.7s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   1.7s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.449 total time=   1.2s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   3.1s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.451 total time=   1.6s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.308 total time=   5.2s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   2.9s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   5.5s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.265 total time=   1.5s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.265 total time=   2.1s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.286 total time=   2.9s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   2.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   4.5s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   1.4s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.457 total time=   1.3s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   2.8s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.503 total time=   2.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.472 total time=   1.7s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.390 total time=   3.3s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.484 total time=   2.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.335 total time=   0.8s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.418 total time=   1.1s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.366 total time=   1.9s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   2.8s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   2.9s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   1.5s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.473 total time=   3.6s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.492 total time=   1.6s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.577 total time=   4.8s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.522 total time=   2.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.500 total time=   1.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.520 total time=   1.1s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.459 total time=   1.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.491 total time=   1.5s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.548 total time=   2.6s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   4.1s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   5.2s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   2.1s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.407 total time=   2.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.498 total time=   2.5s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.474 total time=   3.5s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.301 total time=   6.6s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   3.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   3.3s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.195 total time=   1.1s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.281 total time=   1.5s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.313 total time=   1.4s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   2.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   3.3s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   2.2s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.449 total time=   2.8s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   1.9s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.451 total time=   3.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.308 total time=  10.7s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   8.2s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   7.9s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.265 total time=   2.1s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.265 total time=   2.2s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.286 total time=   2.2s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   3.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   4.9s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   1.4s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.457 total time=   2.8s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   4.1s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.503 total time=   2.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.472 total time=   3.6s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.390 total time=   3.9s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.484 total time=   3.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.335 total time=   1.1s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.418 total time=   2.5s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.366 total time=   2.3s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   2.7s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   5.2s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   1.8s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.473 total time=   9.3s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.492 total time=   6.9s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.577 total time=   4.8s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.522 total time=   2.1s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.500 total time=   3.1s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.520 total time=   2.5s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.459 total time=   1.3s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.491 total time=   0.8s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.548 total time=   0.6s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.519 total time=   3.1s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   7.3s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   2.8s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.406 total time=   1.2s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.484 total time=   2.2s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.475 total time=   1.5s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.294 total time=   2.9s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   6.6s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=   4.6s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.233 total time=   0.7s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.264 total time=   0.6s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.275 total time=   0.9s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.519 total time=   5.9s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   4.8s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   1.9s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.436 total time=   1.2s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.458 total time=   2.5s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.497 total time=   1.4s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.302 total time=   4.8s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   3.0s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=   4.9s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.254 total time=   0.9s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.270 total time=   0.4s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.250 total time=   0.4s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.519 total time=   2.7s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   5.8s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   1.8s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   1.1s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   2.6s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.481 total time=   1.8s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.465 total time=   2.3s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.382 total time=   3.5s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.453 total time=   1.5s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.289 total time=   0.4s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.251 total time=   0.4s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.312 total time=   0.4s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.519 total time=   3.1s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   4.4s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   1.7s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.242 total time=   2.2s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.239 total time=   1.2s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.243 total time=   0.8s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.513 total time=   1.1s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.463 total time=   0.9s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.494 total time=   0.8s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.427 total time=   0.6s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.389 total time=   0.6s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.403 total time=   0.6s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.519 total time=   3.1s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   4.0s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   1.5s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.406 total time=   1.0s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.484 total time=   2.2s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.475 total time=   1.5s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.294 total time=   3.0s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   4.4s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=   3.2s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.233 total time=   0.4s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.264 total time=   0.4s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.275 total time=   0.4s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.519 total time=   2.9s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   4.2s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   2.0s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.436 total time=   1.4s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.458 total time=   2.5s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.497 total time=   1.4s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.302 total time=   3.0s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   4.4s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=   2.9s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.254 total time=   0.4s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.270 total time=   0.4s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.250 total time=   0.5s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.519 total time=   3.7s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   4.7s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   1.9s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   2.5s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   1.3s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.481 total time=   1.2s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.465 total time=   3.3s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.382 total time=   1.5s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.453 total time=   2.4s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.289 total time=   0.7s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.251 total time=   1.0s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.312 total time=   0.5s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.519 total time=   1.8s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   5.0s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   1.5s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.242 total time=   0.8s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.239 total time=   0.8s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.243 total time=   0.9s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.513 total time=   0.8s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.463 total time=   0.7s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.494 total time=   1.0s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.427 total time=   0.9s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.389 total time=   1.2s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.403 total time=   1.1s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   3.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   4.8s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   5.4s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.406 total time=   3.4s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.488 total time=   1.3s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.474 total time=   1.1s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.301 total time=   5.3s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   3.3s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   9.5s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.227 total time=   3.4s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.280 total time=   4.6s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.305 total time=   4.5s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   5.8s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.418 total time=  10.5s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   5.5s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.422 total time=   5.3s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.517 total time=   4.6s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.478 total time=   1.9s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.308 total time=   5.2s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   3.1s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   4.7s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.277 total time=   2.3s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.268 total time=   3.6s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.276 total time=   4.1s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   3.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   6.2s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   2.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.457 total time=   5.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   2.1s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.503 total time=   1.4s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.472 total time=   3.4s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.390 total time=   2.3s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.484 total time=   1.6s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.322 total time=   0.8s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.451 total time=   2.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.375 total time=   2.1s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   2.7s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   5.1s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   1.9s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.478 total time=   3.7s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.455 total time=   2.9s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.545 total time=   1.5s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.516 total time=   0.9s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.465 total time=   0.8s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.520 total time=   1.9s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.457 total time=   1.4s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.464 total time=   1.5s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.553 total time=   0.7s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   1.9s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   4.7s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   1.4s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.406 total time=   1.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.488 total time=   0.7s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.474 total time=   1.2s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.301 total time=   4.2s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   2.9s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   4.4s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.227 total time=   1.4s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.280 total time=   4.4s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.305 total time=   4.2s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   3.8s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   9.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   5.7s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.422 total time=   1.2s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.517 total time=   2.7s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.478 total time=   2.3s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.308 total time=   4.5s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   3.2s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.332 total time=   4.5s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.277 total time=   1.3s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.268 total time=   2.1s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.276 total time=   2.8s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   2.1s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   4.9s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   4.7s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.457 total time=   3.6s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   5.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.503 total time=   4.4s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.472 total time=   7.8s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.390 total time=   4.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.484 total time=   7.7s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.322 total time=   2.6s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.451 total time=   1.2s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.375 total time=   3.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   3.7s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   4.1s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   2.4s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.478 total time=   2.6s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.455 total time=   1.2s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.545 total time=   2.4s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.516 total time=   1.1s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.465 total time=   1.2s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.520 total time=   0.9s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.457 total time=   0.6s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.464 total time=   0.8s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.553 total time=   0.6s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   2.3s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   6.6s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   2.7s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.406 total time=   1.7s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.484 total time=   1.9s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.475 total time=   2.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.294 total time=   3.5s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   4.9s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=   3.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.249 total time=   0.4s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.261 total time=   0.4s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.268 total time=   0.7s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   2.5s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   4.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   1.9s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.417 total time=   1.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.511 total time=   0.9s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.487 total time=   0.8s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.302 total time=   4.8s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   3.1s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=   4.7s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.254 total time=   0.4s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.270 total time=   0.4s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.228 total time=   0.4s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   1.9s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   4.7s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   1.7s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   1.2s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   2.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.481 total time=   2.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.465 total time=   1.9s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.382 total time=   2.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.462 total time=   2.8s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.277 total time=   0.5s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.295 total time=   0.7s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.321 total time=   0.6s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   5.7s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   9.1s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   6.7s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.397 total time=   2.8s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.410 total time=   2.5s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.469 total time=   4.4s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.500 total time=   1.3s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.462 total time=   0.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.500 total time=   0.9s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.442 total time=   0.5s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.393 total time=   0.7s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.379 total time=   1.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   5.6s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   3.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   2.2s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.406 total time=   2.3s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.484 total time=   0.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=poly, probability=True, random_state=0;, score=0.475 total time=   0.8s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.294 total time=   3.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.257 total time=   5.7s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=   3.3s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.249 total time=   0.4s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.261 total time=   0.4s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1, kernel=sigmoid, probability=True, random_state=0;, score=0.268 total time=   0.4s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   6.6s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   4.6s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   3.8s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.417 total time=   1.9s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.511 total time=   0.9s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=poly, probability=True, random_state=0;, score=0.487 total time=   1.7s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.302 total time=   5.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.265 total time=   4.6s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=rbf, probability=True, random_state=0;, score=0.310 total time=  10.3s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.254 total time=   0.8s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.270 total time=   0.7s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.1, kernel=sigmoid, probability=True, random_state=0;, score=0.228 total time=   1.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   3.2s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   7.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   2.5s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.432 total time=   1.1s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.424 total time=   2.5s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=poly, probability=True, random_state=0;, score=0.481 total time=   2.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.465 total time=   4.7s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.382 total time=   2.5s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=rbf, probability=True, random_state=0;, score=0.462 total time=   1.6s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.277 total time=   0.5s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.295 total time=   0.6s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.01, kernel=sigmoid, probability=True, random_state=0;, score=0.321 total time=   0.4s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   4.7s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   4.2s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   3.4s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.397 total time=   2.6s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.410 total time=   1.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.469 total time=   2.4s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.500 total time=   2.5s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.462 total time=   1.3s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.500 total time=   1.2s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.442 total time=   0.7s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.393 total time=   0.9s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.379 total time=   0.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1,\n",
       " 'class_weight': 'balanced',\n",
       " 'decision_function_shape': 'ovo',\n",
       " 'gamma': 0.001,\n",
       " 'kernel': 'rbf',\n",
       " 'probability': True,\n",
       " 'random_state': 0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001,],\n",
    "    'random_state':[0],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'probability': [True],\n",
    "    'decision_function_shape': ['ovo', 'ovr']\n",
    "\n",
    "}\n",
    "random_state=0\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, descnm = data_preprocessing(data_db)\n",
    "X_train, y_train  = SMOTE(random_state=random_state).fit_resample(X_train, y_train)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "cv_res, cv_params = grid_search(X_val, y_val, param_grid, \n",
    "                                algorithm='SVC',)\n",
    "\n",
    "cv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_decision_function_shape</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_probability</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2.284351</td>\n",
       "      <td>0.296288</td>\n",
       "      <td>0.205657</td>\n",
       "      <td>0.105708</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'decision...</td>\n",
       "      <td>0.548911</td>\n",
       "      <td>0.562013</td>\n",
       "      <td>0.648952</td>\n",
       "      <td>0.586625</td>\n",
       "      <td>4.439470e-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>3.369160</td>\n",
       "      <td>0.569590</td>\n",
       "      <td>0.266781</td>\n",
       "      <td>0.124049</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'decision...</td>\n",
       "      <td>0.548911</td>\n",
       "      <td>0.562013</td>\n",
       "      <td>0.648952</td>\n",
       "      <td>0.586625</td>\n",
       "      <td>4.439470e-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.381158</td>\n",
       "      <td>0.105377</td>\n",
       "      <td>0.055315</td>\n",
       "      <td>0.027140</td>\n",
       "      <td>0.001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>ovo</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 0.001, 'class_weight': 'balanced', 'deci...</td>\n",
       "      <td>0.513338</td>\n",
       "      <td>0.593218</td>\n",
       "      <td>0.650044</td>\n",
       "      <td>0.585534</td>\n",
       "      <td>5.607388e-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.018216</td>\n",
       "      <td>0.472280</td>\n",
       "      <td>0.031040</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>0.001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.001</td>\n",
       "      <td>linear</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 0.001, 'class_weight': 'balanced', 'deci...</td>\n",
       "      <td>0.513338</td>\n",
       "      <td>0.593218</td>\n",
       "      <td>0.650044</td>\n",
       "      <td>0.585534</td>\n",
       "      <td>5.607388e-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.675016</td>\n",
       "      <td>0.023027</td>\n",
       "      <td>0.028566</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>0.001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.01</td>\n",
       "      <td>linear</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 0.001, 'class_weight': 'balanced', 'deci...</td>\n",
       "      <td>0.513338</td>\n",
       "      <td>0.593218</td>\n",
       "      <td>0.650044</td>\n",
       "      <td>0.585534</td>\n",
       "      <td>5.607388e-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.189099</td>\n",
       "      <td>0.007622</td>\n",
       "      <td>0.052376</td>\n",
       "      <td>0.016389</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.01</td>\n",
       "      <td>rbf</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 0.001, 'class_weight': None, 'decision_f...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.420285</td>\n",
       "      <td>0.039213</td>\n",
       "      <td>0.023340</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'decision_fu...</td>\n",
       "      <td>0.199206</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.199735</td>\n",
       "      <td>3.741306e-04</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.402553</td>\n",
       "      <td>0.022339</td>\n",
       "      <td>0.024265</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'decision_fu...</td>\n",
       "      <td>0.199206</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.199735</td>\n",
       "      <td>3.741306e-04</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.817573</td>\n",
       "      <td>0.090735</td>\n",
       "      <td>0.032416</td>\n",
       "      <td>0.004706</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'decision_func...</td>\n",
       "      <td>0.199206</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.199735</td>\n",
       "      <td>3.741306e-04</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>0.805185</td>\n",
       "      <td>0.049520</td>\n",
       "      <td>0.042502</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'decision_func...</td>\n",
       "      <td>0.199206</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.199735</td>\n",
       "      <td>3.741306e-04</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "222       2.284351      0.296288         0.205657        0.105708       1   \n",
       "206       3.369160      0.569590         0.266781        0.124049       1   \n",
       "0         1.381158      0.105377         0.055315        0.027140   0.001   \n",
       "28        1.018216      0.472280         0.031040        0.004314   0.001   \n",
       "24        0.675016      0.023027         0.028566        0.001834   0.001   \n",
       "..             ...           ...              ...             ...     ...   \n",
       "58        0.189099      0.007622         0.052376        0.016389   0.001   \n",
       "121       0.420285      0.039213         0.023340        0.001827    0.01   \n",
       "105       0.402553      0.022339         0.024265        0.000427    0.01   \n",
       "301       0.817573      0.090735         0.032416        0.004706      10   \n",
       "317       0.805185      0.049520         0.042502        0.003995      10   \n",
       "\n",
       "    param_class_weight param_decision_function_shape param_gamma param_kernel  \\\n",
       "222           balanced                           ovr       0.001          rbf   \n",
       "206           balanced                           ovo       0.001          rbf   \n",
       "0             balanced                           ovo           1       linear   \n",
       "28            balanced                           ovr       0.001       linear   \n",
       "24            balanced                           ovr        0.01       linear   \n",
       "..                 ...                           ...         ...          ...   \n",
       "58                None                           ovr        0.01          rbf   \n",
       "121               None                           ovr        0.01         poly   \n",
       "105               None                           ovo        0.01         poly   \n",
       "301               None                           ovo       0.001         poly   \n",
       "317               None                           ovr       0.001         poly   \n",
       "\n",
       "    param_probability param_random_state  \\\n",
       "222              True                  0   \n",
       "206              True                  0   \n",
       "0                True                  0   \n",
       "28               True                  0   \n",
       "24               True                  0   \n",
       "..                ...                ...   \n",
       "58               True                  0   \n",
       "121              True                  0   \n",
       "105              True                  0   \n",
       "301              True                  0   \n",
       "317              True                  0   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "222  {'C': 1, 'class_weight': 'balanced', 'decision...           0.548911   \n",
       "206  {'C': 1, 'class_weight': 'balanced', 'decision...           0.548911   \n",
       "0    {'C': 0.001, 'class_weight': 'balanced', 'deci...           0.513338   \n",
       "28   {'C': 0.001, 'class_weight': 'balanced', 'deci...           0.513338   \n",
       "24   {'C': 0.001, 'class_weight': 'balanced', 'deci...           0.513338   \n",
       "..                                                 ...                ...   \n",
       "58   {'C': 0.001, 'class_weight': None, 'decision_f...           0.200000   \n",
       "121  {'C': 0.01, 'class_weight': None, 'decision_fu...           0.199206   \n",
       "105  {'C': 0.01, 'class_weight': None, 'decision_fu...           0.199206   \n",
       "301  {'C': 10, 'class_weight': None, 'decision_func...           0.199206   \n",
       "317  {'C': 10, 'class_weight': None, 'decision_func...           0.199206   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "222           0.562013           0.648952         0.586625    4.439470e-02   \n",
       "206           0.562013           0.648952         0.586625    4.439470e-02   \n",
       "0             0.593218           0.650044         0.585534    5.607388e-02   \n",
       "28            0.593218           0.650044         0.585534    5.607388e-02   \n",
       "24            0.593218           0.650044         0.585534    5.607388e-02   \n",
       "..                 ...                ...              ...             ...   \n",
       "58            0.200000           0.200000         0.200000    2.775558e-17   \n",
       "121           0.200000           0.200000         0.199735    3.741306e-04   \n",
       "105           0.200000           0.200000         0.199735    3.741306e-04   \n",
       "301           0.200000           0.200000         0.199735    3.741306e-04   \n",
       "317           0.200000           0.200000         0.199735    3.741306e-04   \n",
       "\n",
       "     rank_test_score  \n",
       "222                1  \n",
       "206                1  \n",
       "0                  3  \n",
       "28                 3  \n",
       "24                 3  \n",
       "..               ...  \n",
       "58               351  \n",
       "121              445  \n",
       "105              445  \n",
       "301              445  \n",
       "317              445  \n",
       "\n",
       "[448 rows x 18 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_svm_cv_iter_1 = pd.DataFrame(cv_res).sort_values(by='mean_test_score', ascending=False)\n",
    "db_svm_cv_iter_1.to_csv('db_svm_cv_iter_1.csv', index=False)\n",
    "db_svm_cv_iter_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 448 candidates, totalling 1344 fits\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   3.6s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   2.9s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   2.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.4s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=  10.3s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   7.8s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=  11.6s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=  10.1s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   5.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   4.5s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.5s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   2.8s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   3.2s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   3.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   8.6s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   5.9s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   5.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   6.3s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.3s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.3s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   1.6s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   2.4s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   2.9s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.5s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.1s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.9s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.6s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.5s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.1s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.8s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   1.6s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   3.3s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   1.5s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.3s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.0s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.1s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.3s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.3s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.5s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   1.9s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   2.9s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   1.6s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.1s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.3s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.2s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.5s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.4s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   1.2s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   2.4s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   2.8s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.8s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.1s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.5s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.2s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.0s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.5s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   2.6s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   2.6s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   1.5s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.1s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.1s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.5s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.7s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.6s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.3s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.2s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.513 total time=   2.2s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.593 total time=   1.2s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.650 total time=   2.0s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.6s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.9s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.7s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.4s\n",
      "[CV 1/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 2/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   4.5s\n",
      "[CV 3/3] END C=0.001, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.4s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   1.6s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.001, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   0.9s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   0.8s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   0.9s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.1s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.9s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.5s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.2s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.4s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   4.1s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.3s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   2.8s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   2.1s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   1.2s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.4s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.6s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.6s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.3s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.1s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.8s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   0.9s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   1.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   1.1s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.1s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.9s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.2s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.4s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.5s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   5.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.9s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   4.6s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   1.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   0.9s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   0.8s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.4s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.5s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.5s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.5s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.4s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   1.9s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   0.8s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   0.9s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.0s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.6s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   4.3s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.6s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   1.3s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   0.8s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   0.9s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.9s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.8s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.5s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.4s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.1s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.9s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.9s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.8s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   0.8s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   1.1s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   2.7s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.6s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.6s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   5.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.8s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.0s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.555 total time=   1.0s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.549 total time=   1.1s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.584 total time=   1.1s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.1s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   5.8s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.6s\n",
      "[CV 1/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 2/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.4s\n",
      "[CV 3/3] END C=0.01, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.1s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.6s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   0.6s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   0.8s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.5s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.6s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.6s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   0.6s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.8s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   0.5s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   0.7s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   0.6s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.5s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.365 total time=   0.7s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.317 total time=   0.7s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.312 total time=   0.5s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 1/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.01, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   0.9s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   0.8s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   0.7s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.6s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.5s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.425 total time=   5.6s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.481 total time=   5.5s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.397 total time=   4.4s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.415 total time=   4.4s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.466 total time=   4.9s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.341 total time=  11.6s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   1.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   1.6s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   1.2s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.7s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.8s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   5.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   5.3s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   4.8s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   0.7s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   0.8s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   0.7s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.5s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.0s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.3s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   5.0s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.7s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.6s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.3s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   0.9s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   0.7s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   0.8s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.4s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.1s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.7s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   5.3s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.3s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.8s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.1s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   0.7s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   0.9s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   0.7s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.9s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.6s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.425 total time=   3.4s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.481 total time=   5.2s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.397 total time=   3.1s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.415 total time=   2.4s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.466 total time=   2.3s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.341 total time=   2.4s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   0.8s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   0.8s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   0.9s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.8s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.5s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.8s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   0.9s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   0.9s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   0.8s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.1s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.2s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.6s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.7s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.6s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.0s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.554 total time=   0.8s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.503 total time=   0.7s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.536 total time=   0.9s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.1s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.8s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.2s\n",
      "[CV 1/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.8s\n",
      "[CV 2/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 3/3] END C=0.1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   4.1s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.9s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   0.5s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   0.8s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   0.8s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   0.6s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.8s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   0.6s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   0.7s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   0.9s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   0.7s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   1.0s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   0.7s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.7s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   0.8s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   0.6s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.7s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   1.1s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   1.7s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.422 total time=   0.7s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.425 total time=   0.9s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.423 total time=   0.6s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=0.1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   0.8s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   1.1s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   2.4s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.201 total time=   2.7s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.293 total time=   2.1s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.202 total time=   4.5s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.549 total time=   2.4s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.562 total time=   3.6s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.649 total time=   4.1s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.494 total time=   3.7s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.591 total time=   5.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.648 total time=   3.2s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   1.4s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   1.2s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   1.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.408 total time=   5.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.531 total time=   5.7s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.390 total time=   4.2s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.347 total time=   2.6s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.503 total time=   3.2s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.439 total time=   2.9s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   3.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   1.8s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   1.5s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.5s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.1s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.6s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.6s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.8s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.8s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.6s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   4.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   1.3s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   1.6s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   2.3s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.4s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.8s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.8s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.6s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.6s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.1s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.5s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   1.7s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   2.1s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   2.2s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.201 total time=   2.2s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.293 total time=   3.6s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.202 total time=   2.8s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.549 total time=   3.9s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.562 total time=   4.2s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.649 total time=   4.9s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.494 total time=   1.8s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.591 total time=   3.7s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.648 total time=   2.2s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   1.1s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   1.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   1.0s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.3s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.408 total time=   5.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.531 total time=   4.7s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.390 total time=   5.1s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.347 total time=   3.8s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.503 total time=   4.2s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.439 total time=   3.6s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   0.8s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   1.7s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   2.4s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.1s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.1s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.3s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   5.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   5.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   4.3s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   4.0s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   4.4s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.521 total time=   1.8s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.448 total time=   1.4s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.492 total time=   1.6s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   5.6s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.6s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.5s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.6s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.5s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   5.1s\n",
      "[CV 1/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   4.8s\n",
      "[CV 2/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   4.0s\n",
      "[CV 3/3] END C=1, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   5.8s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   2.6s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   3.0s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   2.0s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.6s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   3.4s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.8s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.4s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.1s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.0s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   2.9s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   1.9s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   1.2s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   1.2s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   3.0s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   1.3s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.4s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.5s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   1.6s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   1.7s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   2.8s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   1.0s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   1.1s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   2.4s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.5s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   1.4s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   1.2s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   1.2s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   2.8s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   1.0s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   1.1s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   2.5s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.493 total time=   2.4s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.433 total time=   2.0s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.439 total time=   1.0s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=1, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   1.9s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   4.1s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   3.1s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.311 total time=   3.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.293 total time=   1.9s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.342 total time=   4.5s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.576 total time=   1.1s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.532 total time=   2.4s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.580 total time=   2.3s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.558 total time=   1.2s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.558 total time=   1.3s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.611 total time=   2.6s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   3.3s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   3.5s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   2.3s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.2s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   5.7s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.558 total time=   4.3s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.566 total time=   3.2s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.642 total time=   3.3s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.513 total time=   2.2s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.593 total time=   3.4s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.649 total time=   2.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   3.4s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   3.8s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   2.3s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.6s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   5.7s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.405 total time=   4.7s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.521 total time=   5.6s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.398 total time=   6.4s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.366 total time=   4.1s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.363 total time=   3.8s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.286 total time=   3.2s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   2.1s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   4.2s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   1.3s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.3s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.8s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.1s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   6.7s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=  10.9s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   6.1s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   6.1s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   6.8s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   5.5s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   5.9s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   5.4s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   5.5s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.311 total time=   7.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.293 total time=   8.2s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.342 total time=   7.5s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.576 total time=   3.1s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.532 total time=   3.2s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.580 total time=   3.4s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.558 total time=   2.9s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.558 total time=   3.3s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.611 total time=   2.2s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   3.9s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   6.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   3.7s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   6.1s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   5.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   5.3s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.558 total time=   4.3s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.566 total time=   4.8s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.642 total time=   5.0s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.513 total time=   3.7s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.593 total time=   6.1s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.649 total time=   7.7s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   3.2s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   7.5s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   5.6s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   6.0s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   5.3s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   5.9s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.405 total time=   7.5s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.521 total time=   6.2s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.398 total time=   5.7s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.366 total time=   3.9s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.363 total time=   4.3s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.286 total time=   4.7s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.528 total time=   2.4s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.430 total time=   3.1s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.500 total time=   1.4s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.9s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.0s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.6s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.8s\n",
      "[CV 1/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.6s\n",
      "[CV 2/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 3/3] END C=10, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   2.6s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   1.8s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   1.0s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.199 total time=   0.5s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.405 total time=   0.5s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.427 total time=   0.6s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.375 total time=   0.8s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.363 total time=   0.3s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.355 total time=   0.3s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.304 total time=   0.3s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   1.1s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   3.1s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   0.9s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.217 total time=   0.5s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   0.4s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   0.4s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   1.3s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   2.9s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   1.0s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   1.6s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   2.8s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   1.0s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   1.2s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   2.9s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   0.9s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.199 total time=   0.7s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.405 total time=   0.4s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.427 total time=   0.4s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.375 total time=   0.4s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.363 total time=   0.3s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.355 total time=   0.4s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.304 total time=   0.4s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   1.1s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   2.8s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   1.0s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.217 total time=   0.4s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   0.4s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   0.4s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   1.2s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   2.8s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   0.9s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.2s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.548 total time=   1.7s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.447 total time=   4.0s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.460 total time=   1.1s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.6s\n",
      "[CV 1/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 2/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 3/3] END C=10, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   6.9s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   5.5s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   3.3s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.473 total time=   3.7s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.492 total time=   2.3s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.577 total time=   2.8s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.522 total time=   1.8s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.500 total time=   2.5s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.520 total time=   1.9s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.459 total time=   1.6s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.491 total time=   1.8s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.548 total time=   0.7s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   3.4s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   5.3s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   2.6s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.3s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.8s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.562 total time=   2.1s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.513 total time=   1.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.598 total time=   1.1s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.555 total time=   2.3s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.549 total time=   1.9s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.583 total time=   1.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   3.4s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   5.2s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   1.6s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.3s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.574 total time=   2.5s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.562 total time=   4.8s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.631 total time=   5.9s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.513 total time=   5.6s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.593 total time=   2.6s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.650 total time=   6.9s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   7.7s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   5.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   4.2s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.9s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.8s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.405 total time=   5.6s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.520 total time=  10.2s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.400 total time=  10.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.358 total time=   5.6s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.467 total time=   6.4s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.438 total time=   7.2s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   4.2s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   7.1s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   5.5s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.473 total time=   4.6s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.492 total time=   6.4s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.577 total time=   6.8s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.522 total time=   2.9s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.500 total time=   2.5s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.520 total time=   1.1s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.459 total time=   0.6s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.491 total time=   1.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.548 total time=   0.7s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   3.6s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   4.3s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   2.0s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.2s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.1s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.562 total time=   1.2s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.513 total time=   1.7s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.598 total time=   2.9s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.555 total time=   1.3s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.549 total time=   2.6s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.583 total time=   1.2s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   8.1s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   9.1s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   6.2s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=  10.5s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   7.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.7s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.574 total time=   2.0s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.562 total time=   2.0s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.631 total time=   1.8s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.513 total time=   2.4s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.593 total time=   3.9s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.650 total time=   3.4s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   3.1s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   5.8s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.489 total time=   3.6s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.6s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   3.9s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   5.1s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.405 total time=   5.1s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.520 total time=   4.2s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.400 total time=   4.4s\n",
      "[CV 1/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.358 total time=   3.8s\n",
      "[CV 2/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.467 total time=   4.7s\n",
      "[CV 3/3] END C=100, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.438 total time=   3.9s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.519 total time=   5.2s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   8.8s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   3.5s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.242 total time=   1.4s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.239 total time=   1.1s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.243 total time=   2.4s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.513 total time=   1.8s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.463 total time=   1.2s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.494 total time=   2.5s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.427 total time=   1.0s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.389 total time=   0.8s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.403 total time=   0.6s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.519 total time=   4.0s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   6.6s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   3.2s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.5s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.371 total time=   1.6s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.399 total time=   3.2s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.333 total time=   1.9s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.365 total time=   0.8s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.317 total time=   0.6s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.311 total time=   0.6s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.519 total time=   4.1s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   7.3s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   2.3s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.8s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.217 total time=   1.4s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   0.8s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   0.7s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.519 total time=   3.7s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   9.9s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   5.0s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.2s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.9s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   2.2s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.5s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.5s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.519 total time=   2.2s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   6.6s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   2.6s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.242 total time=   2.9s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.239 total time=   3.1s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.243 total time=   5.9s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.513 total time=   1.2s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.463 total time=   1.4s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.494 total time=   2.6s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.427 total time=   1.2s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.389 total time=   1.7s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.403 total time=   1.7s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.519 total time=   5.0s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.411 total time=  15.2s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   8.5s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   5.8s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   7.4s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.2s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.371 total time=   6.0s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.399 total time=   4.8s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.333 total time=   4.4s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.365 total time=   3.6s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.317 total time=   2.8s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.311 total time=   3.6s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.519 total time=  10.5s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.411 total time=  17.3s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   8.3s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.5s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.4s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.5s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.217 total time=   3.1s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   3.9s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   3.7s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.2s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.0s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   2.7s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.519 total time=  12.7s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.411 total time=  16.5s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.467 total time=   4.9s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.9s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   3.0s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.7s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.200 total time=   1.8s\n",
      "[CV 1/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.3s\n",
      "[CV 2/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.8s\n",
      "[CV 3/3] END C=100, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   3.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   8.8s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.418 total time=  11.7s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   6.4s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.478 total time=   4.8s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.455 total time=   4.6s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.545 total time=   5.3s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.516 total time=   3.7s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.465 total time=   3.7s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.520 total time=   4.0s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.457 total time=   3.8s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.464 total time=   2.7s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.553 total time=   2.9s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   5.3s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.418 total time=  14.7s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   9.2s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.201 total time=  12.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.204 total time=  11.4s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.202 total time=   8.5s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.545 total time=   3.1s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.468 total time=   4.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.557 total time=   2.9s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.554 total time=   3.7s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.502 total time=   4.8s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.536 total time=   4.5s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   8.8s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.418 total time=  17.3s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   9.4s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=  10.3s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   9.7s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   8.2s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.548 total time=   4.0s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.492 total time=   4.1s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.586 total time=   3.9s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.555 total time=   4.1s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.549 total time=   4.4s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.584 total time=   4.4s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   9.7s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.418 total time=  11.8s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   4.7s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   6.5s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   6.4s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   6.7s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.574 total time=   5.3s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.561 total time=   5.8s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.631 total time=   5.5s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.513 total time=   4.2s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.593 total time=   5.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.650 total time=   3.5s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   6.1s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   9.4s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   4.6s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.478 total time=   2.7s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.455 total time=   4.1s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.545 total time=   3.4s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.516 total time=   1.2s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.465 total time=   2.8s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.520 total time=   1.9s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.457 total time=   0.6s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.464 total time=   0.8s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.553 total time=   0.7s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   3.8s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   6.1s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   3.7s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.201 total time=   5.5s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.204 total time=   5.1s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.202 total time=   4.8s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.545 total time=   1.5s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.468 total time=   2.5s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.557 total time=   1.5s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.554 total time=   0.7s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.502 total time=   2.3s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.536 total time=   1.1s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   5.1s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   7.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   2.8s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   5.5s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   5.2s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   5.7s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.548 total time=   2.3s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.492 total time=   3.7s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.586 total time=   2.1s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.555 total time=   2.8s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.549 total time=   2.2s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.584 total time=   3.3s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.526 total time=   5.3s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.418 total time=   7.7s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.498 total time=   3.3s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   7.5s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.9s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   4.7s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.574 total time=   4.2s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.561 total time=   4.7s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.631 total time=   3.3s\n",
      "[CV 1/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.513 total time=   2.9s\n",
      "[CV 2/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.593 total time=   3.0s\n",
      "[CV 3/3] END C=1000, class_weight=balanced, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.650 total time=   2.4s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   3.4s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   6.3s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   2.4s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.397 total time=   3.1s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.410 total time=   1.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.469 total time=   3.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.500 total time=   0.9s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.462 total time=   0.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.500 total time=   0.8s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.442 total time=   0.6s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.393 total time=   1.1s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.379 total time=   2.3s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   3.3s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   4.1s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   3.6s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.6s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.7s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.495 total time=   1.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.466 total time=   1.5s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.457 total time=   0.9s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.422 total time=   0.6s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.425 total time=   0.9s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.423 total time=   0.6s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   4.2s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   6.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   3.2s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.379 total time=   0.7s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.399 total time=   1.4s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.325 total time=   1.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.365 total time=   2.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.317 total time=   1.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.312 total time=   1.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   3.9s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   7.2s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   3.7s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.217 total time=   0.7s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   0.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   0.8s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovo, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   3.9s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   5.9s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   2.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.397 total time=   3.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.410 total time=   1.2s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=poly, probability=True, random_state=0;, score=0.469 total time=   3.3s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.500 total time=   0.9s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.462 total time=   0.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=rbf, probability=True, random_state=0;, score=0.500 total time=   1.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.442 total time=   0.6s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.393 total time=   0.9s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.001, kernel=sigmoid, probability=True, random_state=0;, score=0.379 total time=   0.8s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   3.6s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   5.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   2.3s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   2.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   1.5s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.495 total time=   1.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.466 total time=   0.8s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=rbf, probability=True, random_state=0;, score=0.457 total time=   0.8s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.422 total time=   0.9s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.425 total time=   0.7s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=0.0001, kernel=sigmoid, probability=True, random_state=0;, score=0.423 total time=   0.6s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   3.8s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   7.2s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   3.4s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.9s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.6s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.379 total time=   1.0s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.399 total time=   1.4s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=rbf, probability=True, random_state=0;, score=0.325 total time=   1.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.365 total time=   1.7s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.317 total time=   2.0s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-05, kernel=sigmoid, probability=True, random_state=0;, score=0.312 total time=   1.1s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.502 total time=   2.1s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.411 total time=   5.4s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=linear, probability=True, random_state=0;, score=0.466 total time=   2.0s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.5s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.3s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=poly, probability=True, random_state=0;, score=0.200 total time=   0.4s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.217 total time=   1.1s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   2.2s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=rbf, probability=True, random_state=0;, score=0.209 total time=   1.7s\n",
      "[CV 1/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 2/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   1.3s\n",
      "[CV 3/3] END C=1000, class_weight=None, decision_function_shape=ovr, gamma=1e-06, kernel=sigmoid, probability=True, random_state=0;, score=0.200 total time=   0.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 100,\n",
       " 'class_weight': 'balanced',\n",
       " 'decision_function_shape': 'ovo',\n",
       " 'gamma': 1e-05,\n",
       " 'kernel': 'rbf',\n",
       " 'probability': True,\n",
       " 'random_state': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': [0.001, 0.0001, 0.00001, 0.000001],\n",
    "    'random_state':[0],\n",
    "    'class_weight': ['balanced', None],\n",
    "    'probability': [True],\n",
    "    'decision_function_shape': ['ovo', 'ovr']\n",
    "\n",
    "}\n",
    "random_state=0\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, descnm = data_preprocessing(data_db)\n",
    "X_train, y_train  = SMOTE(random_state=random_state).fit_resample(X_train, y_train)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "cv_res, cv_params = grid_search(X_val, y_val, param_grid, \n",
    "                                algorithm='SVC',)\n",
    "\n",
    "cv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_decision_function_shape</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_probability</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1.798274</td>\n",
       "      <td>0.098819</td>\n",
       "      <td>0.137225</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>100</td>\n",
       "      <td>balanced</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 100, 'class_weight': 'balanced', 'decisi...</td>\n",
       "      <td>0.574308</td>\n",
       "      <td>0.561616</td>\n",
       "      <td>0.631491</td>\n",
       "      <td>0.589138</td>\n",
       "      <td>3.039271e-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>3.930775</td>\n",
       "      <td>1.444594</td>\n",
       "      <td>0.472676</td>\n",
       "      <td>0.284684</td>\n",
       "      <td>100</td>\n",
       "      <td>balanced</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 100, 'class_weight': 'balanced', 'decisi...</td>\n",
       "      <td>0.574308</td>\n",
       "      <td>0.561616</td>\n",
       "      <td>0.631491</td>\n",
       "      <td>0.589138</td>\n",
       "      <td>3.039271e-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>5.190283</td>\n",
       "      <td>0.249182</td>\n",
       "      <td>0.353573</td>\n",
       "      <td>0.030332</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 1000, 'class_weight': 'balanced', 'decis...</td>\n",
       "      <td>0.574308</td>\n",
       "      <td>0.560823</td>\n",
       "      <td>0.631491</td>\n",
       "      <td>0.588874</td>\n",
       "      <td>3.063363e-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>3.619465</td>\n",
       "      <td>0.541893</td>\n",
       "      <td>0.452940</td>\n",
       "      <td>0.023249</td>\n",
       "      <td>1000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 1000, 'class_weight': 'balanced', 'decis...</td>\n",
       "      <td>0.574308</td>\n",
       "      <td>0.560823</td>\n",
       "      <td>0.631491</td>\n",
       "      <td>0.588874</td>\n",
       "      <td>3.063363e-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>4.280975</td>\n",
       "      <td>0.348262</td>\n",
       "      <td>0.420717</td>\n",
       "      <td>0.057590</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'decisio...</td>\n",
       "      <td>0.558435</td>\n",
       "      <td>0.565584</td>\n",
       "      <td>0.642215</td>\n",
       "      <td>0.588745</td>\n",
       "      <td>3.792146e-02</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.344023</td>\n",
       "      <td>0.096599</td>\n",
       "      <td>0.023685</td>\n",
       "      <td>0.008564</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>poly</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'decision_fu...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.320330</td>\n",
       "      <td>0.031581</td>\n",
       "      <td>0.023028</td>\n",
       "      <td>0.006432</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'decision_fu...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>4.550011</td>\n",
       "      <td>0.754415</td>\n",
       "      <td>0.090600</td>\n",
       "      <td>0.010960</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'decisio...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.562359</td>\n",
       "      <td>0.083585</td>\n",
       "      <td>0.025978</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>ovr</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'decision_func...</td>\n",
       "      <td>0.199206</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.199735</td>\n",
       "      <td>3.741306e-04</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.480953</td>\n",
       "      <td>0.006388</td>\n",
       "      <td>0.025802</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'decision_func...</td>\n",
       "      <td>0.199206</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.199735</td>\n",
       "      <td>3.741306e-04</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "346       1.798274      0.098819         0.137225        0.011789     100   \n",
       "330       3.930775      1.444594         0.472676        0.284684     100   \n",
       "398       5.190283      0.249182         0.353573        0.030332    1000   \n",
       "414       3.619465      0.541893         0.452940        0.023249    1000   \n",
       "278       4.280975      0.348262         0.420717        0.057590      10   \n",
       "..             ...           ...              ...             ...     ...   \n",
       "109       0.344023      0.096599         0.023685        0.008564    0.01   \n",
       "107       0.320330      0.031581         0.023028        0.006432    0.01   \n",
       "261       4.550011      0.754415         0.090600        0.010960      10   \n",
       "305       0.562359      0.083585         0.025978        0.001565      10   \n",
       "289       0.480953      0.006388         0.025802        0.000818      10   \n",
       "\n",
       "    param_class_weight param_decision_function_shape param_gamma param_kernel  \\\n",
       "346           balanced                           ovr     0.00001          rbf   \n",
       "330           balanced                           ovo     0.00001          rbf   \n",
       "398           balanced                           ovo    0.000001          rbf   \n",
       "414           balanced                           ovr    0.000001          rbf   \n",
       "278           balanced                           ovr      0.0001          rbf   \n",
       "..                 ...                           ...         ...          ...   \n",
       "109               None                           ovo    0.000001         poly   \n",
       "107               None                           ovo     0.00001      sigmoid   \n",
       "261           balanced                           ovo      0.0001         poly   \n",
       "305               None                           ovr       0.001         poly   \n",
       "289               None                           ovo       0.001         poly   \n",
       "\n",
       "    param_probability param_random_state  \\\n",
       "346              True                  0   \n",
       "330              True                  0   \n",
       "398              True                  0   \n",
       "414              True                  0   \n",
       "278              True                  0   \n",
       "..                ...                ...   \n",
       "109              True                  0   \n",
       "107              True                  0   \n",
       "261              True                  0   \n",
       "305              True                  0   \n",
       "289              True                  0   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "346  {'C': 100, 'class_weight': 'balanced', 'decisi...           0.574308   \n",
       "330  {'C': 100, 'class_weight': 'balanced', 'decisi...           0.574308   \n",
       "398  {'C': 1000, 'class_weight': 'balanced', 'decis...           0.574308   \n",
       "414  {'C': 1000, 'class_weight': 'balanced', 'decis...           0.574308   \n",
       "278  {'C': 10, 'class_weight': 'balanced', 'decisio...           0.558435   \n",
       "..                                                 ...                ...   \n",
       "109  {'C': 0.01, 'class_weight': None, 'decision_fu...           0.200000   \n",
       "107  {'C': 0.01, 'class_weight': None, 'decision_fu...           0.200000   \n",
       "261  {'C': 10, 'class_weight': 'balanced', 'decisio...           0.200000   \n",
       "305  {'C': 10, 'class_weight': None, 'decision_func...           0.199206   \n",
       "289  {'C': 10, 'class_weight': None, 'decision_func...           0.199206   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "346           0.561616           0.631491         0.589138    3.039271e-02   \n",
       "330           0.561616           0.631491         0.589138    3.039271e-02   \n",
       "398           0.560823           0.631491         0.588874    3.063363e-02   \n",
       "414           0.560823           0.631491         0.588874    3.063363e-02   \n",
       "278           0.565584           0.642215         0.588745    3.792146e-02   \n",
       "..                 ...                ...              ...             ...   \n",
       "109           0.200000           0.200000         0.200000    2.775558e-17   \n",
       "107           0.200000           0.200000         0.200000    2.775558e-17   \n",
       "261           0.200000           0.200000         0.200000    2.775558e-17   \n",
       "305           0.200000           0.200000         0.199735    3.741306e-04   \n",
       "289           0.200000           0.200000         0.199735    3.741306e-04   \n",
       "\n",
       "     rank_test_score  \n",
       "346                1  \n",
       "330                1  \n",
       "398                3  \n",
       "414                3  \n",
       "278                5  \n",
       "..               ...  \n",
       "109              207  \n",
       "107              207  \n",
       "261              207  \n",
       "305              447  \n",
       "289              447  \n",
       "\n",
       "[448 rows x 18 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_svm_cv_iter_2 = pd.DataFrame(cv_res).sort_values(by='mean_test_score', ascending=False)\n",
    "db_svm_cv_iter_2.to_csv('db_svm_cv_iter_2.csv', index=False)\n",
    "db_svm_cv_iter_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN scores \n",
      "\n",
      "f1: 0.849\n",
      "balanced accuracy: 0.851\n",
      "matthews corrcoeff: 0.814\n",
      "cf:\n",
      "[[1853  265   99   22   27]\n",
      " [ 368 1548   89   85  176]\n",
      " [  53   35 2044  134    0]\n",
      " [  40    7  100 2065   54]\n",
      " [   7   72    7   50 2130]]\n",
      "-----------\n",
      "VAL scores \n",
      "\n",
      "f1: 0.699\n",
      "balanced accuracy: 0.673\n",
      "matthews corrcoeff: 0.404\n",
      "cf:\n",
      "[[ 42  21   6   3   0]\n",
      " [120 487  41  40  67]\n",
      " [  4   4  16   1   1]\n",
      " [  9   2   4  52   1]\n",
      " [  2   5   1   0  25]]\n",
      "-----------\n",
      "TEST scores \n",
      "\n",
      "f1: 0.720\n",
      "balanced accuracy: 0.713\n",
      "matthews corrcoeff: 0.453\n",
      "cf:\n",
      "[[ 46  12   5   7   2]\n",
      " [118 499  32  29  77]\n",
      " [  3   2  17   3   1]\n",
      " [  3   2   8  54   1]\n",
      " [  2   2   0   2  27]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kernel='rbf'\n",
    "max_iter=10000\n",
    "random_state=0\n",
    "gamma=1e-5\n",
    "C=100\n",
    "decision_function_shape='ovo'\n",
    "class_weight='balanced'\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, descnm = data_preprocessing(data_db)\n",
    "\n",
    "X_train, y_train  = SMOTE(random_state=random_state).fit_resample(X_train, y_train)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# create final model in linreg\n",
    "svm = SVC(probability=True, kernel=kernel,max_iter=max_iter, random_state=random_state, gamma=gamma, class_weight=class_weight, decision_function_shape=decision_function_shape, \n",
    "          C=C)\n",
    "fit = svm.fit(X_train, y_train)\n",
    "y_pred = fit.predict(X_train)\n",
    "y_val_pred = fit.predict(X_val)\n",
    "y_test_pred = fit.predict(X_test)\n",
    "\n",
    "# calculate statistical metrics for training set\n",
    "train_f1 = metrics.f1_score(y_train, y_pred, average = 'weighted')\n",
    "train_ba = metrics.balanced_accuracy_score(y_train, y_pred)\n",
    "train_mcc = metrics.matthews_corrcoef(y_train, y_pred)\n",
    "train_cf = metrics.confusion_matrix(y_train, y_pred)\n",
    "\n",
    "# calculate statistical metrics for val set\n",
    "val_f1 = metrics.f1_score(y_val, y_val_pred, average = 'weighted')\n",
    "val_ba = metrics.balanced_accuracy_score(y_val, y_val_pred)\n",
    "val_mcc = metrics.matthews_corrcoef(y_val, y_val_pred)\n",
    "val_cf = metrics.confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# calculate statistical metrics for testing set\n",
    "test_f1 = metrics.f1_score(y_test, y_test_pred, average = 'weighted')\n",
    "test_ba = metrics.balanced_accuracy_score(y_test, y_test_pred)\n",
    "test_mcc = metrics.matthews_corrcoef(y_test, y_test_pred)\n",
    "test_cf = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(f'TRAIN scores \\n')\n",
    "print(f'f1: {train_f1:.3f}')\n",
    "print(f'balanced accuracy: {train_ba:.3f}')\n",
    "print(f'matthews corrcoeff: {train_mcc:.3f}')\n",
    "print(f'cf:\\n{train_cf}')\n",
    "print('-----------')\n",
    "print(f'VAL scores \\n')\n",
    "print(f'f1: {val_f1:.3f}')\n",
    "print(f'balanced accuracy: {val_ba:.3f}')\n",
    "print(f'matthews corrcoeff: {val_mcc:.3f}')\n",
    "print(f'cf:\\n{val_cf}')\n",
    "print('-----------')\n",
    "print(f'TEST scores \\n')\n",
    "print(f'f1: {test_f1:.3f}')\n",
    "print(f'balanced accuracy: {test_ba:.3f}')\n",
    "print(f'matthews corrcoeff: {test_mcc:.3f}')\n",
    "print(f'cf:\\n{test_cf}')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, descnm = data_preprocessing(data_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation took 110.57697892189026 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model_rf = pd.DataFrame(find_model(X_train, y_train, X_val, y_val, algorithm='RandomForestClassifier', multiclass=True))#.to_csv('da_lr_lbfgs.csv')\n",
    "end_time = time.time()\n",
    "duration_rf = end_time-start_time\n",
    "print(f\"Operation took {duration_rf} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling</th>\n",
       "      <th>scaling</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_ba</th>\n",
       "      <th>train_mcc</th>\n",
       "      <th>train_cf</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>val_ba</th>\n",
       "      <th>val_mcc</th>\n",
       "      <th>val_cf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomUnderSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.997</td>\n",
       "      <td>[[98, 0, 0, 0], [0, 97, 0, 1], [0, 0, 98, 0], ...</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.408</td>\n",
       "      <td>[[60, 16, 16, 5], [171, 479, 43, 62], [8, 1, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>none</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.996</td>\n",
       "      <td>[[2257, 9, 0, 0], [9, 2250, 2, 5], [0, 0, 2266...</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.658</td>\n",
       "      <td>[[56, 36, 5, 0], [28, 721, 2, 4], [7, 11, 50, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomOverSampler</td>\n",
       "      <td>none</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.996</td>\n",
       "      <td>[[2266, 0, 0, 0], [18, 2241, 2, 5], [0, 0, 226...</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.639</td>\n",
       "      <td>[[45, 48, 4, 0], [17, 734, 2, 2], [3, 17, 48, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no_sampling</td>\n",
       "      <td>none</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.975</td>\n",
       "      <td>[[279, 13, 0, 0], [5, 2259, 1, 1], [0, 1, 202,...</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.603</td>\n",
       "      <td>[[42, 54, 1, 0], [13, 738, 2, 2], [4, 22, 42, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sampling scaling  train_accuracy  train_f1  train_ba  train_mcc  \\\n",
       "1  RandomUnderSampler    none           0.997     0.997     0.997      0.997   \n",
       "0               SMOTE    none           0.997     0.997     0.997      0.996   \n",
       "2   RandomOverSampler    none           0.997     0.997     0.997      0.996   \n",
       "3         no_sampling    none           0.991     0.991     0.977      0.975   \n",
       "\n",
       "                                            train_cf  val_accuracy  val_f1  \\\n",
       "1  [[98, 0, 0, 0], [0, 97, 0, 1], [0, 0, 98, 0], ...         0.648   0.696   \n",
       "0  [[2257, 9, 0, 0], [9, 2250, 2, 5], [0, 0, 2266...         0.885   0.881   \n",
       "2  [[2266, 0, 0, 0], [18, 2241, 2, 5], [0, 0, 226...         0.884   0.873   \n",
       "3  [[279, 13, 0, 0], [5, 2259, 1, 1], [0, 1, 202,...         0.875   0.861   \n",
       "\n",
       "   val_ba  val_mcc                                             val_cf  \n",
       "1   0.693    0.408  [[60, 16, 16, 5], [171, 479, 43, 62], [8, 1, 5...  \n",
       "0   0.688    0.658  [[56, 36, 5, 0], [28, 721, 2, 4], [7, 11, 50, ...  \n",
       "2   0.649    0.639  [[45, 48, 4, 0], [17, 734, 2, 2], [3, 17, 48, ...  \n",
       "3   0.598    0.603  [[42, 54, 1, 0], [13, 738, 2, 2], [4, 22, 42, ...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.to_csv('db-rf.csv')\n",
    "model_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.415 total time=   2.6s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.423 total time=   2.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.512 total time=   2.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.535 total time=   2.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.507 total time=   2.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.637 total time=   2.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.621 total time=   1.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.545 total time=   1.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.636 total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.429 total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.441 total time=   0.9s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.512 total time=   0.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.524 total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.559 total time=   0.9s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.611 total time=   0.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.557 total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.568 total time=   1.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.681 total time=   1.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=1, random_state=0;, score=0.480 total time=   9.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=1, random_state=0;, score=0.456 total time=  11.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=1, random_state=0;, score=0.488 total time=   8.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=5, random_state=0;, score=0.588 total time=   5.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=5, random_state=0;, score=0.547 total time=   6.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=5, random_state=0;, score=0.592 total time=   5.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.590 total time=   5.4s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.565 total time=   5.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.635 total time=   7.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.438 total time=   1.9s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.464 total time=   3.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.491 total time=   1.3s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.550 total time=   1.2s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.539 total time=   2.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.588 total time=   1.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.615 total time=   2.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.561 total time=   1.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.629 total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.416 total time=   2.2s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.431 total time=   1.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.486 total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.589 total time=   2.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.526 total time=   1.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.621 total time=   0.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.601 total time=   0.9s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.564 total time=   0.9s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.636 total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=1, random_state=0;, score=0.450 total time=   9.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=1, random_state=0;, score=0.495 total time=  10.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=1, random_state=0;, score=0.535 total time=  12.3s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=5, random_state=0;, score=0.543 total time=   8.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=5, random_state=0;, score=0.557 total time=   9.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=5, random_state=0;, score=0.564 total time=   8.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.581 total time=   6.9s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.587 total time=   7.6s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.644 total time=   8.3s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.438 total time=   1.4s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.464 total time=   1.8s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.491 total time=   2.3s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.550 total time=   1.2s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.539 total time=   2.6s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.588 total time=   1.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.615 total time=   2.2s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.561 total time=   1.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.629 total time=   2.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.416 total time=   1.2s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.431 total time=   2.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.486 total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.589 total time=   0.9s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.526 total time=   0.9s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.621 total time=   1.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.601 total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.564 total time=   1.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.636 total time=   0.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=1, random_state=0;, score=0.450 total time=  10.3s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=1, random_state=0;, score=0.495 total time=  10.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=1, random_state=0;, score=0.535 total time=  10.3s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=5, random_state=0;, score=0.543 total time=   9.3s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=5, random_state=0;, score=0.557 total time=   9.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=5, random_state=0;, score=0.564 total time=   8.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.581 total time=   6.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.587 total time=   7.9s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.644 total time=   7.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.473 total time=   1.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.446 total time=   2.8s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.513 total time=   1.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.555 total time=   2.4s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.525 total time=   1.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.585 total time=   2.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.604 total time=   1.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.532 total time=   2.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.652 total time=   1.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.439 total time=   2.8s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.447 total time=   1.8s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.509 total time=   2.6s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.520 total time=   1.4s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.524 total time=   1.6s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.607 total time=   2.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.585 total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.534 total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.688 total time=   2.8s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=1, random_state=0;, score=0.473 total time=  10.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=1, random_state=0;, score=0.453 total time=   8.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=1, random_state=0;, score=0.505 total time=   8.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=5, random_state=0;, score=0.572 total time=   7.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=5, random_state=0;, score=0.535 total time=   7.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=5, random_state=0;, score=0.588 total time=   9.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.603 total time=   5.9s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.572 total time=   6.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.601 total time=   6.8s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.450 total time=   1.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.441 total time=   2.6s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.525 total time=   1.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.534 total time=   1.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.556 total time=   2.4s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.591 total time=   1.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.564 total time=   1.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.560 total time=   2.4s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.614 total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.442 total time=   2.4s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.456 total time=   1.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.514 total time=   2.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.604 total time=   1.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.544 total time=   2.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.583 total time=   1.6s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.588 total time=   2.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.557 total time=   1.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.649 total time=   1.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=1, random_state=0;, score=0.482 total time=   9.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=1, random_state=0;, score=0.487 total time=  10.4s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=1, random_state=0;, score=0.512 total time=  10.5s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=5, random_state=0;, score=0.541 total time=   8.8s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=5, random_state=0;, score=0.556 total time=   9.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=5, random_state=0;, score=0.569 total time=   8.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.581 total time=   7.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.577 total time=   9.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.605 total time=   8.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.450 total time=   2.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.441 total time=   2.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.525 total time=   1.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.534 total time=   1.4s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.556 total time=   2.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.591 total time=   1.4s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.564 total time=   1.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.560 total time=   2.4s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.614 total time=   1.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.442 total time=   1.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.456 total time=   2.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.514 total time=   1.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.604 total time=   2.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.544 total time=   1.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.583 total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.588 total time=   2.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.557 total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.649 total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=1, random_state=0;, score=0.482 total time=   9.8s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=1, random_state=0;, score=0.487 total time=  13.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=1, random_state=0;, score=0.512 total time=  11.4s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=5, random_state=0;, score=0.541 total time=   8.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=5, random_state=0;, score=0.556 total time=   9.9s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=5, random_state=0;, score=0.569 total time=  10.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.581 total time=   8.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.577 total time=  12.6s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.605 total time=   9.0s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.416 total time=   1.7s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.450 total time=   2.5s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.520 total time=   1.4s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.356 total time=   1.1s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.358 total time=   2.3s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.402 total time=   1.2s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.339 total time=   2.1s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.313 total time=   1.2s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.380 total time=   2.2s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.433 total time=   1.1s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.433 total time=   2.2s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.534 total time=   1.1s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.337 total time=   1.7s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.351 total time=   1.8s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.392 total time=   0.9s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.318 total time=   1.5s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.305 total time=   2.1s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.325 total time=   1.7s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=1, random_state=0;, score=0.501 total time=  13.0s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=1, random_state=0;, score=0.476 total time=  15.5s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=1, random_state=0;, score=0.580 total time=  12.3s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=5, random_state=0;, score=0.336 total time=   8.7s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=5, random_state=0;, score=0.426 total time=   9.9s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=5, random_state=0;, score=0.506 total time=   9.2s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.336 total time=   9.6s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.421 total time=   6.7s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.421 total time=   7.6s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.450 total time=   1.7s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.457 total time=   2.4s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.535 total time=   1.6s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.360 total time=   2.2s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.403 total time=   1.2s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.401 total time=   2.4s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.342 total time=   1.0s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.331 total time=   1.0s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.343 total time=   1.0s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.431 total time=   0.9s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.465 total time=   1.0s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.504 total time=   1.0s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.340 total time=   0.9s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.392 total time=   0.9s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.402 total time=   0.9s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.309 total time=   0.9s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.308 total time=   1.0s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.356 total time=   1.9s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=1, random_state=0;, score=0.451 total time=   8.9s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=1, random_state=0;, score=0.458 total time=  11.1s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=1, random_state=0;, score=0.556 total time=  10.1s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=5, random_state=0;, score=0.367 total time=   8.0s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=5, random_state=0;, score=0.441 total time=   9.0s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=5, random_state=0;, score=0.499 total time=   9.1s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.347 total time=   7.0s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.446 total time=   8.6s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.455 total time=  11.0s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.450 total time=   2.0s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.457 total time=   2.4s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=1, random_state=0;, score=0.535 total time=   2.0s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.360 total time=   1.9s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.403 total time=   1.2s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=5, random_state=0;, score=0.401 total time=   1.2s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.342 total time=   2.1s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.331 total time=   1.2s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.343 total time=   1.3s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.431 total time=   2.0s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.465 total time=   0.9s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=1, random_state=0;, score=0.504 total time=   1.0s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.340 total time=   0.9s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.392 total time=   0.9s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=5, random_state=0;, score=0.402 total time=   1.0s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.309 total time=   0.9s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.308 total time=   0.8s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.356 total time=   0.9s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=1, random_state=0;, score=0.451 total time=   9.5s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=1, random_state=0;, score=0.458 total time=  10.1s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=1, random_state=0;, score=0.556 total time=  12.9s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=5, random_state=0;, score=0.367 total time=   8.1s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=5, random_state=0;, score=0.441 total time=   9.6s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=5, random_state=0;, score=0.499 total time=   8.9s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.347 total time=   7.2s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.446 total time=   7.4s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.455 total time=   7.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'criterion': 'entropy',\n",
       " 'max_features': None,\n",
       " 'min_samples_leaf': 10,\n",
       " 'random_state': 0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'random_state':[0],\n",
    "    'class_weight': ['balanced', 'balanced_subsample', None],\n",
    "\n",
    "}\n",
    "\n",
    "random_state=0\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, descnm = data_preprocessing(data_db)\n",
    "X_train, y_train  = SMOTE(random_state=random_state).fit_resample(X_train, y_train)\n",
    "\n",
    "cv_res, cv_params = grid_search(X_val, y_val, param_grid, \n",
    "                                algorithm='RandomForestClassifier',)\n",
    "\n",
    "cv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.543119</td>\n",
       "      <td>0.570267</td>\n",
       "      <td>0.044137</td>\n",
       "      <td>0.011018</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.580710</td>\n",
       "      <td>0.586554</td>\n",
       "      <td>0.643970</td>\n",
       "      <td>0.603744</td>\n",
       "      <td>0.028543</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.304468</td>\n",
       "      <td>0.487281</td>\n",
       "      <td>0.039913</td>\n",
       "      <td>0.012187</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'log...</td>\n",
       "      <td>0.580710</td>\n",
       "      <td>0.586554</td>\n",
       "      <td>0.643970</td>\n",
       "      <td>0.603744</td>\n",
       "      <td>0.028543</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.548415</td>\n",
       "      <td>0.771321</td>\n",
       "      <td>0.068666</td>\n",
       "      <td>0.038562</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.585426</td>\n",
       "      <td>0.534151</td>\n",
       "      <td>0.688232</td>\n",
       "      <td>0.602603</td>\n",
       "      <td>0.064065</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.421853</td>\n",
       "      <td>0.409720</td>\n",
       "      <td>0.054206</td>\n",
       "      <td>0.019046</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.615255</td>\n",
       "      <td>0.561432</td>\n",
       "      <td>0.629422</td>\n",
       "      <td>0.602036</td>\n",
       "      <td>0.029288</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.800551</td>\n",
       "      <td>0.477576</td>\n",
       "      <td>0.079839</td>\n",
       "      <td>0.028997</td>\n",
       "      <td>balanced</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'log...</td>\n",
       "      <td>0.615255</td>\n",
       "      <td>0.561432</td>\n",
       "      <td>0.629422</td>\n",
       "      <td>0.602036</td>\n",
       "      <td>0.029288</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1.489372</td>\n",
       "      <td>0.398287</td>\n",
       "      <td>0.050211</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.341712</td>\n",
       "      <td>0.330842</td>\n",
       "      <td>0.342509</td>\n",
       "      <td>0.338354</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.945127</td>\n",
       "      <td>0.014968</td>\n",
       "      <td>0.036765</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.341712</td>\n",
       "      <td>0.330842</td>\n",
       "      <td>0.342509</td>\n",
       "      <td>0.338354</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.232622</td>\n",
       "      <td>0.434324</td>\n",
       "      <td>0.052715</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.309103</td>\n",
       "      <td>0.308111</td>\n",
       "      <td>0.355864</td>\n",
       "      <td>0.324360</td>\n",
       "      <td>0.022281</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.854255</td>\n",
       "      <td>0.031576</td>\n",
       "      <td>0.032162</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.309103</td>\n",
       "      <td>0.308111</td>\n",
       "      <td>0.355864</td>\n",
       "      <td>0.324360</td>\n",
       "      <td>0.022281</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.630722</td>\n",
       "      <td>0.342289</td>\n",
       "      <td>0.135984</td>\n",
       "      <td>0.081383</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "      <td>0.317989</td>\n",
       "      <td>0.305054</td>\n",
       "      <td>0.324565</td>\n",
       "      <td>0.315869</td>\n",
       "      <td>0.008105</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "17       7.543119      0.570267         0.044137        0.011018   \n",
       "26       7.304468      0.487281         0.039913        0.012187   \n",
       "32       1.548415      0.771321         0.068666        0.038562   \n",
       "11       1.421853      0.409720         0.054206        0.019046   \n",
       "20       1.800551      0.477576         0.079839        0.028997   \n",
       "..            ...           ...              ...             ...   \n",
       "74       1.489372      0.398287         0.050211        0.009656   \n",
       "65       0.945127      0.014968         0.036765        0.003882   \n",
       "68       1.232622      0.434324         0.052715        0.011070   \n",
       "77       0.854255      0.031576         0.032162        0.007466   \n",
       "59       1.630722      0.342289         0.135984        0.081383   \n",
       "\n",
       "    param_class_weight param_criterion param_max_features  \\\n",
       "17            balanced         entropy               None   \n",
       "26            balanced        log_loss               None   \n",
       "32  balanced_subsample            gini               log2   \n",
       "11            balanced         entropy               sqrt   \n",
       "20            balanced        log_loss               sqrt   \n",
       "..                 ...             ...                ...   \n",
       "74                None        log_loss               sqrt   \n",
       "65                None         entropy               sqrt   \n",
       "68                None         entropy               log2   \n",
       "77                None        log_loss               log2   \n",
       "59                None            gini               log2   \n",
       "\n",
       "   param_min_samples_leaf param_random_state  \\\n",
       "17                     10                  0   \n",
       "26                     10                  0   \n",
       "32                     10                  0   \n",
       "11                     10                  0   \n",
       "20                     10                  0   \n",
       "..                    ...                ...   \n",
       "74                     10                  0   \n",
       "65                     10                  0   \n",
       "68                     10                  0   \n",
       "77                     10                  0   \n",
       "59                     10                  0   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "17  {'class_weight': 'balanced', 'criterion': 'ent...           0.580710   \n",
       "26  {'class_weight': 'balanced', 'criterion': 'log...           0.580710   \n",
       "32  {'class_weight': 'balanced_subsample', 'criter...           0.585426   \n",
       "11  {'class_weight': 'balanced', 'criterion': 'ent...           0.615255   \n",
       "20  {'class_weight': 'balanced', 'criterion': 'log...           0.615255   \n",
       "..                                                ...                ...   \n",
       "74  {'class_weight': None, 'criterion': 'log_loss'...           0.341712   \n",
       "65  {'class_weight': None, 'criterion': 'entropy',...           0.341712   \n",
       "68  {'class_weight': None, 'criterion': 'entropy',...           0.309103   \n",
       "77  {'class_weight': None, 'criterion': 'log_loss'...           0.309103   \n",
       "59  {'class_weight': None, 'criterion': 'gini', 'm...           0.317989   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "17           0.586554           0.643970         0.603744        0.028543   \n",
       "26           0.586554           0.643970         0.603744        0.028543   \n",
       "32           0.534151           0.688232         0.602603        0.064065   \n",
       "11           0.561432           0.629422         0.602036        0.029288   \n",
       "20           0.561432           0.629422         0.602036        0.029288   \n",
       "..                ...                ...              ...             ...   \n",
       "74           0.330842           0.342509         0.338354        0.005322   \n",
       "65           0.330842           0.342509         0.338354        0.005322   \n",
       "68           0.308111           0.355864         0.324360        0.022281   \n",
       "77           0.308111           0.355864         0.324360        0.022281   \n",
       "59           0.305054           0.324565         0.315869        0.008105   \n",
       "\n",
       "    rank_test_score  \n",
       "17                1  \n",
       "26                1  \n",
       "32                3  \n",
       "11                4  \n",
       "20                4  \n",
       "..              ...  \n",
       "74               77  \n",
       "65               77  \n",
       "68               79  \n",
       "77               79  \n",
       "59               81  \n",
       "\n",
       "[81 rows x 16 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_rf_cv_iter_1 = pd.DataFrame(cv_res).sort_values(by='mean_test_score', ascending=False)\n",
    "db_rf_cv_iter_1.to_csv('db_rf_cv_iter_1.csv', index=False)\n",
    "db_rf_cv_iter_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 135 candidates, totalling 405 fits\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.621 total time=   3.2s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.545 total time=   2.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.636 total time=   2.3s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.613 total time=   1.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.576 total time=   1.3s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.655 total time=   1.3s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.629 total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.586 total time=   1.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.617 total time=   1.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.578 total time=   1.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.603 total time=   1.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.632 total time=   1.7s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.523 total time=   1.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.491 total time=   1.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.518 total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.557 total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.568 total time=   0.8s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.681 total time=   1.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.604 total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.556 total time=   0.9s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.651 total time=   0.7s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.613 total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.618 total time=   0.8s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.652 total time=   0.7s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.581 total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.573 total time=   0.7s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.617 total time=   0.7s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.504 total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.554 total time=   0.6s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.537 total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.590 total time=   5.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.565 total time=   6.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.635 total time=   6.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=15, random_state=0;, score=0.624 total time=   8.4s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=15, random_state=0;, score=0.547 total time=   8.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=15, random_state=0;, score=0.638 total time=   5.7s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=20, random_state=0;, score=0.604 total time=   5.6s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=20, random_state=0;, score=0.576 total time=   4.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=20, random_state=0;, score=0.640 total time=   4.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=50, random_state=0;, score=0.533 total time=   2.6s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=50, random_state=0;, score=0.605 total time=   2.7s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=50, random_state=0;, score=0.590 total time=   4.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=100, random_state=0;, score=0.474 total time=   1.6s\n",
      "[CV 2/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=100, random_state=0;, score=0.511 total time=   2.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=gini, max_features=None, min_samples_leaf=100, random_state=0;, score=0.489 total time=   2.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.615 total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.561 total time=   2.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.629 total time=   1.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.623 total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.570 total time=   2.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.661 total time=   1.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.597 total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.597 total time=   0.9s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.663 total time=   0.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.604 total time=   0.9s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.587 total time=   0.8s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.588 total time=   0.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.515 total time=   0.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.485 total time=   0.7s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.510 total time=   0.7s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.601 total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.564 total time=   1.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.636 total time=   0.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.572 total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.575 total time=   0.8s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.666 total time=   0.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.635 total time=   1.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.592 total time=   1.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.648 total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.570 total time=   0.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.591 total time=   0.6s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.592 total time=   0.7s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.531 total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.550 total time=   0.6s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.512 total time=   0.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.581 total time=   6.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.587 total time=   8.5s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.644 total time=   7.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=15, random_state=0;, score=0.606 total time=   6.5s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=15, random_state=0;, score=0.572 total time=   5.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=15, random_state=0;, score=0.611 total time=   6.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=20, random_state=0;, score=0.585 total time=   4.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=20, random_state=0;, score=0.563 total time=   7.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=20, random_state=0;, score=0.633 total time=   5.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=50, random_state=0;, score=0.461 total time=   4.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=50, random_state=0;, score=0.613 total time=   3.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=50, random_state=0;, score=0.588 total time=   4.1s\n",
      "[CV 1/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=100, random_state=0;, score=0.439 total time=   1.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=100, random_state=0;, score=0.494 total time=   2.8s\n",
      "[CV 3/3] END class_weight=balanced, criterion=entropy, max_features=None, min_samples_leaf=100, random_state=0;, score=0.511 total time=   2.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.615 total time=   1.2s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.561 total time=   2.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.629 total time=   1.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.623 total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.570 total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.661 total time=   1.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.597 total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.597 total time=   1.0s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.663 total time=   1.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.604 total time=   0.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.587 total time=   0.7s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.588 total time=   0.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.515 total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.485 total time=   0.8s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.510 total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.601 total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.564 total time=   0.8s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.636 total time=   0.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.572 total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.575 total time=   0.8s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.666 total time=   0.9s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.635 total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.592 total time=   0.7s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.648 total time=   0.8s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.570 total time=   0.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.591 total time=   0.6s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.592 total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.531 total time=   0.6s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.550 total time=   0.6s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.512 total time=   0.6s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.581 total time=   6.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.587 total time=   6.1s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.644 total time=   7.2s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=15, random_state=0;, score=0.606 total time=   5.2s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=15, random_state=0;, score=0.572 total time=   6.4s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=15, random_state=0;, score=0.611 total time=   6.0s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=20, random_state=0;, score=0.585 total time=   5.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=20, random_state=0;, score=0.563 total time=   4.9s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=20, random_state=0;, score=0.633 total time=   6.4s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=50, random_state=0;, score=0.461 total time=   3.1s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=50, random_state=0;, score=0.613 total time=   4.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=50, random_state=0;, score=0.588 total time=   3.5s\n",
      "[CV 1/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=100, random_state=0;, score=0.439 total time=   2.7s\n",
      "[CV 2/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=100, random_state=0;, score=0.494 total time=   2.2s\n",
      "[CV 3/3] END class_weight=balanced, criterion=log_loss, max_features=None, min_samples_leaf=100, random_state=0;, score=0.511 total time=   2.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.604 total time=   1.4s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.532 total time=   1.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.652 total time=   2.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.625 total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.551 total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.651 total time=   2.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.626 total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.622 total time=   1.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.658 total time=   1.9s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.582 total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.573 total time=   1.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.616 total time=   1.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.506 total time=   0.7s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.496 total time=   0.8s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.525 total time=   0.8s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.585 total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.534 total time=   1.9s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.688 total time=   1.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.608 total time=   0.9s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.568 total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.649 total time=   1.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.618 total time=   0.9s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.577 total time=   0.9s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.659 total time=   0.9s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.576 total time=   0.9s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.603 total time=   1.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.619 total time=   1.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.523 total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.561 total time=   0.7s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.507 total time=   0.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.603 total time=   5.9s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.572 total time=   5.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.601 total time=   6.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=15, random_state=0;, score=0.628 total time=   4.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=15, random_state=0;, score=0.556 total time=   6.4s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=15, random_state=0;, score=0.647 total time=   5.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=20, random_state=0;, score=0.612 total time=   5.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=20, random_state=0;, score=0.548 total time=   3.9s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=20, random_state=0;, score=0.606 total time=   5.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=50, random_state=0;, score=0.531 total time=   2.7s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=50, random_state=0;, score=0.598 total time=   3.7s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=50, random_state=0;, score=0.590 total time=   2.7s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=100, random_state=0;, score=0.459 total time=   2.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=100, random_state=0;, score=0.505 total time=   2.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=gini, max_features=None, min_samples_leaf=100, random_state=0;, score=0.494 total time=   2.4s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.564 total time=   1.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.560 total time=   1.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.614 total time=   2.4s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.609 total time=   1.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.562 total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.636 total time=   2.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.585 total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.552 total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.627 total time=   2.8s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.607 total time=   1.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.577 total time=   1.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.589 total time=   2.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.496 total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.476 total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.521 total time=   1.8s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.588 total time=   1.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.557 total time=   1.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.649 total time=   1.9s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.593 total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.558 total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.661 total time=   1.8s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.622 total time=   1.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.621 total time=   1.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.669 total time=   1.8s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.578 total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.616 total time=   0.9s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.621 total time=   0.8s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.526 total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.554 total time=   0.8s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.513 total time=   0.8s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.581 total time=   6.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.577 total time=   7.6s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.605 total time=   6.8s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=15, random_state=0;, score=0.593 total time=   6.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=15, random_state=0;, score=0.563 total time=   7.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=15, random_state=0;, score=0.629 total time=   8.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=20, random_state=0;, score=0.556 total time=   5.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=20, random_state=0;, score=0.569 total time=   6.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=20, random_state=0;, score=0.631 total time=   5.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=50, random_state=0;, score=0.469 total time=   4.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=50, random_state=0;, score=0.584 total time=   3.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=50, random_state=0;, score=0.593 total time=   4.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=100, random_state=0;, score=0.463 total time=   2.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=100, random_state=0;, score=0.488 total time=   2.9s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=entropy, max_features=None, min_samples_leaf=100, random_state=0;, score=0.506 total time=   2.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.564 total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.560 total time=   2.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.614 total time=   1.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.609 total time=   1.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.562 total time=   2.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.636 total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.585 total time=   1.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.552 total time=   2.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.627 total time=   1.9s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.607 total time=   1.5s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.577 total time=   1.9s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.589 total time=   1.4s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.496 total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.476 total time=   2.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.521 total time=   1.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.588 total time=   1.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.557 total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.649 total time=   2.1s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.593 total time=   1.2s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.558 total time=   1.1s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.661 total time=   2.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.622 total time=   1.1s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.621 total time=   1.0s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.669 total time=   1.0s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.578 total time=   1.4s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.616 total time=   1.3s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.621 total time=   0.9s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.526 total time=   0.8s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.554 total time=   0.8s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.513 total time=   0.8s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.581 total time=   6.8s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.577 total time=   6.6s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.605 total time=   7.6s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=15, random_state=0;, score=0.593 total time=   5.6s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=15, random_state=0;, score=0.563 total time=   7.8s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=15, random_state=0;, score=0.629 total time=   7.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=20, random_state=0;, score=0.556 total time=   6.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=20, random_state=0;, score=0.569 total time=   5.4s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=20, random_state=0;, score=0.631 total time=   6.2s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=50, random_state=0;, score=0.469 total time=   3.3s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=50, random_state=0;, score=0.584 total time=   4.5s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=50, random_state=0;, score=0.593 total time=   3.3s\n",
      "[CV 1/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=100, random_state=0;, score=0.463 total time=   3.0s\n",
      "[CV 2/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=100, random_state=0;, score=0.488 total time=   2.2s\n",
      "[CV 3/3] END class_weight=balanced_subsample, criterion=log_loss, max_features=None, min_samples_leaf=100, random_state=0;, score=0.506 total time=   3.0s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.339 total time=   0.9s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.313 total time=   0.9s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.380 total time=   1.0s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.319 total time=   1.0s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.287 total time=   0.8s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.352 total time=   1.0s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.272 total time=   0.9s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.258 total time=   0.8s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.313 total time=   0.8s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.8s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.6s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.318 total time=   0.8s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.305 total time=   0.8s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.325 total time=   1.2s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.289 total time=   1.9s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.258 total time=   1.1s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.353 total time=   1.0s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.272 total time=   1.0s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.250 total time=   1.0s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.305 total time=   1.0s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.250 total time=   1.5s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.250 total time=   1.0s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.8s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.6s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.8s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.6s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.336 total time=   5.6s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.421 total time=   7.2s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=10, random_state=0;, score=0.421 total time=   6.3s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=15, random_state=0;, score=0.338 total time=   6.9s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=15, random_state=0;, score=0.403 total time=   5.3s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=15, random_state=0;, score=0.391 total time=   6.0s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=20, random_state=0;, score=0.338 total time=   4.5s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=20, random_state=0;, score=0.346 total time=   5.6s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=20, random_state=0;, score=0.369 total time=   4.1s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=50, random_state=0;, score=0.250 total time=   4.6s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=50, random_state=0;, score=0.250 total time=   3.6s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=50, random_state=0;, score=0.250 total time=   3.9s\n",
      "[CV 1/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=100, random_state=0;, score=0.250 total time=   2.3s\n",
      "[CV 2/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=100, random_state=0;, score=0.250 total time=   2.3s\n",
      "[CV 3/3] END class_weight=None, criterion=gini, max_features=None, min_samples_leaf=100, random_state=0;, score=0.250 total time=   2.5s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.342 total time=   1.2s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.331 total time=   1.1s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.343 total time=   1.1s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.349 total time=   1.0s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.287 total time=   0.9s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.360 total time=   0.9s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.290 total time=   1.0s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.269 total time=   0.9s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.313 total time=   0.9s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.8s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.6s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.6s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.6s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.309 total time=   0.8s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.308 total time=   0.8s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.356 total time=   0.8s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.293 total time=   1.1s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.258 total time=   1.7s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.326 total time=   0.9s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.272 total time=   0.7s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.294 total time=   0.8s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.6s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.8s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.8s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.6s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.347 total time=   6.0s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.446 total time=   9.0s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=10, random_state=0;, score=0.455 total time=   7.7s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=15, random_state=0;, score=0.328 total time=   8.3s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=15, random_state=0;, score=0.427 total time=   6.9s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=15, random_state=0;, score=0.391 total time=   7.4s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=20, random_state=0;, score=0.341 total time=   6.4s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=20, random_state=0;, score=0.412 total time=   5.2s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=20, random_state=0;, score=0.373 total time=   5.6s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=50, random_state=0;, score=0.332 total time=   3.1s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=50, random_state=0;, score=0.250 total time=   3.2s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=50, random_state=0;, score=0.292 total time=   4.7s\n",
      "[CV 1/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=100, random_state=0;, score=0.250 total time=   2.7s\n",
      "[CV 2/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=100, random_state=0;, score=0.250 total time=   3.6s\n",
      "[CV 3/3] END class_weight=None, criterion=entropy, max_features=None, min_samples_leaf=100, random_state=0;, score=0.250 total time=   2.4s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.342 total time=   1.0s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.331 total time=   1.0s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=10, random_state=0;, score=0.343 total time=   1.0s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.349 total time=   1.8s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.287 total time=   1.3s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=15, random_state=0;, score=0.360 total time=   1.2s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.290 total time=   0.9s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.269 total time=   1.0s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=20, random_state=0;, score=0.313 total time=   1.0s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.8s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.9s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=sqrt, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.309 total time=   0.9s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.308 total time=   0.9s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=10, random_state=0;, score=0.356 total time=   0.9s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.293 total time=   0.8s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.258 total time=   0.9s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=15, random_state=0;, score=0.326 total time=   0.8s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.272 total time=   0.8s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.250 total time=   0.8s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=20, random_state=0;, score=0.294 total time=   0.8s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.9s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=50, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.6s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.7s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=log2, min_samples_leaf=100, random_state=0;, score=0.250 total time=   0.6s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.347 total time=   6.8s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.446 total time=  10.6s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=10, random_state=0;, score=0.455 total time=  10.7s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=15, random_state=0;, score=0.328 total time=   6.9s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=15, random_state=0;, score=0.427 total time=   6.7s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=15, random_state=0;, score=0.391 total time=   5.9s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=20, random_state=0;, score=0.341 total time=   4.7s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=20, random_state=0;, score=0.412 total time=   5.3s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=20, random_state=0;, score=0.373 total time=   5.8s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=50, random_state=0;, score=0.332 total time=   3.2s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=50, random_state=0;, score=0.250 total time=   3.1s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=50, random_state=0;, score=0.292 total time=   3.5s\n",
      "[CV 1/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=100, random_state=0;, score=0.250 total time=   2.9s\n",
      "[CV 2/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=100, random_state=0;, score=0.250 total time=   1.9s\n",
      "[CV 3/3] END class_weight=None, criterion=log_loss, max_features=None, min_samples_leaf=100, random_state=0;, score=0.250 total time=   2.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced_subsample',\n",
       " 'criterion': 'entropy',\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 20,\n",
       " 'random_state': 0}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'min_samples_leaf': [10, 15, 20, 50, 100],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'random_state':[0],\n",
    "    'class_weight': ['balanced', 'balanced_subsample', None],\n",
    "\n",
    "}\n",
    "\n",
    "random_state=0\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, descnm = data_preprocessing(data_db)\n",
    "X_train, y_train  = SMOTE(random_state=random_state).fit_resample(X_train, y_train)\n",
    "\n",
    "cv_res, cv_params = grid_search(X_val, y_val, param_grid, \n",
    "                                algorithm='RandomForestClassifier',)\n",
    "\n",
    "cv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.352468</td>\n",
       "      <td>0.283251</td>\n",
       "      <td>0.056033</td>\n",
       "      <td>0.029575</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.621986</td>\n",
       "      <td>0.620603</td>\n",
       "      <td>0.668508</td>\n",
       "      <td>0.637032</td>\n",
       "      <td>0.022264</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1.002776</td>\n",
       "      <td>0.084810</td>\n",
       "      <td>0.041103</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.621986</td>\n",
       "      <td>0.620603</td>\n",
       "      <td>0.668508</td>\n",
       "      <td>0.637032</td>\n",
       "      <td>0.022264</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.362295</td>\n",
       "      <td>0.387840</td>\n",
       "      <td>0.038346</td>\n",
       "      <td>0.008457</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.626035</td>\n",
       "      <td>0.621515</td>\n",
       "      <td>0.658140</td>\n",
       "      <td>0.635230</td>\n",
       "      <td>0.016305</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.721791</td>\n",
       "      <td>0.037742</td>\n",
       "      <td>0.032864</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.613023</td>\n",
       "      <td>0.617751</td>\n",
       "      <td>0.652360</td>\n",
       "      <td>0.627712</td>\n",
       "      <td>0.017536</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.380705</td>\n",
       "      <td>0.257520</td>\n",
       "      <td>0.048085</td>\n",
       "      <td>0.016267</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.634839</td>\n",
       "      <td>0.592249</td>\n",
       "      <td>0.647576</td>\n",
       "      <td>0.624888</td>\n",
       "      <td>0.023658</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.783398</td>\n",
       "      <td>0.057220</td>\n",
       "      <td>0.046231</td>\n",
       "      <td>0.010450</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.705298</td>\n",
       "      <td>0.038416</td>\n",
       "      <td>0.037967</td>\n",
       "      <td>0.009341</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.574440</td>\n",
       "      <td>0.015506</td>\n",
       "      <td>0.033182</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2.826892</td>\n",
       "      <td>0.494913</td>\n",
       "      <td>0.042237</td>\n",
       "      <td>0.010488</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2.470192</td>\n",
       "      <td>0.453961</td>\n",
       "      <td>0.036196</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>None</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'log_loss'...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "67        1.352468      0.283251         0.056033        0.029575   \n",
       "82        1.002776      0.084810         0.041103        0.008258   \n",
       "47        1.362295      0.387840         0.038346        0.008457   \n",
       "7         0.721791      0.037742         0.032864        0.005315   \n",
       "22        1.380705      0.257520         0.048085        0.016267   \n",
       "..             ...           ...              ...             ...   \n",
       "123       0.783398      0.057220         0.046231        0.010450   \n",
       "108       0.705298      0.038416         0.037967        0.009341   \n",
       "109       0.574440      0.015506         0.033182        0.006380   \n",
       "119       2.826892      0.494913         0.042237        0.010488   \n",
       "134       2.470192      0.453961         0.036196        0.009368   \n",
       "\n",
       "     param_class_weight param_criterion param_max_features  \\\n",
       "67   balanced_subsample         entropy               log2   \n",
       "82   balanced_subsample        log_loss               log2   \n",
       "47   balanced_subsample            gini               sqrt   \n",
       "7              balanced            gini               log2   \n",
       "22             balanced         entropy               log2   \n",
       "..                  ...             ...                ...   \n",
       "123                None        log_loss               sqrt   \n",
       "108                None         entropy               sqrt   \n",
       "109                None         entropy               sqrt   \n",
       "119                None         entropy               None   \n",
       "134                None        log_loss               None   \n",
       "\n",
       "    param_min_samples_leaf param_random_state  \\\n",
       "67                      20                  0   \n",
       "82                      20                  0   \n",
       "47                      20                  0   \n",
       "7                       20                  0   \n",
       "22                      20                  0   \n",
       "..                     ...                ...   \n",
       "123                     50                  0   \n",
       "108                     50                  0   \n",
       "109                    100                  0   \n",
       "119                    100                  0   \n",
       "134                    100                  0   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "67   {'class_weight': 'balanced_subsample', 'criter...           0.621986   \n",
       "82   {'class_weight': 'balanced_subsample', 'criter...           0.621986   \n",
       "47   {'class_weight': 'balanced_subsample', 'criter...           0.626035   \n",
       "7    {'class_weight': 'balanced', 'criterion': 'gin...           0.613023   \n",
       "22   {'class_weight': 'balanced', 'criterion': 'ent...           0.634839   \n",
       "..                                                 ...                ...   \n",
       "123  {'class_weight': None, 'criterion': 'log_loss'...           0.250000   \n",
       "108  {'class_weight': None, 'criterion': 'entropy',...           0.250000   \n",
       "109  {'class_weight': None, 'criterion': 'entropy',...           0.250000   \n",
       "119  {'class_weight': None, 'criterion': 'entropy',...           0.250000   \n",
       "134  {'class_weight': None, 'criterion': 'log_loss'...           0.250000   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "67            0.620603           0.668508         0.637032        0.022264   \n",
       "82            0.620603           0.668508         0.637032        0.022264   \n",
       "47            0.621515           0.658140         0.635230        0.016305   \n",
       "7             0.617751           0.652360         0.627712        0.017536   \n",
       "22            0.592249           0.647576         0.624888        0.023658   \n",
       "..                 ...                ...              ...             ...   \n",
       "123           0.250000           0.250000         0.250000        0.000000   \n",
       "108           0.250000           0.250000         0.250000        0.000000   \n",
       "109           0.250000           0.250000         0.250000        0.000000   \n",
       "119           0.250000           0.250000         0.250000        0.000000   \n",
       "134           0.250000           0.250000         0.250000        0.000000   \n",
       "\n",
       "     rank_test_score  \n",
       "67                 1  \n",
       "82                 1  \n",
       "47                 3  \n",
       "7                  4  \n",
       "22                 5  \n",
       "..               ...  \n",
       "123              120  \n",
       "108              120  \n",
       "109              120  \n",
       "119              120  \n",
       "134              120  \n",
       "\n",
       "[135 rows x 16 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_rf_cv_iter_2 = pd.DataFrame(cv_res).sort_values(by='mean_test_score', ascending=False)\n",
    "db_rf_cv_iter_2.to_csv('db_rf_cv_iter_2.csv', index=False)\n",
    "db_rf_cv_iter_2\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN scores \n",
      "\n",
      "f1: 0.961\n",
      "balanced accuracy: 0.962\n",
      "matthews corrcoeff: 0.949\n",
      "cf:\n",
      "[[2146   99   18    3]\n",
      " [ 100 2074   69   23]\n",
      " [   0   13 2246    7]\n",
      " [   0   16    0 2250]]\n",
      "-----------\n",
      "VAL scores \n",
      "\n",
      "f1: 0.842\n",
      "balanced accuracy: 0.685\n",
      "matthews corrcoeff: 0.573\n",
      "cf:\n",
      "[[ 57  31   9   0]\n",
      " [ 56 671  17  11]\n",
      " [  6   8  53   1]\n",
      " [  1  11   5  16]]\n",
      "-----------\n",
      "TEST scores \n",
      "\n",
      "f1: 0.835\n",
      "balanced accuracy: 0.650\n",
      "matthews corrcoeff: 0.545\n",
      "cf:\n",
      "[[ 48  42   6   1]\n",
      " [ 36 681  23  15]\n",
      " [  6   9  51   2]\n",
      " [  2  12   4  15]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion='entropy'\n",
    "max_features = 'log2'\n",
    "min_samples_leaf = 20\n",
    "max_iter=10000\n",
    "random_state=0\n",
    "class_weight = 'balanced_subsample'\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, descnm = data_preprocessing(data_db)\n",
    "X_train, y_train  = SMOTE(random_state=random_state).fit_resample(X_train, y_train)\n",
    "\n",
    "scaler = preprocessing.Normalizer()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# create final model in linreg\n",
    "lr = RandomForestClassifier(random_state=random_state,class_weight=class_weight, criterion=criterion, max_features=max_features, min_samples_leaf=min_samples_leaf)\n",
    "fit = lr.fit(X_train, y_train)\n",
    "y_pred = fit.predict(X_train)\n",
    "y_val_pred = fit.predict(X_val)\n",
    "y_test_pred = fit.predict(X_test)\n",
    "\n",
    "# calculate statistical metrics for training set\n",
    "train_f1 = metrics.f1_score(y_train, y_pred, average = 'weighted')\n",
    "train_ba = metrics.balanced_accuracy_score(y_train, y_pred)\n",
    "train_mcc = metrics.matthews_corrcoef(y_train, y_pred)\n",
    "train_cf = metrics.confusion_matrix(y_train, y_pred)\n",
    "\n",
    "# calculate statistical metrics for val set\n",
    "val_f1 = metrics.f1_score(y_val, y_val_pred, average = 'weighted')\n",
    "val_ba = metrics.balanced_accuracy_score(y_val, y_val_pred)\n",
    "val_mcc = metrics.matthews_corrcoef(y_val, y_val_pred)\n",
    "val_cf = metrics.confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# calculate statistical metrics for testing set\n",
    "test_f1 = metrics.f1_score(y_test, y_test_pred, average = 'weighted')\n",
    "test_ba = metrics.balanced_accuracy_score(y_test, y_test_pred)\n",
    "test_mcc = metrics.matthews_corrcoef(y_test, y_test_pred)\n",
    "test_cf = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(f'TRAIN scores \\n')\n",
    "print(f'f1: {train_f1:.3f}')\n",
    "print(f'balanced accuracy: {train_ba:.3f}')\n",
    "print(f'matthews corrcoeff: {train_mcc:.3f}')\n",
    "print(f'cf:\\n{train_cf}')\n",
    "print('-----------')\n",
    "print(f'VAL scores \\n')\n",
    "print(f'f1: {val_f1:.3f}')\n",
    "print(f'balanced accuracy: {val_ba:.3f}')\n",
    "print(f'matthews corrcoeff: {val_mcc:.3f}')\n",
    "print(f'cf:\\n{val_cf}')\n",
    "print('-----------')\n",
    "print(f'TEST scores \\n')\n",
    "print(f'f1: {test_f1:.3f}')\n",
    "print(f'balanced accuracy: {test_ba:.3f}')\n",
    "print(f'matthews corrcoeff: {test_mcc:.3f}')\n",
    "print(f'cf:\\n{test_cf}')\n",
    "print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGREG\n",
    "solver='saga'\n",
    "max_iter=10000\n",
    "random_state=0\n",
    "C=0.1\n",
    "penalty='l1'\n",
    "class_weight='balanced'\n",
    "\n",
    "X_train_lr, X_val_lr, X_test_lr, y_train_lr, y_val_lr, y_test_lr, descnm = data_preprocessing(data_da)\n",
    "\n",
    "X_train_lr, y_train_lr  = SMOTE(random_state=random_state).fit_resample(X_train_lr, y_train_lr)\n",
    "scaler = preprocessing.Normalizer()\n",
    "X_train_lr = scaler.fit_transform(X_train_lr)\n",
    "X_val_lr = scaler.transform(X_val_lr)\n",
    "X_test_lr = scaler.transform(X_test_lr)\n",
    "\n",
    "# create final model in linreg\n",
    "lr = LogisticRegression(solver=solver,max_iter=max_iter, random_state=random_state, C=C, penalty=penalty, class_weight=class_weight)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#SVM\n",
    "kernel='linear'\n",
    "max_iter=10000\n",
    "random_state=0\n",
    "gamma=1\n",
    "class_weight='balanced'\n",
    "\n",
    "X_train_svm, X_val_svm, X_test_svm, y_train_svm, y_val_svm, y_test_svm, descnm = data_preprocessing(data_da)\n",
    "\n",
    "X_train_svm, y_train_svm  = RandomOverSampler(random_state=random_state).fit_resample(X_train_svm, y_train_svm)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_svm = scaler.fit_transform(X_train_svm)\n",
    "X_val_svm = scaler.transform(X_val_svm)\n",
    "X_test_svm = scaler.transform(X_test_svm)\n",
    "scaler = preprocessing.Normalizer()\n",
    "X_train_svm = scaler.fit_transform(X_train_svm)\n",
    "X_val_svm = scaler.transform(X_val_svm)\n",
    "X_test_svm = scaler.transform(X_test_svm)\n",
    "\n",
    "# create final model in linreg\n",
    "svm = SVC(probability=True, kernel=kernel,max_iter=max_iter, random_state=random_state, gamma=gamma, class_weight=class_weight)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#RANDOM FOREST\n",
    "X_train_rf, X_val_rf, X_test_rf, y_train_rf, y_val_rf, y_test_rf, descnm = data_preprocessing(data_da)\n",
    "\n",
    "X_train_rf, y_train_rf  = RandomOverSampler(random_state=random_state).fit_resample(X_train_rf, y_train_rf)\n",
    "\n",
    "# create final model in RF\n",
    "rf = RandomForestClassifier(random_state=random_state, class_weight=class_weight, criterion=criterion, max_features=max_features, min_samples_leaf=min_samples_leaf)\n",
    "rf.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "#CURVE\n",
    "# Make predictions on the test set\n",
    "y_pred_proba_lr = lr.predict_proba(X_test_lr)[:, 1] #lr\n",
    "y_pred_proba_svm = svm.predict_proba(X_test_svm)[:, 1] #svm\n",
    "y_pred_proba_rf = rf.predict_proba(X_test_rf)[:, 1] #rf\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr_lr, tpr_lr, thresholds = metrics.roc_curve(y_test_lr, y_pred_proba_lr)\n",
    "fpr_svm, tpr_svm, thresholds = metrics.roc_curve(y_test_svm, y_pred_proba_svm)\n",
    "fpr_rf, tpr_rf, thresholds = metrics.roc_curve(y_test_rf, y_pred_proba_rf)\n",
    "\n",
    "roc_auc_lr = metrics.auc(fpr_lr, tpr_lr)\n",
    "roc_auc_svm = metrics.auc(fpr_svm, tpr_svm)\n",
    "roc_auc_rf = metrics.auc(fpr_rf, tpr_rf)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr_lr, tpr_lr, color='red', lw=2, label='LR: %0.2f' % roc_auc_lr)\n",
    "plt.plot(fpr_svm, tpr_svm, color='green', lw=2, label='SVM: %0.2f' % roc_auc_svm)\n",
    "plt.plot(fpr_rf, tpr_rf, color='blue', lw=2, label='RF %0.2f' % roc_auc_rf)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('A/NA')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kinase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
